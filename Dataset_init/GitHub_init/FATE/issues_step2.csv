url	label	title	search_text	comments	created_time	updated_time	closed_time
https://github.com/FederatedAI/FATE/issues/3132	[]	运行出现奇怪错误，急需帮助	"运行出现奇怪错误，急需帮助部署两个k8s集群做联邦（CentOS），运行测试算例，出现一个很奇怪的错误。在work_mode=1情况下，虽然运行官方的例子整个pipeline没有问题，但一旦对table或namespace重命名后(比如把namespace的experiment改名为experiment_b)，pipeline的reader就无法通过。

jupyter-notebook里上传数据
!flow data upload -c upload_guest.json --drop
!flow data upload -c upload_host.json --drop
运行计算
!flow job submit -c hetero_lr_normal_conf.json -d hetero_lr_normal_dsl.json
因为issues里面不能上传json文件，所以我加了.txt后缀，如果下载运行的话，可以把文件名的.txt后缀删除
[hetero_lr_normal_conf.json.txt](https://github.com/FederatedAI/FATE/files/7221995/hetero_lr_normal_conf.json.txt)
[hetero_lr_normal_dsl.json.txt](https://github.com/FederatedAI/FATE/files/7221997/hetero_lr_normal_dsl.json.txt)
[upload_guest.json.txt](https://github.com/FederatedAI/FATE/files/7221998/upload_guest.json.txt)
[upload_host.json.txt](https://github.com/FederatedAI/FATE/files/7221999/upload_host.json.txt)

fateboard里面数据确实读了，证明上传数据成功，但reader就是无法通过，且没有任何出错提示。
![image](https://user-images.githubusercontent.com/28068712/134611625-0b078e6a-3c97-4c91-987a-2a810ad0dd2b.png)
![image](https://user-images.githubusercontent.com/28068712/134611696-6f807700-352a-41c0-97b1-eb925864ce8d.png)
![image](https://user-images.githubusercontent.com/28068712/134611712-e3af8f8c-aa31-4a8b-b9dd-1d329a458af7.png)

奇怪的问题就是：在保证各个json文件的table name和namespace一致的情况下，虽然采用原始默认的table name和namespace运行pipeline全绿，为什么稍微改动表名或namespace，就无法运行通过？难道除了这四个json文件，还有哪里需要同步改动？
奇怪的问题就是：在保证各个json文件的table name和namespace一致的情况下，虽然采用原始默认的table name和namespace运行pipeline全绿，为什么稍微改动表名或namespace，就无法运行通过？难道除了这四个json文件，还有哪里需要同步改动？已经解决，与重命名无关，根本原因是work_mode=1（多集群）时候，每方需要在自己的notebook里提交自己的数据。如果要重命名，确保各方数据的新名称与json文件的设置保持一致即可。"	2	2021-09-24 03:08:30	2021-09-24 09:47:18	2021-09-24 09:47:18
https://github.com/FederatedAI/FATE/issues/2977	[]	"""predict_score"" for logistic regression test on Fate Board wrong in magnitude"	"""predict_score"" for logistic regression test on Fate Board wrong in magnitude**Describe the bug**
In fateboard, the ""predict_score"" for logistic regression test will sometimes be larger than 1. For example, look at the following screenshot:
![Screen Shot 2021-08-17 at 4 31 29 PM](https://user-images.githubusercontent.com/62225631/129692241-01f66ac4-7466-44af-a86d-fca5cde86178.png)
and after a deeper insight, I find that it's actually missing a magnitude specification. For example, the value 2.719735 is actually 2.719735...e-12. But somehow the magnitude ""e-12"" is missing, which really confuses users.
![Screen Shot 2021-08-17 at 4 34 03 PM](https://user-images.githubusercontent.com/62225631/129692652-d23ae2a5-4f4d-4cc8-8147-07995c6722c4.png)
We will fix this issue in FATE-Board V1.6.1，thanks for your carefulness."	1	2021-08-17 08:35:39	2021-08-18 08:55:19	2021-08-18 08:55:19
https://github.com/FederatedAI/FATE/issues/2955	[]	Poor Implementation of SPDZ protocol	"Poor Implementation of SPDZ protocol**Describe the bug**
The implementation of SPDZ protocol is incomplete, crucial features of the original protocol are truncated.
1. Not secure against active malicious adversary.
Without using information theoretic MACs or zero-knowledge proofs as the original protocol, active malicious adversary can cheat on their inputs and render incorrect results.  

2. Only support two parties.
The implementation uses Paillier encryption to produce beaver triplets which makes it limit to two parties while the original SPDZ has no party number limits. Should use somewhat FHE or leveled FHE like BGV, BFV to produce beaver triplets instead. Thanks report. 

>     1. Not secure against active malicious adversary.
>        Without using information theoretic MACs or zero-knowledge proofs as the original protocol, active malicious adversary can cheat on their inputs and render incorrect results.

The `secure against active malicious adversary` is not the goal we try to achieve in recent version, but pull requests are always welcome.

>     2. Only support two parties.
>        The implementation uses Paillier encryption to produce beaver triplets which makes it limit to two parties while the original SPDZ has no party number limits. Should use somewhat FHE or leveled FHE like BGV, BFV to produce beaver triplets instead.

Yes, we support two parties now becasue we meat some fixpoint-encoder issue, not becuase we use the `Paillier encryption` 
protocol. And we don't see the point of goodness to use somewhat FHE to genearete beaver triplets. Could you please provide any more detailed explanation？
> Thanks report.
> 
> > ```
> > 1. Not secure against active malicious adversary.
> >    Without using information theoretic MACs or zero-knowledge proofs as the original protocol, active malicious adversary can cheat on their inputs and render incorrect results.
> > ```
> 
> The `secure against active malicious adversary` is not the goal we try to achieve in recent version, but pull requests are always welcome.
> 
> > ```
> > 2. Only support two parties.
> >    The implementation uses Paillier encryption to produce beaver triplets which makes it limit to two parties while the original SPDZ has no party number limits. Should use somewhat FHE or leveled FHE like BGV, BFV to produce beaver triplets instead.
> > ```
> 
> Yes, we support two parties now becasue we meat some fixpoint-encoder issue, not becuase we use the `Paillier encryption`

**_> My mistake, if Paillier supports multiplication between ciphertext and constants, and you followed the SPDZ2's triplets generation protocol, fate's beaver_triplets doesn't have party number limitation. Also, can you give me more details of this fixpoint-encoder issue? I am working on the two party limit issue. And can we use Microsoft Seal's CKKS instead of Paillier to fix this issue?_**

> protocol. And we don't see the point of goodness to use somewhat FHE to genearete beaver triplets. Could you please provide any more detailed explanation？

**_> SPDZ2's` paper do mention some benefits of using Leveled FHE BGV over Paillier at the last paragraphy of its Introduction section._**

**_> One more thing to mention, SPDZ's unit test shows errors : module ""fate_arch.session"" has no attirbute ""init""._**@weiwee 
**Good News**: The party number limit of SPDZ can be removed by using Microsoft Seal's CKKS as well as all the redundant fixpoint encoding and decoding code.   I tested the modified SPDZ in hetero_pearson with three parties:1 Guest, 2 Hosts, and the data I used is breast_hetero_guest and breast_hetero_host. 
Here is the first corr row:

>  [0.9739451840944395 0.42625413530776457 0.9755094378288185
>  0.9697823086090491 0.05205141649569391 0.561382889899243
>  0.7069897199142066 0.7481190687094059 -0.19798667287048125
>  -0.5964790654824891 0.4159688144789205 -0.08748228172470007
>  0.38501085106115696 0.758014080265595 -0.44258157229279843
>  -0.014301103237581181 0.13761181368069303 0.43303178978547496
>  -0.5738301629347646 -0.388682601417217]

And the first corr row using original  SPDZ:

> [0.97387 0.42623 0.97545 0.96972 0.052039999999999996 0.56136
>  0.7069300000000001 0.74806 -0.19799 -0.59645 0.41595000000000004 -0.08748
>  0.38499 0.75797 -0.44254 -0.014299999999999998 0.13759 0.433
>  -0.5738000000000001 -0.38864]

We can see the results are pretty close.  

**Bad News** :   The ciphertext is too large(nearly 1.9GB) for the tested table(Using CKKS.tensor for encryption). It caused memory error when I tried to remote. To pass the test, I cut breast_hetero_guest to 10 rows.  

Nary a douobt. This large ciphertext size issue will limit its applications. Have to work on that latter.    Close this issue first."	3	2021-08-09 03:56:36	2021-08-25 10:11:15	2021-08-25 10:11:15
https://github.com/FederatedAI/FATE/issues/2909	[]	pipeline: command not found	"pipeline: command not found**Describe the bug**
A clear and concise description of what the bug is.

按照git文档成功安装fate-client后无法使用pipeline

**To Reproduce**
Steps to reproduce the behavior:
通过docker完成单机部署并通过单元测试和toy测试验证，通过whl安装fate-client
```
Singularity> pip show fate-client
Name: fate-client
Version: 0.3.0.post1
Summary: Clients for FATE, including flow_client and pipeline
Home-page: https://fate.fedai.org/
Author: FederatedAI
Author-email: contact@FedAI.org
License: Apache-2.0
Location: /root/.local/lib/python3.6/site-packages
Requires: flask, setuptools, tensorflow, click, ruamel.yaml, requests-toolbelt, loguru, requests
Required-by: fate-test
Singularity> pipeline init --help
bash: pipeline: command not found
```

**Expected behavior**
A clear and concise description of what you expected to happen.

**Screenshots**
If applicable, add screenshots to help explain your problem.

**Desktop (please complete the following information):**
 - OS: [e.g. iOS]
 - Browser [e.g. chrome, safari]
 - Version [e.g. 22]

**Smartphone (please complete the following information):**
 - Device: [e.g. iPhone6]
 - OS: [e.g. iOS8.1]
 - Browser [e.g. stock browser, safari]
 - Version [e.g. 22]

**Additional context**
Add any other context about the problem here.
edit:
由于没有平台root权限，利用singularity3.7的fakeroot在Linux平台上进入环境。

使用裸机尝试可以安装成功。

验证是安装路径在/root/.local/bin下，使用`export PATH=$PATH:/root/.local/bin`解决"	1	2021-07-23 03:35:07	2021-07-23 07:43:35	2021-07-23 07:43:35
https://github.com/FederatedAI/FATE/issues/2893	[]	发布模型时一个成功一个失败	"发布模型时一个成功一个失败刚训练好的模型，然后模型在各方均部署成功。但发布模型的时候一个成功一个失败，请问时什么原因？
请求：
{
    ""initiator"": {
        ""role"": ""guest"",
        ""party_id"": ""9999""
    },
    ""job_parameters"": {
        ""work_mode"": 1,
        ""model_id"": ""arbiter-10000#guest-9999#host-8888#model"",
        ""model_version"": ""2021071909181355014422""
    },
    ""role"": {
        ""arbiter"": [
            ""10000""
        ],
        ""host"": [
            ""8888""
        ],
        ""guest"": [
            ""9999""
        ]
    }
}
响应：
{
    ""data"": {
        ""detail"": {
            ""guest"": {
                ""9999"": {
                    ""retcode"": 123,
                    ""retmsg"": ""model initialization error, please check if the model exists and the configuration of the FATEFLOW load model process is correct. ""
                }
            },
            ""host"": {
                ""8888"": {
                    ""retcode"": 0,
                    ""retmsg"": ""success""
                }
            }
        },
        ""guest"": {
            ""9999"": 123
        },
        ""host"": {
            ""8888"": 0
        }
    },
    ""jobId"": ""2021071909183592077723"",
    ""retcode"": 101,
    ""retmsg"": ""failed""
}FATE version? post your `conf/service_conf.yaml` plz. which backend are you using? plz post its config too.The problem has been resolved。
Thanks for your helpHow did you solve it?  I have met the same problem."	3	2021-07-19 09:47:31	2021-09-28 02:01:02	2021-08-26 03:00:03
https://github.com/FederatedAI/FATE/issues/2845	[]	Homogeneous Logistic Regression using Gradient Aggregation not implemented?	"Homogeneous Logistic Regression using Gradient Aggregation not implemented?Hi,
I was going through the code of homo-lr, and I wonder if the method described in the README is not implemented in the code.

**Mismatch between README and code?**
Described in https://github.com/FederatedAI/FATE/blob/7f81d654bf9ddbb1207bbd3c02e130f5ea54b1dc/python/federatedml/linear_model/logistic_regression/README.rst 
<img width=""1227"" alt=""Screen Shot 2021-06-27 at 2 14 24 PM"" src=""https://user-images.githubusercontent.com/59325005/123535036-03729e00-d754-11eb-8a41-8505564df62a.png"">
the homogeneous LR sends and aggregates **gradients** in each iteration. However, in the code, it is the **model weights** that are sent and aggregated:
https://github.com/FederatedAI/FATE/blob/7f81d654bf9ddbb1207bbd3c02e130f5ea54b1dc/python/federatedml/linear_model/logistic_regression/homo_logsitic_regression/homo_lr_host.py#L94-L95

and the gradient is computed and applied for weight update **within** each host
https://github.com/FederatedAI/FATE/blob/7f81d654bf9ddbb1207bbd3c02e130f5ea54b1dc/python/federatedml/linear_model/logistic_regression/homo_logsitic_regression/homo_lr_host.py#L117-L131

There seems to be a mismatch between the README and the code.  

**Describe the solution you'd like**
Is homo-lr using gradient aggregation not implemented or is the code elsewhere? Could you refer to the code if it is elsewhere?
If not implemented, could you explain if any difficulties were encountered that blocked the implementation? (e.g. encryption, numerical precision, etc.)?

**Describe alternatives you've considered**
I did an implementation to use the gradient aggregation described in the README.rst above (for simplicity I did not use encryption)
https://github.com/xingzhis/pretendFLR
It works well if precise gradients (of the cross-entropy loss) are used, but if Taylor expansion gradient is used (so that additively homomorphic encryption can be used), the numerical errors accumulate, resulting in a failure to learn the model correctly.

Thank you very much!
@xingzhis Sorry for misunderstanding you. We do aggregate the model_weights instead of gradient. The Readme will be fix in next version. 

@tanmc123 Thank you very much!"	2	2021-06-27 06:51:10	2021-07-06 01:18:13	2021-07-06 01:18:13
https://github.com/FederatedAI/FATE/issues/2834	[]	Homogeneous Neural Network	"Homogeneous Neural Network**Describe the bug**
A clear and concise description of what the bug is.

**To Reproduce**
Steps to reproduce the behavior:
1. Go to https://github.com/FederatedAI/FATE/blob/master/examples/pipeline/homo_nn/pipeline_homo_nn_multi_layer.py
2. Update the neural network to be the following

def main(config=""../../config.yaml"", namespace=""""):
    homo_nn_0 = HomoNN(name=""homo_nn_0"",
                       max_iter=epochs,
                       batch_size=batch_size)
    homo_nn_0.add(Dense(units=nodes_per_layer[0], input_shape=(12,), activation=""relu""))
    homo_nn_0.add(Dropout(dropout))
    homo_nn_0.add(Dense(units=nodes_per_layer[1], activation=""relu""))
    homo_nn_0.add(Dropout(dropout))
    homo_nn_0.add(Dense(units=nodes_per_layer[2], activation=""relu""))
    homo_nn_0.add(Dropout(dropout))
    homo_nn_0.add(Dense(units=1, activation=""relu""))
    homo_nn_0.compile(optimizer=optimizers.Adam(learning_rate=0.05),
                      metrics=[""MeanSquaredError""],
                      loss=""mean_squared_error"")

**Expected behavior**
I expect the NN to output a single prediction of the target variable which is a continuous variable

**Errors**
ValueError: A target array with shape (16, 1) was passed for an output of shape (None, 151) while using as loss `mean_squared_error`. This loss expects targets to have the same shape as the output.

**Question**
How can I perform a regression prediction using neural network, instead of a categorical prediction shown in all 3 homo_nn examples?

Note that the error goes away if i change loss=""mean_absolute_error"" instead.Homo Neural Network does not support regression task now, only supports classification task.thanks for your reply! would be great if that can be made clearer in the documentation."	2	2021-06-16 13:52:27	2021-06-22 12:50:51	2021-06-22 12:50:51
https://github.com/FederatedAI/FATE/issues/2817	[]	BUG：Please check that you are connecting to the correct HDFS RPC port	"BUG：Please check that you are connecting to the correct HDFS RPC port**Describe the bug**
KubeFATE部署完之后，准备数据上传，结果出现HDFS的报错异常，刚部署上就出现异常，请问有么有大佬遇到此问题

**To Reproduce**
Steps to reproduce the behavior:
1. 准备mnist数据
2. 仿照upload文件写文件命名
3.执行数据上传命令
4. See error

**Expected behavior**





**Screenshots**
![image](https://user-images.githubusercontent.com/40295475/120348131-780e1480-c32f-11eb-91c7-b7319844413f.png)

![image](https://user-images.githubusercontent.com/40295475/120348195-8a884e00-c32f-11eb-924c-a297529db6bc.png)

**Desktop (please complete the following information):**
 - OS: [e.g. iOS]
 - Browser [e.g. chrome, safari]
 - Version [e.g. 22]

**Smartphone (please complete the following information):**
 - Device: [e.g. iPhone6]
 - OS: [e.g. iOS8.1]
 - Browser [e.g. stock browser, safari]
 - Version [e.g. 22]

**Additional context**
Add any other context about the problem here.
数据处理有一些问题"	1	2021-06-01 15:17:39	2021-06-02 01:15:28	2021-06-02 01:15:07
https://github.com/FederatedAI/FATE/issues/2758	['bug']	Homo_onehot存在特征不能对齐的bug！	"Homo_onehot存在特征不能对齐的bug！**1、问题描述**
在真实场景下使用横向onehot对数据做处理，之后再用横向LR模型，得到的结果与预期相差非常大（远远不如只使用本地数据），完全不可用。
**2、实验过程**
经过多次实验，发现横向LR得到的结果均很差，Debug横向LR的计算逻辑，没有发现问题，十分无助。后来，无意中检查了onehot之后的特征列，如下图所示：
![image](https://user-images.githubusercontent.com/34981842/115832226-3c854e00-a445-11eb-92b5-5f3cf59dfe17.png)
上图是guest方使用homo_onehot之后特征顺序的结果
![image](https://user-images.githubusercontent.com/34981842/115832412-76eeeb00-a445-11eb-9ae4-f395d4de6642.png)
上图是host方使用homo_onehot之后特征顺序的结果
可以看到，使用homo_onehot得到的特征顺序不一致！
**不免有些疑惑，计算的时候是根据字段名还是字段顺序计算的？**
![image](https://user-images.githubusercontent.com/34981842/115832694-c46b5800-a445-11eb-8643-133dafe1ba3f.png)
上图是guest方第一次本地计算的参数结果
![image](https://user-images.githubusercontent.com/34981842/115832784-e1079000-a445-11eb-9426-73f5d9c5bc88.png)
 上图是host方第一次本地计算的参数结果
由于在实验条件下两边上传了一样的数据，可以看到对应特征名下的参数值是相同的，接下来看一下聚合的结果：
![image](https://user-images.githubusercontent.com/34981842/115833183-53787000-a446-11eb-93d4-3c6a9f848dc5.png)
**3、结论**
不免有些惊讶，竟然是根据特征顺序进行计算的，但是homo_onehot得到的特征顺序又不一致，导致参数更新时梯度信息混乱，得到十分意外的结果。
感谢FATE平台，感谢FATE开源社区，希望FATE能够越来越好！！确实有这个问题，预计将在1.5.2修复，感谢提出"	1	2021-04-23 07:15:31	2021-06-09 03:28:45	2021-06-09 03:28:45
https://github.com/FederatedAI/FATE/issues/2752	[]	请问下，现在serving支持dsl_v2了吗？（因模型部署上线后预测无结果而有的猜疑....）	"请问下，现在serving支持dsl_v2了吗？（因模型部署上线后预测无结果而有的猜疑....）（dockers部署的）用最新版的fate跑pipeline训练出的模型在部署上线时，过程都是success，但是到推理测试就是啥结果也没，返回结果像下面这样：

- {""retcode"":0,""retmsg"":"""",""data"":{""modelId"":""guest#9999#guest-9999#host-10000#model"",""modelVersion"":""2021041903133901753497"",""timestamp"":1618802149453},""flag"":0}

然后瞅了下serving-server容器，发现在运行加载模型命令（**_flow model load -c publish_load_model.json_**）的时候，这个容器logs里会报这个错：

- DSLParser init catch error:{}
 org.json.JSONException: JSONObject[""input""] not found.

就怀疑是解析dsl时出错了，所以想问下现在的serving是不是还不支持dsl_v2？如果是的话，难道还要用dsl_v1来上线？或是其他什么方式？大佬们求解orz
@nemirorox @weiwee @jarviszeng-zjc @tanmc123 @ioracion 2.0.4的fate serving是支持DSL 2.0的@jiahaoc1993 感谢回复！
希望能再帮忙解疑下：就是在加载模型时，serving-server容器后台会报这个错：
![log](https://user-images.githubusercontent.com/17641924/115361589-4dd71c00-a1f3-11eb-842d-2583db337716.png)
我部属的流程是这样的（按照pipeline预测例子弄的，是不是这样不对？）：
![微信截图_20210420161000](https://user-images.githubusercontent.com/17641924/115361710-69422700-a1f3-11eb-8699-856d5f45b145.png)

@ioracion 容器版本的serving是2.0.0的，所以报错正常@jiahaoc1993 非常感谢！问题解决了"	4	2021-04-19 09:47:17	2021-04-21 07:24:10	2021-04-21 07:24:10
https://github.com/FederatedAI/FATE/issues/2751	[]	安装fate-client之后无法使用flow命令	"安装fate-client之后无法使用flow命令**环境**：使用docker-compose 配置的fate1.5版本
使用清华源安装fate-client
**错误**：
![image](https://user-images.githubusercontent.com/39814669/115117798-ecd0fd80-9fd2-11eb-8b4a-b9d4ff8308f9.png)

**RuntimeError**: Click will abort further execution because Python 3 was configured to use ASCII as encoding for the environment. Consult https://click.palletsprojects.com/python3/ for mitigation steps.

Additional information: on this system no suitable UTF-8 locales were discovered. This most likely requires resolving by reconfiguring the locale system.
尝试的解决办法：
export LC_ALL=en_US.UTF-8
export LANG=en_US.UTF-8
![image](https://user-images.githubusercontent.com/39814669/115117938-8b5d5e80-9fd3-11eb-8510-517e269dc11e.png)
**仍然不行**
![image](https://user-images.githubusercontent.com/39814669/115117975-afb93b00-9fd3-11eb-8533-9710167bdf1b.png)

请问如何解决这个问题，或者说还有无其他办法让我可以使用flow命令？已解决，系统缺少utf-8的字符编码语言包，下载安装设置环境变量即可。"	1	2021-04-17 15:23:03	2021-04-25 06:04:56	2021-04-25 06:04:56
https://github.com/FederatedAI/FATE/issues/2748	[]	车联网与联邦学习结合的话用standalone还是cluster	"车联网与联邦学习结合的话用standalone还是clusterPlease briefly describe the scenario of your demands in Internet of Vehicles, how to combine your demands with federated learning. Generally, computers on vehicles have limited capability which can hardly cover training assignments locally. If you send some data collected from sensors to computing server, you must take latency among all vehicles and servers. Also, cost is always a big deal.感谢您的回答，具体场景确实如您所说。我们的想法是在这样的场景下进行，车辆之间要想互相通信，需要借助每个路口的路边单元，可以把路边单元看做一个基站，通过基站决定走哪条信道，从而使整个网络中的信道负载达到最优，最主要的部分是路边单元收集车辆通信请求数据后，传到联邦学习的框架里，训练完成后返回方案。但是现在我们不知道该如何将路边单元的数据传到联邦学习框架里，以及是否有已有的合适的算法，感谢您的指导，非常期待您对以上问题的解答，万分感谢



> Please briefly describe the scenario of your demands in Internet of Vehicles, how to combine your demands with federated learning. Generally, computers on vehicles have limited capability which can hardly cover training assignments locally. If you send some data collected from sensors to computing server, you must take latency among all vehicles and servers. Also, cost is always a big deal.

"	2	2021-04-15 12:03:27	2021-05-26 13:40:04	2021-05-26 13:40:04
https://github.com/FederatedAI/FATE/issues/2746	[]	Where is the proto_generate.sh?	"Where is the proto_generate.sh?**Describe the bug**
Where is the [proto_generate.sh](https://github.com/FederatedAI/FATE/blob/master/doc/python/federatedml/protobuf/proto_generate.sh)?
https://github.com/FederatedAI/FATE/blob/178f04d1a58181359d6550b4673d4b4dc72a778f/doc/develop_guide.rst#L266

By the way, how to recompile the whole FATE after generating files from `.proto` files.It is located here: https://github.com/FederatedAI/FATE/blob/master/python/fate_arch/protobuf/generate_py.sh

We will fix the doc later. Thank you for pointing out. "	1	2021-04-14 10:38:29	2021-07-09 03:15:40	2021-07-09 03:15:40
https://github.com/FederatedAI/FATE/issues/2742	[]	请问一下FATE对具体的Linux版本有要求吗？比如SUSE、centos，或者 ubantu这些linux都支持吗？	请问一下FATE对具体的Linux版本有要求吗？比如SUSE、centos，或者 ubantu这些linux都支持吗？You can use docker to experience FATE and to avoid problems in some distributions of Linux.	1	2021-04-13 01:14:41	2021-05-26 13:40:21	2021-05-26 13:40:21
https://github.com/FederatedAI/FATE/issues/2739	[]	fate集群，使用mnist训练数据模型，按照彭路工程师发布的博客操作，为什么任务出错了？	"fate集群，使用mnist训练数据模型，按照彭路工程师发布的博客操作，为什么任务出错了？我按照这个彭路工程师的操作，https://my.oschina.net/u/4238514/blog/3279779
使用fate集群，mnist数据集来训练模型，
为什么任务训练出错了。。
看不懂报错信息55555
不知道怎么解决，求大神指教，，


任务提交成功，但是执行失败，报错信息如下：
![image](https://user-images.githubusercontent.com/50815935/114028361-f9ef3d80-98aa-11eb-82b6-00675187d554.png)


修改损失函数为categorical_crossentpoty时，报错如下：
![image](https://user-images.githubusercontent.com/50815935/114028241-d88e5180-98aa-11eb-98d3-a713e943f377.png)

[ERROR] [2021-04-08 12:07:35,634] [2600:140528646215488] - task_executor.py[line:191]: You are passing a target array of shape (30000, 1) while using as loss `categorical_crossentropy`. `categorical_crossentropy` expects targets to be binary matrices (1s and 0s) of shape (samples, classes). If your targets are integer classes, you can convert them to the expected format via:

```

from keras.utils import to_categorical

y_binary = to_categorical(y_int)

y_binary = to_categorical(y_int)

```

Alternatively, you can use the loss function `sparse_categorical_crossentropy` instead, which does expect integer targets.

Traceback (most recent call last):

  File ""./fate/python/fate_flow/operation/task_executor.py"", line 168, in run_task

    run_object.run(component_parameters_on_party, task_run_args)

  File ""./fate/python/federatedml/model_base.py"", line 101, in run

    this_data_output = func(*params)

  File ""./fate/python/federatedml/nn/homo_nn/enter_point.py"", line 107, in fit

    _version_0.client_fit(self=self, data_inst=data)

  File ""./fate/python/federatedml/nn/homo_nn/_version_0.py"", line 161, in client_fit

    self.nn_model.train(data, aggregate_every_n_epoch=self.aggregate_every_n_epoch)

  File ""./fate/python/federatedml/nn/backend/tf_keras/nn_model.py"", line 250, in train

    self._model.fit(x=data, epochs=epochs, verbose=1, shuffle=True, **left_kwargs)

  File ""/opt/app-root/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_v1.py"", line 808, in fit

    use_multiprocessing=use_multiprocessing)

  File ""/opt/app-root/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator_v1.py"", line 593, in fit

    steps_name='steps_per_epoch')

  File ""/opt/app-root/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator_v1.py"", line 259, in model_iteration

    batch_outs = batch_function(*batch_data)

  File ""/opt/app-root/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_v1.py"", line 1063, in train_on_batch

    extract_tensors_from_dataset=True)

  File ""/opt/app-root/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_v1.py"", line 2336, in _standardize_user_data




构建出的模型json：
{""class_name"": ""Sequential"", ""config"": {""name"": ""sequential"", ""layers"": [{""class_name"": ""InputLayer"", ""config"": {""batch_input_shape"": [null, 784], ""dtype"": ""float32"", ""sparse"": false, ""ragged"": false, ""name"": ""dense_input""}}, {""class_name"": ""Dense"", ""config"": {""name"": ""dense"", ""trainable"": true, ""batch_input_shape"": [null, 784], ""dtype"": ""float32"", ""units"": 512, ""activation"": ""relu"", ""use_bias"": true, ""kernel_initializer"": {""class_name"": ""GlorotUniform"", ""config"": {""seed"": null}}, ""bias_initializer"": {""class_name"": ""Zeros"", ""config"": {}}, ""kernel_regularizer"": null, ""bias_regularizer"": null, ""activity_regularizer"": null, ""kernel_constraint"": null, ""bias_constraint"": null}}, {""class_name"": ""Dense"", ""config"": {""name"": ""dense_1"", ""trainable"": true, ""dtype"": ""float32"", ""units"": 256, ""activation"": ""relu"", ""use_bias"": true, ""kernel_initializer"": {""class_name"": ""GlorotUniform"", ""config"": {""seed"": null}}, ""bias_initializer"": {""class_name"": ""Zeros"", ""config"": {}}, ""kernel_regularizer"": null, ""bias_regularizer"": null, ""activity_regularizer"": null, ""kernel_constraint"": null, ""bias_constraint"": null}}, {""class_name"": ""Dense"", ""config"": {""name"": ""dense_2"", ""trainable"": true, ""dtype"": ""float32"", ""units"": 10, ""activation"": ""softmax"", ""use_bias"": true, ""kernel_initializer"": {""class_name"": ""GlorotUniform"", ""config"": {""seed"": null}}, ""bias_initializer"": {""class_name"": ""Zeros"", ""config"": {}}, ""kernel_regularizer"": null, ""bias_regularizer"": null, ""activity_regularizer"": null, ""kernel_constraint"": null, ""bias_constraint"": null}}]}, ""keras_version"": ""2.4.0"", ""backend"": ""tensorflow""}
"	1	2021-04-08 12:45:01	2021-04-11 05:05:26	2021-04-11 05:05:26
https://github.com/FederatedAI/FATE/issues/2665	[]	evaluation评测结果是否又bug？！	"evaluation评测结果是否又bug？！前端显示是否存在bug？
如下图所示，通过混淆矩阵手动计算的精确率和召回率，和前端显示的完全不一致，是前端显示的bug吗？

![微信图片_20210319152059](https://user-images.githubusercontent.com/34981842/111744869-d5fd9500-88c6-11eb-9f32-e523535eb208.jpg)

hi，
上面那个的threshold是50%分位点（Quantile），
下面那个的threshold是0.5（实值），二者是不一样的。Problem solved, issue close"	2	2021-03-19 07:25:11	2021-04-05 02:03:26	2021-04-05 02:03:25
https://github.com/FederatedAI/FATE/issues/2646	[]	请教Homo_LR训练卡在initialized model！！	"请教Homo_LR训练卡在initialized model！！请教一下为什么使用homo_lr建模时，一直卡在initialized model，可能是什么原因造成的？
log信息如下图所示
![image](https://user-images.githubusercontent.com/34981842/111022797-0b5e3a80-8410-11eb-8bb0-1f2c7b2952e9.png)
![image](https://user-images.githubusercontent.com/34981842/111022805-216bfb00-8410-11eb-8f9a-26970934046b.png)
没有问题了，其中某一方数据异常，导致整体进度卡住。"	1	2021-03-13 07:25:50	2021-04-23 02:55:55	2021-04-23 02:55:55
https://github.com/FederatedAI/FATE/issues/2641	[]	Homo OneHot Encoder是否有bug	"Homo OneHot Encoder是否有bug使用横向onehot--‘’Homo_OneHot_Encoder‘’，测试集单独onehot_1，输入数据集为测试数据集及onehot_0的model，特征可以保持一致。同时也会存在问题，测试集单独onehot_1的得到的特征同训练集onehot_0一致，但onehot_1之后out_put的数据全是0。
```json
""one_hot_0"":{
   ""module"":""HomoOneHotEncoder"",
   ""input"":{
      ""data"":{
         ""data"":[
            ""dataio_0.data""
         ]
      }
   },
   ""output"":{
      ""data"":[
         ""data""
      ],
      ""model"":[
         ""model""
      ]
   }
},
""one_hot_1"":{
   ""module"":""HomoOneHotEncoder"",
   ""input"":{
      ""data"":{
         ""data"":[
            ""dataio_1.data""
         ]
      },
      ""model"":[
         ""one_hot_0.model""
      ]
   },
   ""output"":{
      ""data"":[
         ""data""
      ],
      ""model"":[
         ""model""
      ]
   }
},
```
@xiaoqing928 感谢提出，预计会在1.5.2和1.6同步修复"	1	2021-03-11 02:58:27	2021-06-09 03:29:15	2021-06-09 03:29:15
https://github.com/FederatedAI/FATE/issues/2639	[]	OnehotEncoder逻辑是否有Bug	"OnehotEncoder逻辑是否有Bugsklearn的onehot分两个步骤：
1、将训练集与测试集的数据合并做fit
2、分别对训练集数据、测试集数据做tranform得到2份结果

但fate的onehot，却是训练集单独onehot_0，输入数据集只有训练集自身的数据，测试集单独onehot_1，输入数据集为测试数据集及onehot_0的model，并没有将2个数据集合并做fit的过程：
""one_hot_0"": {
            ""module"": ""OneHotEncoder"",
            ""input"": {
                ""data"": {
                    ""data"": [
                        ""intersection_0.data""
                    ]
                }
            },
            ""output"": {
                ""data"": [
                    ""data""
                ],
                ""model"": [
                    ""model""
                ]
            }
        },
        ""one_hot_1"": {
            ""module"": ""OneHotEncoder"",
            ""input"": {
                ""data"": {
                    ""data"": [
                        ""intersection_1.data""
                    ]
                },
                ""model"": [
                    ""one_hot_0.model""
                ]
            },
            ""output"": {
                ""data"": [
                    ""data""
                ],
                ""model"": [
                    ""model""
                ]
            }
        },你好，我使用过横向onehot--‘’Homo_OneHot_Encoder‘’，跟你的处理一样，测试集单独onehot_1，输入数据集为测试数据集及onehot_0的model，特征可以保持一致。同时也会存在问题，测试集单独onehot_1的得到的特征同训练集onehot_0一致，但onehot_1之后out_put的数据全是0。很奇怪，希望有人能解答一下。他的逻辑是没有问题的，fate会把训练集onehot之后的特征记录下来，测试集只需和训练集保持一致即可> 他的逻辑是没有问题的，fate会把训练集onehot之后的特征记录下来，测试集只需和训练集保持一致即可

如果测试集里有的特征值在训练集里是没有的呢，比如城市，训练集里有上海、北京、深圳，训练集onehot之后扩展出来的特征列是city_上海，city_北京，city_深圳，那测试集里出现城市是成都的呢？

难道必须要保证测试集里的特征值不要超出训练集里包含的取值吗？这样数据准备很麻烦啊


> > 他的逻辑是没有问题的，fate会把训练集onehot之后的特征记录下来，测试集只需和训练集保持一致即可
> 
> 如果测试集里有的特征值在训练集里是没有的呢，比如城市，训练集里有上海、北京、深圳，训练集onehot之后扩展出来的特征列是city_上海，city_北京，city_深圳，那测试集里出现城市是成都的呢？
> 
> 难道必须要保证测试集里的特征值不要超出训练集里包含的取值吗？这样数据准备很麻烦啊

你说的这个问题的话，即使加进了验证数据，未来遇到真实预测数据的时候，一样有可能遇到从未出现的值，这个无法避免的。现在的逻辑是，如果测试集出现训练集没有的值，则转化的所有值都为0."	4	2021-03-10 15:22:18	2021-07-02 08:14:41	2021-07-02 08:14:41
https://github.com/FederatedAI/FATE/issues/2452	[]	线性回归模型在线测试无预测结果	"线性回归模型在线测试无预测结果host.csv数据
`id,x1
1,1
2,2
3,3
4,4
5,5
6,6
7,7
8,8`
guest.csv数据
`id,y,x0
1,1,0
2,2,1
3,3,0
4,4,1`
job_conf.json
```
{
    ""initiator"": {
        ""role"": ""guest"",
        ""party_id"": 9999
    },
    ""job_parameters"": {
        ""work_mode"": 1
    },
    ""role"": {
        ""guest"": [
            9999
        ],
        ""host"": [
            10000
        ],
        ""arbiter"": [
            10000
        ]
    },
    ""role_parameters"": {
        ""guest"": {
            ""args"": {
                ""data"": {
                    ""train_data"": [
                        {
                            ""name"": ""test"",
                            ""namespace"": ""test""
                        }
                    ]
                }
            },
            ""dataio_0"": {
                ""with_label"": [
                    true
                ],
                ""label_name"": [
                    ""y""
                ],
                ""label_type"": [
                    ""float""
                ],
                ""output_format"": [
                    ""dense""
                ],
                ""missing_fill"": [
                    true
                ],
                ""outlier_replace"": [
                    false
                ]
            },
            ""evaluation_0"": {
                ""eval_type"": [
                    ""regression""
                ],
                ""pos_label"": [
                    1
                ]
            }
        },
        ""host"": {
            ""args"": {
                ""data"": {
                    ""train_data"": [
                        {
                            ""name"": ""test"",
                            ""namespace"": ""test""
                        }
                    ]
                }
            },
            ""dataio_0"": {
                ""with_label"": [
                    false
                ],
                ""output_format"": [
                    ""dense""
                ],
                ""outlier_replace"": [
                    false
                ]
            },
            ""evaluation_0"": {
                ""need_run"": [
                    false
                ]
            }
        }
    },
    ""algorithm_parameters"": {
        ""hetero_linr_0"": {
            ""penalty"": ""L2"",
            ""optimizer"": ""sgd"",
            ""tol"": 0.001,
            ""alpha"": 0.01,
            ""max_iter"": 20,
            ""early_stop"": ""weight_diff"",
            ""batch_size"": -1,
            ""learning_rate"": 0.15,
            ""decay"": 0.0,
            ""decay_sqrt"": false,
            ""init_param"": {
                ""init_method"": ""zeros""
            },
            ""encrypted_mode_calculator_param"": {
                ""mode"": ""fast""
            }
        }
    }
}
```
dsl_conf.json
`{
    ""components"" : {
        ""dataio_0"": {
            ""module"": ""DataIO"",
            ""input"": {
                ""data"": {
                    ""data"": [
                        ""args.train_data""
                    ]
                }
            },
            ""output"": {
                ""data"": [""train""],
                ""model"": [""dataio""]
            }
         },
         ""intersection_0"": {
             ""module"": ""Intersection"",
             ""input"": {
                 ""data"": {
                     ""data"": [
                         ""dataio_0.train""
                     ]
                 }
             },
             ""output"": {
                 ""data"": [""train""]
             }
         },
        ""hetero_linr_0"": {
            ""module"": ""HeteroLinR"",
            ""input"": {
                ""data"": {
                    ""train_data"": [""intersection_0.train""]
                }
            },
            ""output"": {
                ""data"": [""train""],
                ""model"": [""hetero_linr""]
            }
        },
        ""evaluation_0"": {
            ""module"": ""Evaluation"",
            ""input"": {
                ""data"": {
                    ""data"": [""hetero_linr_0.train""]
                }
            }
        }
    }
}`
调用在线推理接口
curl -X POST -H 'Content-Type: application/json' -i 'http://localhost:8059/federation/v1/inference' --data '{
  ""head"": {
    ""serviceId"": ""test""
  },
  ""body"": {
    ""featureData"": {
      ""x0"": 1
    },
    ""sendToRemoteFeatureData"": {
      ""id"": ""5""
    }
  }
}'
预测结果
{
    ""retcode"": 0,
    ""retmsg"": """",
    ""data"": {
        ""modelId"": ""guest#9999#arbiter-10000#guest-9999#host-10000#model"",
        ""modelVersion"": ""2021010412180273130115"",
        ""timestamp"": 1609809836490
    },
    ""flag"": 0
}
无预测结果值，是线性回归算法的bug吗Serving目前不支持线性模型。所有支持的算法组件请参考：https://github.com/FederatedAI/FATE-Serving/tree/master/fate-serving-federatedml/src/main/java/com/webank/ai/fate/serving/federatedml/model 

Serving currently does not support online inference with HeteroLinR model. For supported modules, please refer here:  https://github.com/FederatedAI/FATE-Serving/tree/master/fate-serving-federatedml/src/main/java/com/webank/ai/fate/serving/federatedml/model"	1	2021-01-07 02:46:35	2021-01-15 08:42:48	2021-01-15 08:42:48
https://github.com/FederatedAI/FATE/issues/2449	[]	Pipeline Examples 'Connection refused, Please check if the fate flow service is started'	"Pipeline Examples 'Connection refused, Please check if the fate flow service is started'Hi there,

I am interested in using FATE to do some research problems. 

I used the Stand-alone Deployment Guide with docker  environment successfully. 

Unfortunately, when I try to execute the command in the demo folder below:
root@e7e3434e58b1:/fate/examples/pipeline/demo# python pipeline-upload.py -base /fate

I got these error informations below:
2021-01-06 08:47:03.424 | ERROR    | __main__:main:63 - An error has been caught in function 'main', process 'MainProcess' (369), thread 'MainThread' (139780264617792):
Traceback (most recent call last):

  File ""/usr/local/lib/python3.6/site-packages/pipeline/utils/invoker/job_submitter.py"", line 105, in upload_data
    raise ValueError

ValueError


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File ""pipeline-upload.py"", line 73, in <module>
    main(args.base)
    │    │    └ '/fate'
    │    └ Namespace(base='/fate')
    └ <function main at 0x7f2120e02e18>

> File ""pipeline-upload.py"", line 63, in main
    pipeline_upload.upload(work_mode=work_mode, backend=backend, drop=1)
    │               │                │                  └ <Backend.EGGROLL: 0>
    │               │                └ <WorkMode.STANDALONE: 0>
    │               └ <function PipeLine.upload at 0x7f20e9652950>
    └ <pipeline.backend.pipeline.PipeLine object at 0x7f20e9643b00>

  File ""/usr/local/lib/python3.6/site-packages/pipeline/backend/pipeline.py"", line 495, in upload
    self._train_job_id, detail_info = self._job_invoker.upload_data(upload_conf, int(drop))
    │    │                            │    │            │           │                └ 1
    │    │                            │    │            │           └ {'file': '/fate/examples/data/breast_hetero_guest.csv', 'table_name': 'breast_hetero_guest', 'namespace': 'experiment', 'head...
    │    │                            │    │            └ <function JobInvoker.upload_data at 0x7f20e96482f0>
    │    │                            │    └ <pipeline.utils.invoker.job_submitter.JobInvoker object at 0x7f20e9643ac8>
    │    │                            └ <pipeline.backend.pipeline.PipeLine object at 0x7f20e9643b00>
    │    └ None
    └ <pipeline.backend.pipeline.PipeLine object at 0x7f20e9643b00>
  File ""/usr/local/lib/python3.6/site-packages/pipeline/utils/invoker/job_submitter.py"", line 113, in upload_data
    raise ValueError(""job submit failed, err msg: {}"".format(result))
                                                             └ {'retcode': 100, 'retmsg': 'Connection refused, Please check if the fate flow service is started'}

ValueError: job submit failed, err msg: {'retcode': 100, 'retmsg': 'Connection refused, Please check if the fate flow service is started'}
Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/site-packages/pipeline/utils/invoker/job_submitter.py"", line 105, in upload_data
    raise ValueError
ValueError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""pipeline-upload.py"", line 73, in <module>
    main(args.base)
  File ""pipeline-upload.py"", line 63, in main
    pipeline_upload.upload(work_mode=work_mode, backend=backend, drop=1)
  File ""/usr/local/lib/python3.6/site-packages/loguru/_logger.py"", line 1220, in catch_wrapper
    return function(*args, **kwargs)
  File ""/usr/local/lib/python3.6/site-packages/pipeline/backend/pipeline.py"", line 495, in upload
    self._train_job_id, detail_info = self._job_invoker.upload_data(upload_conf, int(drop))
  File ""/usr/local/lib/python3.6/site-packages/pipeline/utils/invoker/job_submitter.py"", line 113, in upload_data
    raise ValueError(""job submit failed, err msg: {}"".format(result))
ValueError: job submit failed, err msg: {'retcode': 100, 'retmsg': 'Connection refused, Please check if the fate flow service is started'}


Any suggestions are welcome.
Thanks
When initialize pipeline ""pipeline init --ip 127.0.0.1 --port 9380"",
change 127.0.0.1 to the contianer ip,  such as ""192.167.1.100""
It works for me.Find your contianer ip as follow
![image](https://user-images.githubusercontent.com/14838533/103766154-4d0de600-5059-11eb-82ba-1059aa453419.png)
> Find your contianer ip as follow
> ![image](https://user-images.githubusercontent.com/14838533/103766154-4d0de600-5059-11eb-82ba-1059aa453419.png)

Yes, it works! Thanks soooo much."	3	2021-01-06 08:53:33	2021-01-06 12:05:02	2021-01-06 12:05:02
https://github.com/FederatedAI/FATE/issues/2440	[]	为什么按照案例跑不起来	"为什么按照案例跑不起来做了个简单的LR 两份数据上传成功
# python /home/fate/standalone-fate-master-1.5.0/python/fate_flow/fate_flow_client.py -f table_info -n experiment -t breast_hetero_host
{
    ""data"": {
        ""count"": 570,
        ""namespace"": ""experiment"",
        ""partition"": 1,
        ""schema"": {
            ""header"": ""x0,x1,x2,x3,x4,x5,x6,x7,x8,x9,x10,x11,x12,x13,x14,x15,x16,x17,x18,x19"",
            ""sid"": ""id""
        },
        ""table_name"": ""breast_hetero_host""
    },
    ""retcode"": 0,
    ""retmsg"": ""success""
}

# python /home/fate/standalone-fate-master-1.5.0/python/fate_flow/fate_flow_client.py -f table_info -n experiment -t breast_hetero_guest
{
    ""data"": {
        ""count"": 570,
        ""namespace"": ""experiment"",
        ""partition"": 1,
        ""schema"": {
            ""header"": ""y,x0,x1,x2,x3,x4,x5,x6,x7,x8,x9"",
            ""sid"": ""id""
        },
        ""table_name"": ""breast_hetero_guest""
    },
    ""retcode"": 0,
    ""retmsg"": ""success""
}

conf文件如下，没有改，直接从文件中拿的
{
    ""initiator"": {
        ""role"": ""guest"",
        ""party_id"": 10000
    },
    ""job_parameters"": {
        ""work_mode"": 0
    },
    ""role"": {
        ""guest"": [
            10000
        ],
        ""host"": [
            10000
        ],
        ""arbiter"": [
            10000
        ]
    },
    ""role_parameters"": {
        ""guest"": {
            ""args"": {
                ""data"": {
                    ""train_data"": [
                        {
                            ""name"": ""breast_hetero_guest"",
                            ""namespace"": ""experiment""
                        }
                    ],
                    ""eval_data"": [
                        {
                            ""name"": ""breast_hetero_guest"",
                            ""namespace"": ""experiment""
                        }
                    ]
                }
            },
            ""dataio_0"": {
                ""with_label"": [
                    true
                ],
                ""label_name"": [
                    ""y""
                ],
                ""label_type"": [
                    ""int""
                ],
                ""output_format"": [
                    ""dense""
                ],
                ""missing_fill"": [
                    true
                ],
                ""outlier_replace"": [
                    true
                ]
            },
            ""evaluation_0"": {
                ""eval_type"": [
                    ""binary""
                ],
                ""pos_label"": [
                    1
                ]
            }
        },
        ""host"": {
            ""args"": {
                ""data"": {
                    ""train_data"": [
                        {
                            ""name"": ""breast_hetero_host"",
                            ""namespace"": ""experiment""
                        }
                    ],
                    ""eval_data"": [
                        {
                            ""name"": ""breast_hetero_host"",
                            ""namespace"": ""experiment""
                        }
                    ]
                }
            },
            ""dataio_0"": {
                ""with_label"": [
                    false
                ],
                ""output_format"": [
                    ""dense""
                ],
                ""outlier_replace"": [
                    true
                ]
            },
            ""evaluation_0"": {
                ""need_run"": [
                    false
                ]
            }
        }
    },
    ""algorithm_parameters"": {
        ""hetero_lr_0"": {
            ""penalty"": ""L2"",
            ""optimizer"": ""rmsprop"",
            ""tol"": 0.0001,
            ""alpha"": 0.01,
            ""max_iter"": 30,
            ""early_stop"": ""diff"",
            ""batch_size"": -1,
            ""learning_rate"": 0.15,
            ""init_param"": {
                ""init_method"": ""zeros""
            },
            ""sqn_param"": {
                ""update_interval_L"": 3,
                ""memory_M"": 5,
                ""sample_size"": 5000,
                ""random_seed"": null
            },
            ""cv_param"": {
                ""n_splits"": 5,
                ""shuffle"": false,
                ""random_seed"": 103,
                ""need_cv"": false
            }
        },
        ""intersect_0"": {
            ""intersect_method"": ""rsa"",
            ""sync_intersect_ids"": true,
            ""only_output_key"": false
        }
    }
}

dsl文件也是
{
    ""components"" : {
        ""dataio_0"": {
            ""module"": ""DataIO"",
            ""input"": {
                ""data"": {
                    ""data"": [
                        ""args.train_data""
                    ]
                }
            },
            ""output"": {
                ""data"": [""train""],
                ""model"": [""dataio""]
            }
         },
         ""intersection_0"": {
             ""module"": ""Intersection"",
             ""input"": {
                 ""data"": {
                     ""data"": [
                         ""dataio_0.train""
                     ]
                 }
             },
             ""output"": {
                 ""data"": [""train""]
             }
         },
        ""hetero_lr_0"": {
            ""module"": ""HeteroLR"",
            ""input"": {
                ""data"": {
                    ""train_data"": [""intersection_0.train""]
                }
            },
            ""output"": {
                ""data"": [""train""],
                ""model"": [""hetero_lr""]
            }
        },
        ""evaluation_0"": {
            ""module"": ""Evaluation"",
            ""input"": {
                ""data"": {
                    ""data"": [""hetero_lr_0.train""]
                }
            }
        }
    }
}

运行后日志报错

[ERROR] [2021-01-04 16:58:58,271] [23915:139688257656640] - task_executor.py[line:196]: input data's value is empty, it does not contain a label
2
Traceback (most recent call last):
3
  File ""./fate/python/fate_flow/operation/task_executor.py"", line 174, in run_task
4
    run_object.run(component_parameters_on_party, task_run_args)
5
  File ""./fate/python/federatedml/model_base.py"", line 98, in run
6
    this_data_output = func(*real_param)
7
  File ""./fate/python/federatedml/util/data_io.py"", line 885, in fit
8
    data_inst = self.reader.read_data(data_inst, ""fit"")
9
  File ""./fate/python/federatedml/util/data_io.py"", line 133, in read_data
10
    raise ValueError(""input data's value is empty, it does not contain a label"")
11
ValueError: input data's value is empty, it does not contain a label

大神们帮帮我吧，菜鸟一个 ，只想先按照文档运行成功一次已解决 ，是数据文件的问题，直接copy整个文件 就解决了你好，我和你同样的问题，都是： input data's value is empty, it does not contain a label
我之前都能运行成功，但不知道我动了哪里，现在每次提交任务后都显示这样的失败结果
我目前从新上传了数据还是这样
请问是配置文件的问题吗你好，我和你同样的问题，都是： input data's value is empty, it does not contain a label
我之前都能运行成功，但不知道我动了哪里，现在每次提交任务后都显示这样的失败结果
我目前从新上传了数据还是这样
请问是配置文件的问题吗> 你好，我和你同样的问题，都是： input data's value is empty, it does not contain a label
> 我之前都能运行成功，但不知道我动了哪里，现在每次提交任务后都显示这样的失败结果
> 我目前从新上传了数据还是这样
> 请问是配置文件的问题吗

就是数据格式的原因，你用包里的案例中的数据 验证下"	4	2021-01-04 09:48:45	2021-05-15 15:13:10	2021-01-05 05:55:23
https://github.com/FederatedAI/FATE/issues/2423	[]	Fate1.5版本交集组件报错(get_commit_id)	"Fate1.5版本交集组件报错(get_commit_id)**Describe the bug**
Fate1.5版本读取HDFS文件，执行纵向逻辑回归的交集组件时报错
ImportError: cannot import name 'get_commit_id'
![image](https://user-images.githubusercontent.com/41407129/103127635-7c256e80-46cd-11eb-9de4-41165bce61df.png)


经过分析源码，确实没有定义该方法。
通过修改代码，组件能够正常跑通。请官方更新代码。
base_utils.py文件增加方法定义：
def get_commit_id():
    # the model may be larger, SHA1 is not used
    return fate_uuid()

![image](https://user-images.githubusercontent.com/5196427/103132597-3920c680-46e0-11eb-9331-193abf7c2497.png)
Please check to see if your code is in release 1.5.0.
Incorrect code may have other problems."	1	2020-12-25 08:24:16	2021-04-23 02:55:11	2021-04-23 02:55:11
https://github.com/FederatedAI/FATE/issues/2412	[]	集群部署的情况下，跑quick测试，任务创建成功之后一直wait	"集群部署的情况下，跑quick测试，任务创建成功之后一直wait**Describe the bug**
FATE集群部署的情况下，单边测试和双边测试都跑过了，但是quick测试，可以创建job，然后之后一直是wait，查看日志说是向eggroll申请资源失败，请赐教怎么解决谢谢

![image](https://user-images.githubusercontent.com/48507141/102451934-6d5b0e00-4074-11eb-9d7c-68578307051d.png)

我这边也是这个问题，请问您解决了吗：
""f_status"": ""success"",
            ""f_status_code"": null,
            ""f_status"": ""waiting"",
            ""f_status_code"": null,
            ""f_status"": ""waiting"",
            ""f_status_code"": null,
            ""f_status"": ""success"",
            ""f_status_code"": null,
            ""f_status"": ""waiting"",
            ""f_status_code"": null,
            ""f_status"": ""success"",
            ""f_status_code"": null,
            ""f_status"": ""waiting"",
            ""f_status_code"": null,
            ""f_status"": ""success"",
            ""f_status_code"": null,
            ""f_status"": ""waiting"",
            ""f_status_code"": null,
            ""f_status"": ""waiting"",
            ""f_status_code"": null,
            ""f_status"": ""success"",
            ""f_status_code"": null,
            ""f_status"": ""waiting"",
            ""f_status_code"": null,
            ""f_status"": ""success"",
            ""f_status_code"": null,
            ""f_status"": ""waiting"",
            ""f_status_code"": null,
            ""f_status"": ""success"",
            ""f_status_code"": null,
            ""f_status"": ""waiting"",
            ""f_status_code"": null,
> 我这边也是这个问题，请问您解决了吗：
> ""f_status"": ""success"",
> ""f_status_code"": null,
> ""f_status"": ""waiting"",
> ""f_status_code"": null,
> ""f_status"": ""waiting"",
> ""f_status_code"": null,
> ""f_status"": ""success"",
> ""f_status_code"": null,
> ""f_status"": ""waiting"",
> ""f_status_code"": null,
> ""f_status"": ""success"",
> ""f_status_code"": null,
> ""f_status"": ""waiting"",
> ""f_status_code"": null,
> ""f_status"": ""success"",
> ""f_status_code"": null,
> ""f_status"": ""waiting"",
> ""f_status_code"": null,
> ""f_status"": ""waiting"",
> ""f_status_code"": null,
> ""f_status"": ""success"",
> ""f_status_code"": null,
> ""f_status"": ""waiting"",
> ""f_status_code"": null,
> ""f_status"": ""success"",
> ""f_status_code"": null,
> ""f_status"": ""waiting"",
> ""f_status_code"": null,
> ""f_status"": ""success"",
> ""f_status_code"": null,
> ""f_status"": ""waiting"",
> ""f_status_code"": null,

我当时是因为在虚拟机部署的集群，跳过了128G交换空间的分配，在配置足够的真实机器上部署，没出现这个问题好的，谢谢了




------------------&nbsp;原始邮件&nbsp;------------------
发件人: ""HunDeMingMingBaiBai""<notifications@github.com&gt;; 
发送时间: 2021年1月25日(星期一) 下午4:37
收件人: ""FederatedAI/FATE""<FATE@noreply.github.com&gt;; 
抄送: ""李因新""<1034113547@qq.com&gt;; ""Comment""<comment@noreply.github.com&gt;; 
主题: Re: [FederatedAI/FATE] 集群部署的情况下，跑quick测试，任务创建成功之后一直wait (#2412)





  
我这边也是这个问题，请问您解决了吗：
 ""f_status"": ""success"",
 ""f_status_code"": null,
 ""f_status"": ""waiting"",
 ""f_status_code"": null,
 ""f_status"": ""waiting"",
 ""f_status_code"": null,
 ""f_status"": ""success"",
 ""f_status_code"": null,
 ""f_status"": ""waiting"",
 ""f_status_code"": null,
 ""f_status"": ""success"",
 ""f_status_code"": null,
 ""f_status"": ""waiting"",
 ""f_status_code"": null,
 ""f_status"": ""success"",
 ""f_status_code"": null,
 ""f_status"": ""waiting"",
 ""f_status_code"": null,
 ""f_status"": ""waiting"",
 ""f_status_code"": null,
 ""f_status"": ""success"",
 ""f_status_code"": null,
 ""f_status"": ""waiting"",
 ""f_status_code"": null,
 ""f_status"": ""success"",
 ""f_status_code"": null,
 ""f_status"": ""waiting"",
 ""f_status_code"": null,
 ""f_status"": ""success"",
 ""f_status_code"": null,
 ""f_status"": ""waiting"",
 ""f_status_code"": null,
  
我当时是因为在虚拟机部署的集群，跳过了128G交换空间的分配，在配置足够的真实机器上部署，没出现这个问题
 
—
You are receiving this because you commented.
Reply to this email directly, view it on GitHub, or unsubscribe."	3	2020-12-17 06:30:54	2021-03-19 10:41:58	2021-03-19 10:41:58
https://github.com/FederatedAI/FATE/issues/2345	[]	求大佬告知应该如何写预测请求	"求大佬告知应该如何写预测请求**Is your feature request related to a problem? Please describe.**
A clear and concise description of what the problem is. Ex. I'm always frustrated when [...]

**Describe the solution you'd like**
A clear and concise description of what you want to happen.

**Describe alternatives you've considered**
A clear and concise description of any alternative solutions or features you've considered.

**Additional context**
Add any other context or screenshots about the feature request here.

对于随便写官网案例能出结果，自己写请求全是RPC105错误
![image](https://user-images.githubusercontent.com/40295475/99971016-9969d300-2dd7-11eb-9034-6c612273aed8.png)


![image](https://user-images.githubusercontent.com/40295475/99971105-b7cfce80-2dd7-11eb-9eb2-28a0b69e99c6.png)
一旦自己写预测请求就出错
![image](https://user-images.githubusercontent.com/40295475/99971321-f82f4c80-2dd7-11eb-8a41-f92c96a94e96.png)
对于预测文件，我按照官网的格式，无法预测secureboost模型，求大佬告知如何预测
![image](https://user-images.githubusercontent.com/40295475/99971581-552b0280-2dd8-11eb-8070-0469d412ab36.png)
nothing"	3	2020-11-23 14:03:35	2020-11-25 06:25:55	2020-11-25 06:25:41
https://github.com/FederatedAI/FATE/issues/2332	[]	Fate 1.5 run /fate_flow/examples/test_predict_conf.json	"Fate 1.5 run /fate_flow/examples/test_predict_conf.jsonwhen run this command 
```
python /data/projects/fate/python/fate_flow/fate_flow_client.py -f submit_job -c /data/projects/fate/python/fate_flow/examples/test_predict_conf.json
```

i get below error
```
{
    ""retcode"": 100,
    ""retmsg"": ""__init__() missing 1 required positional argument: 'msg'""
}

```


content of test_predict_conf.json
```
{
    ""initiator"": {
        ""role"": ""guest"",
        ""party_id"": 9999
    },
    ""job_parameters"": {
        ""work_mode"": 1,
        ""job_type"": ""predict"",
        ""model_id"": ""arbiter-10000#guest-9999#host-9998#model"",
        ""model_version"": ""202011180908219381005"",
        ""dsl_version"": ""2""
    },
    ""role"": {
        ""guest"": [9999],
        ""host"": [9998],
        ""arbiter"": [10000]
    },
    ""role_parameters"": {
        ""guest"": {
            ""0"": {
                ""reader_0"": {
                    ""table"": {""name"": ""breast_hetero_guest"", ""namespace"": ""experiment""}
                },
                ""dataio_0"":{
                    ""with_label"": true,
                    ""label_name"": ""y"",
                    ""label_type"": ""int"",
                    ""output_format"": ""dense""
                }
            }
        },
        ""host"": {
            ""0"": {
                ""reader_0"": {
                    ""table"": {""name"": ""breast_hetero_host"", ""namespace"": ""experiment""}
                },
                ""dataio_0"":{
                    ""with_label"": false,
                    ""output_format"": ""dense""
                }
            }
        }
    }
}
```

for your info, i have no issue run on 1.4.3@cometta There exists some errors in ""job_parameter"" part of your conf file. Please refer to this doc for more details:
https://github.com/FederatedAI/FATE/blob/master/examples/experiment_template/user_usage/dsl_v2_predict_tutorial.md@tanmc123 thanks, i read through the link you shared but can't find any issue with the code. The conf file is from https://github.com/FederatedAI/FATE/blob/master/python/fate_flow/examples/test_predict_conf.json , i only modified model_id, version and the role id. For your info, i did successfully ran similar codes for older version 1.4.3 and below successfully.  Can you elaborate more on what is possibility cause the issue? i am sure the model id, version and role id are correct. @tanmc123 i successfully run https://github.com/FederatedAI/FATE/blob/master/examples/experiment_template/user_usage/dsl_v2_predict_tutorial.md  example, but what about  https://github.com/FederatedAI/FATE/blob/master/python/fate_flow/examples/test_predict_conf.json ? does it still work in 1.5 ?issue resolved after done minor changes to test_predict_conf.json

```
{
    ""dsl_version"": 2,
    ""initiator"": {
        ""role"": ""guest"",
        ""party_id"": 9999
    },
    ""job_parameters"": {
      ""common"":{
        ""work_mode"": 1,
        ""job_type"": ""predict"",
        ""model_id"": ""<id>"",
        ""model_version"": ""<id>"",
        ""dsl_version"": ""2""
     }
    },

```
"	4	2020-11-18 09:21:30	2020-11-19 07:31:25	2020-11-19 07:31:25
https://github.com/FederatedAI/FATE/issues/2325	[]	"使用1.5.0 All in one 部署FATE集群，Mysqld无法启动【2003, ""Can't connect to MySQL server】"	"使用1.5.0 All in one 部署FATE集群，Mysqld无法启动【2003, ""Can't connect to MySQL server】环境：ubuntu18
原本已安装过mysqld，手动停止了原mysql的服务。

在执行`deploy.sh`时，遇到了这样的提示：
```bash
java -XX:+UseG1GC -XX:+PrintGCDetails -XX:+PrintGCDateStamps -Xloggc:logs/eggroll/rollsite.gc.log -Dlog4j.configurationFile=/data/projects/fate/eggroll/conf/log4j2.properties -cp /data/projects/fate/eggroll/lib/*: com.webank.eggroll.core.Bootstrap --bootstraps com.webank.eggroll.rollsite.EggSiteBootstrap -c /data/projects/fate/eggroll/conf/eggroll.properties -p 9370 -s eggroll-host
service start failed
service not running

service not running
service start failed, please check /data/projects/fate/logs/error.log and /data/projects/fate/logs/console.log
service not running
```

errorlog内容如下
```bash
Traceback (most recent call last):
  File ""/data/projects/fate/common/python/venv/lib/python3.6/site-packages/pymysql/connections.py"", line 583, in connect
    **kwargs)
  File ""/data/projects/fate/common/miniconda3/lib/python3.6/socket.py"", line 724, in create_connection
    raise err
  File ""/data/projects/fate/common/miniconda3/lib/python3.6/socket.py"", line 713, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/data/projects/fate/common/python/venv/lib/python3.6/site-packages/peewee.py"", line 2817, in connect
    self._state.set_connection(self._connect())
  File ""/data/projects/fate/common/python/venv/lib/python3.6/site-packages/playhouse/pool.py"", line 155, in _connect
    conn = super(PooledDatabase, self)._connect()
  File ""/data/projects/fate/common/python/venv/lib/python3.6/site-packages/peewee.py"", line 3642, in _connect
    conn = mysql.connect(db=self.database, **self.connect_params)
  File ""/data/projects/fate/common/python/venv/lib/python3.6/site-packages/pymysql/__init__.py"", line 94, in Connect
    return Connection(*args, **kwargs)
  File ""/data/projects/fate/common/python/venv/lib/python3.6/site-packages/pymysql/connections.py"", line 325, in __init__
    self.connect()
  File ""/data/projects/fate/common/python/venv/lib/python3.6/site-packages/pymysql/connections.py"", line 630, in connect
    raise exc
pymysql.err.OperationalError: (2003, ""Can't connect to MySQL server on ''xxx.xxx.xxx.xxx'' ([Errno 111] Connection refused)"")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/data/projects/fate/python/fate_flow/fate_flow_server.py"", line 91, in <module>
    init_flow_db()
  File ""/data/projects/fate/common/python/venv/lib/python3.6/site-packages/peewee.py"", line 393, in inner
    with self:
  File ""/data/projects/fate/common/python/venv/lib/python3.6/site-packages/peewee.py"", line 2724, in __enter__
    self.db.connect()
  File ""/data/projects/fate/common/python/venv/lib/python3.6/site-packages/playhouse/pool.py"", line 108, in connect
    return super(PooledDatabase, self).connect(reuse_if_open)
  File ""/data/projects/fate/common/python/venv/lib/python3.6/site-packages/peewee.py"", line 2820, in connect
    self._initialize_connection(self._state.conn)
  File ""/data/projects/fate/common/python/venv/lib/python3.6/site-packages/peewee.py"", line 2666, in __exit__
    reraise(new_type, new_type(*exc_args), traceback)
  File ""/data/projects/fate/common/python/venv/lib/python3.6/site-packages/peewee.py"", line 179, in reraise
    raise value.with_traceback(tb)
  File ""/data/projects/fate/common/python/venv/lib/python3.6/site-packages/peewee.py"", line 2817, in connect
    self._state.set_connection(self._connect())
  File ""/data/projects/fate/common/python/venv/lib/python3.6/site-packages/playhouse/pool.py"", line 155, in _connect
    conn = super(PooledDatabase, self)._connect()
  File ""/data/projects/fate/common/python/venv/lib/python3.6/site-packages/peewee.py"", line 3642, in _connect
    conn = mysql.connect(db=self.database, **self.connect_params)
  File ""/data/projects/fate/common/python/venv/lib/python3.6/site-packages/pymysql/__init__.py"", line 94, in Connect
    return Connection(*args, **kwargs)
  File ""/data/projects/fate/common/python/venv/lib/python3.6/site-packages/pymysql/connections.py"", line 325, in __init__
    self.connect()
  File ""/data/projects/fate/common/python/venv/lib/python3.6/site-packages/pymysql/connections.py"", line 630, in connect
    raise exc
peewee.OperationalError: (2003, ""Can't connect to MySQL server on ''xxx.xxx.xxx.xxx'' ([Errno 111] Connection refused)"")
Traceback (most recent call last):
  File ""/data/projects/fate/common/python/venv/lib/python3.6/site-packages/pymysql/connections.py"", line 583, in connect
    **kwargs)
  File ""/data/projects/fate/common/miniconda3/lib/python3.6/socket.py"", line 724, in create_connection
    raise err
  File ""/data/projects/fate/common/miniconda3/lib/python3.6/socket.py"", line 713, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/data/projects/fate/common/python/venv/lib/python3.6/site-packages/peewee.py"", line 2817, in connect
    self._state.set_connection(self._connect())
  File ""/data/projects/fate/common/python/venv/lib/python3.6/site-packages/playhouse/pool.py"", line 155, in _connect
    conn = super(PooledDatabase, self)._connect()
  File ""/data/projects/fate/common/python/venv/lib/python3.6/site-packages/peewee.py"", line 3642, in _connect
    conn = mysql.connect(db=self.database, **self.connect_params)
  File ""/data/projects/fate/common/python/venv/lib/python3.6/site-packages/pymysql/__init__.py"", line 94, in Connect
    return Connection(*args, **kwargs)
  File ""/data/projects/fate/common/python/venv/lib/python3.6/site-packages/pymysql/connections.py"", line 325, in __init__
    self.connect()
  File ""/data/projects/fate/common/python/venv/lib/python3.6/site-packages/pymysql/connections.py"", line 630, in connect
    raise exc
pymysql.err.OperationalError: (2003, ""Can't connect to MySQL server on 'xxx.xxx.xxx.xxx' ([Errno 111] Connection refused)"")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/data/projects/fate/python/fate_flow/fate_flow_server.py"", line 91, in <module>
    init_flow_db()
  File ""/data/projects/fate/common/python/venv/lib/python3.6/site-packages/peewee.py"", line 393, in inner
    with self:
  File ""/data/projects/fate/common/python/venv/lib/python3.6/site-packages/peewee.py"", line 2724, in __enter__
    self.db.connect()
  File ""/data/projects/fate/common/python/venv/lib/python3.6/site-packages/playhouse/pool.py"", line 108, in connect
    return super(PooledDatabase, self).connect(reuse_if_open)
  File ""/data/projects/fate/common/python/venv/lib/python3.6/site-packages/peewee.py"", line 2820, in connect
    self._initialize_connection(self._state.conn)
  File ""/data/projects/fate/common/python/venv/lib/python3.6/site-packages/peewee.py"", line 2666, in __exit__
    reraise(new_type, new_type(*exc_args), traceback)
  File ""/data/projects/fate/common/python/venv/lib/python3.6/site-packages/peewee.py"", line 179, in reraise
    raise value.with_traceback(tb)
  File ""/data/projects/fate/common/python/venv/lib/python3.6/site-packages/peewee.py"", line 2817, in connect
    self._state.set_connection(self._connect())
  File ""/data/projects/fate/common/python/venv/lib/python3.6/site-packages/playhouse/pool.py"", line 155, in _connect
    conn = super(PooledDatabase, self)._connect()
  File ""/data/projects/fate/common/python/venv/lib/python3.6/site-packages/peewee.py"", line 3642, in _connect
    conn = mysql.connect(db=self.database, **self.connect_params)
  File ""/data/projects/fate/common/python/venv/lib/python3.6/site-packages/pymysql/__init__.py"", line 94, in Connect
    return Connection(*args, **kwargs)
  File ""/data/projects/fate/common/python/venv/lib/python3.6/site-packages/pymysql/connections.py"", line 325, in __init__
    self.connect()
  File ""/data/projects/fate/common/python/venv/lib/python3.6/site-packages/pymysql/connections.py"", line 630, in connect
    raise exc
peewee.OperationalError: (2003, ""Can't connect to MySQL server on 'xxx.xxx.xxx.xxx' ([Errno 111] Connection refused)"")

```
mysqld.log内容如下
```
2020-11-13T09:14:03.945889Z mysqld_safe Logging to '/data/projects/fate/common/mysql/mysql-8.0.13/logs/mysqld.log'.
2020-11-13T09:14:03.994002Z mysqld_safe Starting mysqld daemon with databases from /data/projects/fate/data/mysql
2020-11-13T09:14:04.987046Z 0 [System] [MY-010116] [Server] /data/projects/fate/common/mysql/mysql-8.0.13/bin/mysqld (mysqld 8.0.13) starting as process 10147
2020-11-13T09:14:04.997328Z 0 [Warning] [MY-013242] [Server] --character-set-server: 'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.
2020-11-13T09:14:05.036838Z 1 [ERROR] [MY-011011] [Server] Failed to find valid data directory.
2020-11-13T09:14:05.037345Z 0 [ERROR] [MY-010020] [Server] Data Dictionary initialization failed.
2020-11-13T09:14:05.037399Z 0 [ERROR] [MY-010119] [Server] Aborting
2020-11-13T09:14:05.038999Z 0 [System] [MY-010910] [Server] /data/projects/fate/common/mysql/mysql-8.0.13/bin/mysqld: Shutdown complete (mysqld 8.0.13)  MySQL Community Server - GPL.
2020-11-13T09:14:05.081642Z mysqld_safe mysqld from pid file /data/projects/fate/common/mysql/mysql-8.0.13/run/mysqld.pid ended
```

经检查，在my.cnf里头实际上是有
`basedir=/data/projects/fate/common/mysql/mysql-8.0.13`
`datadir=/data/projects/fate/data/mysql`
经检查该路径存在
ls /data/projects/fate/data/mysql
仅有一个文件`binlog.index`

尝试使用了`sudo bin/mysqld --initialize-insecure --user=xxx`指令,无果。不使用sudo结果相同，没有错误提示，也没有变好。
虽然用户名用的不是app，但是权限是按照前文的要求设置的，并且改动了init和deploy脚本里头
`--user=app`的内容。workaround：
apt-get 卸载掉原先安装的mysql
另外后续会因为本机装过openjdk11而再报一个不能启动jvm的错误
卸载后也能暂时解决这个问题请问，这里说的All in one是指KubeFATE吗？> 请问，这里说的All in one是指KubeFATE吗？

不是，native部署方式。> > 请问，这里说的All in one是指KubeFATE吗？
> 
> 不是，native部署方式。

按照cluster方式部署，可以指定每台机器的IP而不是使用系统默认的192.168.0.x的IP吗？
我看部署脚本里还有192.168.0.88和192.168.0.99，是不是至少需要四台机器，才可以配集群？你怎么解决的啊，我也遇到同样的问题。卸了原装MYSQL，只用集成的。



------------------&nbsp;原始邮件&nbsp;------------------
发件人: ""WOW""<notifications@github.com&gt;; 
发送时间: 2021年1月12日(星期二) 下午3:47
收件人: ""FederatedAI/FATE""<FATE@noreply.github.com&gt;; 
抄送: ""倪彧祺""<nnnnnn_2657@qq.com&gt;; ""State change""<state_change@noreply.github.com&gt;; 
主题: Re: [FederatedAI/FATE] 使用1.5.0 All in one 部署FATE集群，Mysqld无法启动【2003, &quot;Can&#39;t connect to MySQL server】 (#2325)





 
你怎么解决的啊，我也遇到同样的问题。
 
—
You are receiving this because you modified the open/close state.
Reply to this email directly, view it on GitHub, or unsubscribe.> 卸了原装MYSQL，只用集成的。
> […](#)
> ------------------&nbsp;原始邮件&nbsp;------------------ 发件人: ""WOW""<notifications@github.com&gt;; 发送时间: 2021年1月12日(星期二) 下午3:47 收件人: ""FederatedAI/FATE""<FATE@noreply.github.com&gt;; 抄送: ""倪彧祺""<nnnnnn_2657@qq.com&gt;; ""State change""<state_change@noreply.github.com&gt;; 主题: Re: [FederatedAI/FATE] 使用1.5.0 All in one 部署FATE集群，Mysqld无法启动【2003, &quot;Can&#39;t connect to MySQL server】 (#2325) 你怎么解决的啊，我也遇到同样的问题。 — You are receiving this because you modified the open/close state. Reply to this email directly, view it on GitHub, or unsubscribe.

谢谢回复，不过还是不行啊，还是遇到同样的问题，郁闷啊。我用的是kubefate在多个机器上安装的。我遇到了同样的问题：
pymysql.err.OperationalError: (2003, ""Can't connect to MySQL server on  ‘my ip’  (timed out)"")
peewee.OperationalError: (2003, ""Can't connect to MySQL server on ‘my ip’  (timed out)"")
已经重新卸载mysql 并重新部署安装，查看端口3306正常运行，但是仍出现上述错误。感谢提供解决思路！
![image](https://user-images.githubusercontent.com/17609160/124580809-14718c80-de83-11eb-95c7-b9ce16dcb53f.png)
> 我遇到了同样的问题：
> pymysql.err.OperationalError: (2003, ""Can't connect to MySQL server on ‘my ip’ (timed out)"")
> peewee.OperationalError: (2003, ""Can't connect to MySQL server on ‘my ip’ (timed out)"")
> 已经重新卸载mysql 并重新部署安装，查看端口3306正常运行，但是仍出现上述错误。感谢提供解决思路！
> ![image](https://user-images.githubusercontent.com/17609160/124580809-14718c80-de83-11eb-95c7-b9ce16dcb53f.png)

偶尔也会在部署成功后遇到这类问题
基本上是停止mysqld相关进程、重启服务，懵懵懂懂地恢复了。
不过这里需要强调的是，出现类似问题用service.sh带的stop是不太够的
最好参考一下官方部署文档里用的那些ps -ef清除所有相关进程"	9	2020-11-16 01:18:44	2021-08-03 06:29:12	2020-11-16 08:57:42
https://github.com/FederatedAI/FATE/issues/2082	[]	Failed to release resource after fate_flow server crashed	"Failed to release resource after fate_flow server crashed**Describe the bug**
The `nodemanager` fails to release `roll_pair.py` process after fate_flow server crashed.

**To Reproduce**
Steps to reproduce the behavior:
1. Start FATE Cluster
2. Kill fate_flow server without `KeyboardInterrupt`
3. Check process in ""nodemanager"",  the resource occupied by the session will not be released.

**Expected behavior**
Once fate_flow server restart, it should reuse the previous session of delete it before create a new one.
Close the issue cuz fixed in v1.5.1"	1	2020-10-13 09:11:58	2021-06-23 06:23:29	2021-06-23 06:23:29
https://github.com/FederatedAI/FATE/issues/2029	[]	逻辑回归对稀疏数据的训练结果很差	"逻辑回归对稀疏数据的训练结果很差**求大佬指点 我运行稀疏数据的时候 效果总是很差 一筹莫展 是参数没配置好吗** 





                   ------如果我解决了这个问题我会在这回复的 如果没有回复那就是需要你的帮助 兄弟们 做一下特征处理 训练的结果 就没那么糟糕了  "	1	2020-10-05 14:42:22	2021-03-18 06:16:18	2021-03-18 06:16:18
https://github.com/FederatedAI/FATE/issues/1983	[]	自定义算法的时候，上传错误脚本的缓存好像无法清空	"自定义算法的时候，上传错误脚本的缓存好像无法清空**Describe the bug**
自定义算法运行的时候，在第 1 步：定义此模块将使用的参数对象的时候填错了，修改过后，运行还是报原来的错误，怀疑是缓存的原因。如何清除，运行更新后的参数对象脚本？

**To Reproduce**
```
# 第一次，粗心写错了
[ERROR] [2020-09-25 06:32:31,022] [9:140147291039488] - job_app.py[line:37]: name 'GMMParam' is not defined
Traceback (most recent call last):
  File ""/data/projects/python/venv/lib/python3.6/site-packages/flask/app.py"", line 2292, in wsgi_app
    response = self.full_dispatch_request()
  File ""/data/projects/python/venv/lib/python3.6/site-packages/flask/app.py"", line 1815, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File ""/data/projects/python/venv/lib/python3.6/site-packages/flask/app.py"", line 1718, in handle_user_exception
    reraise(exc_type, exc_value, tb)
  File ""/data/projects/python/venv/lib/python3.6/site-packages/flask/_compat.py"", line 35, in reraise
    raise value
  File ""/data/projects/python/venv/lib/python3.6/site-packages/flask/app.py"", line 1813, in full_dispatch_request
    rv = self.dispatch_request()
  File ""/data/projects/python/venv/lib/python3.6/site-packages/flask/app.py"", line 1799, in dispatch_request
    return self.view_functions[rule.endpoint](**req.view_args)
  File ""/data/projects/fate/python/fate_flow/apps/job_app.py"", line 46, in submit_job
    job_id, job_dsl_path, job_runtime_conf_path, logs_directory, model_info, board_url = JobController.submit_job(request.json)
  File ""/data/projects/fate/python/fate_flow/driver/job_controller.py"", line 94, in submit_job
    train_runtime_conf=train_runtime_conf)
  File ""/data/projects/fate/python/fate_flow/utils/job_utils.py"", line 190, in get_job_dsl_parser
    mode=job_type)
  File ""/data/projects/fate/python/fate_flow/driver/dsl_parser.py"", line 642, in run
    self._init_component_setting(setting_conf_prefix, self.runtime_conf, default_runtime_conf_prefix)
  File ""/data/projects/fate/python/fate_flow/driver/dsl_parser.py"", line 165, in _init_component_setting
    name)
  File ""/data/projects/fate/python/fate_flow/utils/parameter_util.py"", line 41, in override_parameter
    param_obj = getattr(param_module, param_class)()
  File ""/data/projects/fate/python/federatedml/param/hetero_gmm_param.py"", line 78, in __init__
    super(GMMParam, self).__init__()
NameError: name 'GMMParam' is not defined

# 第二次，修改后，还是报第一次的错，但是最后一行super那里已经改过来了
[ERROR] [2020-09-25 07:04:01,956] [9:140147291039488] - job_app.py[line:37]: name 'GMMParam' is not defined
Traceback (most recent call last):
  File ""/data/projects/python/venv/lib/python3.6/site-packages/flask/app.py"", line 2292, in wsgi_app
    response = self.full_dispatch_request()
  File ""/data/projects/python/venv/lib/python3.6/site-packages/flask/app.py"", line 1815, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File ""/data/projects/python/venv/lib/python3.6/site-packages/flask/app.py"", line 1718, in handle_user_exception
    reraise(exc_type, exc_value, tb)
  File ""/data/projects/python/venv/lib/python3.6/site-packages/flask/_compat.py"", line 35, in reraise
    raise value
  File ""/data/projects/python/venv/lib/python3.6/site-packages/flask/app.py"", line 1813, in full_dispatch_request
    rv = self.dispatch_request()
  File ""/data/projects/python/venv/lib/python3.6/site-packages/flask/app.py"", line 1799, in dispatch_request
    return self.view_functions[rule.endpoint](**req.view_args)
  File ""/data/projects/fate/python/fate_flow/apps/job_app.py"", line 46, in submit_job
    job_id, job_dsl_path, job_runtime_conf_path, logs_directory, model_info, board_url = JobController.submit_job(request.json)
  File ""/data/projects/fate/python/fate_flow/driver/job_controller.py"", line 94, in submit_job
    train_runtime_conf=train_runtime_conf)
  File ""/data/projects/fate/python/fate_flow/utils/job_utils.py"", line 190, in get_job_dsl_parser
    mode=job_type)
  File ""/data/projects/fate/python/fate_flow/driver/dsl_parser.py"", line 642, in run
    self._init_component_setting(setting_conf_prefix, self.runtime_conf, default_runtime_conf_prefix)
  File ""/data/projects/fate/python/fate_flow/driver/dsl_parser.py"", line 165, in _init_component_setting
    name)
  File ""/data/projects/fate/python/fate_flow/utils/parameter_util.py"", line 41, in override_parameter
    param_obj = getattr(param_module, param_class)()
  File ""/data/projects/fate/python/federatedml/param/hetero_gmm_param.py"", line 78, in __init__
    super(HeteroGMMParam, self).__init__()
NameError: name 'GMMParam' is not defined
```

**Additional context**
Add any other context about the problem here.
try restart fateflow service"	1	2020-09-25 07:16:15	2020-11-03 09:53:01	2020-11-03 09:53:01
https://github.com/FederatedAI/FATE/issues/1824	[]	version 1.4.4, I can pass the Unit Test, but when I run 'python quick_run.py', get an error	"version 1.4.4, I can pass the Unit Test, but when I run 'python quick_run.py', get an error
when I run 'python quick_run.py', get error:

Upload data config json: {'file': 'examples/data/breast_b.csv', 'head': 1, 'partition': 16, 'work_mode': 0, 'table_name': 'breast_b', 'namespace': 'breast_b_guest'}
stdout:{
    ""retcode"": 100,
    ""retmsg"": ""The file is obtained from the fate flow client machine, but it does not exist, please check the path: /fate/examples/data/breast_b.csv"",
    ""traceback"": [
        ""Traceback (most recent call last):\n"",
        ""  File \""/fate/examples/federatedml-1.x-examples/../../fate_flow/fate_flow_client.py\"", line 298, in <module>\n    response = call_fun(args.function, config_data, dsl_path, config_path)\n"",
        ""  File \""/fate/examples/federatedml-1.x-examples/../../fate_flow/fate_flow_client.py\"", line 183, in call_fun\n    'please check the path: {}'.format(file_name))\n"",
        ""Exception: The file is obtained from the fate flow client machine, but it does not exist, please check the path: /fate/examples/data/breast_b.csv\n""
    ]
}


{
    ""retcode"": 100,
    ""retmsg"": [
        ""Traceback (most recent call last):\n"",
        ""  File \""quick_run.py\"", line 374, in <module>\n    upload_data()\n"",
        ""  File \""quick_run.py\"", line 354, in upload_data\n    upload(GUEST)\n"",
        ""  File \""quick_run.py\"", line 245, in upload\n    stdout = exec_upload_task(json_info, role)\n"",
        ""  File \""quick_run.py\"", line 126, in exec_upload_task\n    \""[Upload task]exec fail, status:{}, stdout:{}\"".format(status, stdout))\n"",
        ""ValueError: [Upload task]exec fail, status:100, stdout:{'retcode': 100, 'retmsg': 'The file is obtained from the fate flow client machine, but it does not exist, please check the path: /fate/examples/data/breast_b.csv', 'traceback': ['Traceback (most recent call last):\\n', '  File \""/fate/examples/federatedml-1.x-examples/../../fate_flow/fate_flow_client.py\"", line 298, in <module>\\n    response = call_fun(args.function, config_data, dsl_path, config_path)\\n', '  File \""/fate/examples/federatedml-1.x-examples/../../fate_flow/fate_flow_client.py\"", line 183, in call_fun\\n    \\'please check the path: {}\\'.format(file_name))\\n', 'Exception: The file is obtained from the fate flow client machine, but it does not exist, please check the path: /fate/examples/data/breast_b.csv\\n']}\n""
    ]
}

I can't find that file, and don't know where to get it.

I made a mistake, it should be generated by myself or using exiting official files."	1	2020-09-07 06:34:30	2020-09-08 04:17:05	2020-09-08 04:15:49
https://github.com/FederatedAI/FATE/issues/1792	[]	官方data文件ionosphere_scale_hetero_host.csv是不是少了label？	"官方data文件ionosphere_scale_hetero_host.csv是不是少了label？跑官方demo中homo_secureboost\test_secureboost_train_binary_with_missing_value_conf.json横向场景时host报了如下错误：
![image](https://user-images.githubusercontent.com/62371712/91927897-3d7a3b80-ed0d-11ea-9cc1-82c7c07fc71b.png)
追溯到源码中的data：ionosphere_scale_hetero_host.csv发现的确不含label列已发现解决方案"	1	2020-09-02 03:13:32	2020-09-02 03:14:43	2020-09-02 03:14:21
https://github.com/FederatedAI/FATE/issues/1699	[]	单机部署时训练超过7k的数据量在hetero-lr组件会出现lmdb.Error	"单机部署时训练超过7k的数据量在hetero-lr组件会出现lmdb.Error**Describe the bug**
使用fate-1.4.2在单机部署时更换进行示例的训练时，小于7k的数据量都可以成功训练和测试，但是更换为大于7k的数据量时在hetero-lr-0组件failed，出现lmdb.Error：mdb_txn_commit:Input/output error 。但是我查看了服务器磁盘空间足够。这应该是什么原因造成的？我使用的数据集是fate/data/default_credit_hetero_guest.csv和default_credit_hetero_host.csv.

>- task_executor.py[line:144]: mdb_txn_commit: Input/output error 
concurrent.futures.process._RemoteTraceback:  
"""""" 
Traceback (most recent call last): 
  File ""/usr/local/lib/python3.6/concurrent/futures/process.py"", line 175, in _process_worker 
    r = call_item.fn(*call_item.args, **call_item.kwargs) 
  File ""/fate/arch/standalone/standalone/eggroll.py"", line 343, in do_join 
    dst_txn.put(k_bytes, serialize(v3)) 
lmdb.Error: mdb_txn_commit: Input/output error 
""""""   
  The above exception was the direct cause of the following exception:
 Traceback (most recent call last): 
 File ""/fate/fate_flow/driver/task_executor.py"", line 135, in run_task 
    run_object.run(component_parameters, task_run_args) 
File ""/fate/federatedml/model_base.py"", line 91, in run 
    this_data_output = func(*params)
File ""/fate/federatedml/linear_model/logistic_regression/hetero_logistic_regression/hetero_lr_guest.py"", line 77, in fit
    self.fit_binary(data_instances, validate_data)
File ""/fate/federatedml/linear_model/logistic_regression/hetero_logistic_regression/hetero_lr_guest.py"", line 123, in fit_binary
    batch_index
File ""/fate/federatedml/optim/gradient/hetero_linear_model_gradient.py"", line 177, in compute_gradient_procedure
    model_weights.fit_intercept)
 File ""/fate/federatedml/optim/gradient/hetero_linear_model_gradient.py"", line 112, in compute_gradient 
    lambda d, g: (d.features, g))
File ""/fate/arch/api/utils/profile_util.py"", line 32, in _fn 
    rtn = func(*args, **kwargs) 
  File ""/fate/arch/api/impl/based_1x/table.py"", line 140, in join 
    return DTable(self._dtable.join(other._dtable, func=func), session_id=self._session_id) 
  File ""/fate/arch/standalone/standalone/eggroll.py"", line 840, in join 
    result = r.result() 
  File ""/usr/local/lib/python3.6/concurrent/futures/_base.py"", line 425, in result 
    return self.__get_result() 
  File ""/usr/local/lib/python3.6/concurrent/futures/_base.py"", line 384, in __get_result 
    raise self._exception 
lmdb.Error: mdb_txn_commit: Input/output error

运行配置文件算法参数如下：
>- {'HeteroLogisticParam': {'penalty': 'L2', 'tol': 0.0001, 'alpha': 0.01, 'optimizer': 'nesterov_momentum_sgd', 'batch_size': -1, 'learning_rate': 0.15, 'init_param': {'init_method': 'random_uniform', 'init_const': 1, 'fit_intercept': True, 'random_seed': None}, 'max_iter': 30, 'early_stop': 'weight_diff', 'encrypt_param': {'method': 'Paillier', 'key_length': 1024}, 'predict_param': {'threshold': 0.5}, 
'cv_param': {'n_splits': 5, 'mode': 'hetero', 'role': 'guest', 'shuffle': False, 'random_seed': 103, 'need_cv': False}, 'decay': 1, 'decay_sqrt': True, 'multi_class': 'ovr', 'validation_freqs': None, 'stepwise_param': {'score_name': 'AIC', 'mode': 'hetero', 'role': 'guest', 'direction': 'both', 'max_step': 10, 'nvmin': 2, 'nvmax': None, 'need_stepwise': False}, 'early_stopping_rounds': None, 'metrics': ['auc', 'ks'], 'use_first_metric_only': False, 'encrypted_mode_calculator_param': {'mode': 'strict', 're_encrypted_rate': 1}, 
'sqn_param': {'update_interval_L': 3, 'memory_M': 5, 'sample_size': 5000, 'random_seed': None}}, 'initiator': {'role': 'guest', 'party_id': 10000}, 'job_parameters': {'work_mode': 0, 'model_id': 'arbiter-10000#guest-10000#host-10000#model', 'model_version': '20200813032518087622203'}, 'role': {'guest': [10000], 'host': [10000], 'arbiter': [10000]}, 'config': '/fate/examples/federatedml-1.x-examples/hetero_logistic_regression/test_hetero_lr_train_job_conf.json', 'dsl': 'federatedml-1.x-examples/hetero_logistic_regression/test_hetero_lr_train_job_dsl.json', 'function': 'submit_job', 'local': {'role': 'guest', 'party_id': 10000}, 'CodePath': 'federatedml/linear_model/logistic_regression/hetero_logistic_regression/hetero_lr_guest.py/HeteroLRGuest', 'module': 'HeteroLR'}



虽然不太清楚具体原因，但是看这个报错会不会是eggroll的容器空间不够导致的呢？ I find it's my own fault because I solved the problem after rebuilding the  software environment."	2	2020-08-13 05:11:00	2020-10-07 06:16:47	2020-10-07 06:16:47
https://github.com/FederatedAI/FATE/issues/1670	[]	1.4.2版本Upload接口报400错误	"1.4.2版本Upload接口报400错误![微信图片_20200811095504](https://user-images.githubusercontent.com/41407129/89848471-cd1e4580-dbb8-11ea-81d0-f71b7675730c.jpg)

数据和flow client是在同一台机器的，尝试使用use_local_data和module参数，也是一样的效果。
请帮忙分析，谢谢。use_local_data 属性的取值不是String型，而是Integer(0,1)或者Boolean(true,false)类型。我同样遇到这个问题，请问您是怎样解决的？输入参数与您的一样"	2	2020-08-11 01:56:59	2021-03-30 06:53:56	2020-08-12 10:00:41
https://github.com/FederatedAI/FATE/issues/1624	[]	特征分箱仅支持等频和等距分箱吗？跑最优分箱会报错	"特征分箱仅支持等频和等距分箱吗？跑最优分箱会报错报错如下: - ERROR: hetero binning param's optimal is not supported, it should be in ['quantile', 'bucket']""
![image](https://user-images.githubusercontent.com/62371712/88898332-24e6b380-d27f-11ea-9295-4bd7f67d0145.png)

组件参数配置为：
{
""method"": ""optimal"",
 ""optimal_binning_param"": {
 ""metric_method"": ""iv"",
 ""min_bin_pct"": 0.05,
 ""max_bin_pct"": 0.8,
 ""init_bucket_method"": ""quantile"",
 ""init_bin_nums"": 100,
 ""mixture"": true
 },
 ""compress_thres"": 10000,
 ""head_size"": 10000,
 ""error"": 0.001,
 ""bin_num"": 10,
 ""bin_indexes"": -1,
 ""bin_names"": null,
 ""category_indexes"": [0,1,2],
 ""category_names"": null,
 ""adjustment_factor"": 0.5,
 ""local_only"": false,
 ""transform_param"": {
 ""transform_cols"": -1,
 ""transform_names"": null,
 ""transform_type"": ""bin_num""
 }
 }
从1.4版本开始，是支持最优分箱的。"	1	2020-07-30 08:15:58	2021-07-02 08:18:54	2021-07-02 08:18:54
https://github.com/FederatedAI/FATE/issues/1608	[]	please start fate flow server.......	"please start fate flow server.......when i execute fate_flow_client -f submit_job.....

i got an error :
{
    ""retcode"": 999,
    ""retmsg"": ""please start fate flow server: 192.167.0.6:9381""
}

but the service already started : 
![image](https://user-images.githubusercontent.com/30582212/88609277-4b0d2780-d0b6-11ea-8253-bfba28a32cf9.png)



Hello. So, how did you solve it?> Hello. So, how did you solve it?
I apologize. I can't remember why......
I don't use fate every day. Some problems have been solved but I forget"	2	2020-07-28 01:40:00	2020-08-18 00:26:13	2020-07-28 01:41:41
https://github.com/FederatedAI/FATE/issues/1551	['bug']	[SPDZ] Table-based implementation does not support multiple times’ operations	[SPDZ] Table-based implementation does not support multiple times’ operationsIf I multiply under the SPDZ environment two tensors of class `fixedpoint_table.FixedPointTensor`, say *A* and *B*, the resulting product *C = A.dot(B)* will be of class `fixedpoint_numpy.FixedPointTensor`. While there is no problem if I immediately extract the result and leave the environment, errors will occur if I want to use the result to do further computation with tensors of type `fixedpoint_table.FixedPointTensor` because they will have different types. For example, if I want to perform *C+D* where *D* is of type `fixedpoint_table.FixedPointTensor`, either doing *C+D* or *D+C* does not work (with different errors prompting, though).As a user, currently I may sidestep this issue by separating the computation in pieces. Of course it will induce remarkable performance overhead since unnecessary “get()” and “from_source()” have to be performed.track in #2312 	2	2020-07-11 17:10:25	2020-11-11 12:12:22	2020-11-11 12:12:21
https://github.com/FederatedAI/FATE/issues/1535	[]	Fate flow service can't be connected with standalone-fate-master-1.4.1	"Fate flow service can't be connected with standalone-fate-master-1.4.1**Describe the bug**
FATE Flow server starts successfully but failed to connect to it with 9380 port. `ValueError: failed to exec task, status:100, stderr is None stdout:{'retcode': 100, 'retmsg': 'Connection refused, Please check if the fate flow service is started'}`

**To Reproduce**
Steps to reproduce the behavior:
1. Run ```source init.sh init``` under standalone-fate-master-1.4.1
![image](https://user-images.githubusercontent.com/4393234/86312087-76862900-bc54-11ea-8a71-d1804087a514.png)

2. Run `python ./examples/toy_example/run_toy_example.py 10000 10000 0`
![image](https://user-images.githubusercontent.com/4393234/86312225-d381df00-bc54-11ea-8c36-5f7c8aeea8a9.png)



I found it's caused by my wrong hostname which is the same with a website."	1	2020-07-02 03:23:49	2020-07-02 10:26:49	2020-07-02 10:26:49
https://github.com/FederatedAI/FATE/issues/1430	[]	"""Hetero Feature Binning"" leaks extra information"	"""Hetero Feature Binning"" leaks extra informationAs described in https://github.com/FederatedAI/FATE/tree/master/federatedml/feature , to calculate WOE,   B party who has the data labels encrypt its labels with homomorphic encryption and then send them to A.  A then calculate the sum of each bin's label and send back. During this process, party A leaks extra information: the number of samples in each bin.

For example: A and B want to compute this function together:  

                    What is the WOE if 30>= age >= 20 ?

But if they use FATE, B will know **how many A's client are between 20~30 years old !** I don't think this is always acceptable for A. @vincehong That is not true. Actually, party B cannot obtain the feature information and bin split points at all. What party B know is that number of some bins of some features. That means in your case, party B cannot know it is a feature means age and the split points are 20 and 30 neither. 

Hope that can make you more clear about it. Thank you.@tanmc123 I know what you mean. What B can know is : 

                 how many A's client are with the same feature X

while B does not know what X means. 

Actually, given the distribution, and the numbers X_1, X_2, ...X_n, B could figure out these features by a high chance.

The point is: A leaks the number of samples in the bin, beyond the WOE.@vincehong I didn't get how to figure out these features through the number x_1, x_2...etc. Please note it is not the distribution of X, but number of each bins.  Take quantile binning as an example, the number is supposed to be almost same in each bean with the condition of which total amount is not a secret among the parties. Is there any material supporting that?

As for what you meantion so call a ""leak"", if this information cannot benefit the other party, it makes no sense to define it as a ""leak"". Doesn't it?
@tanmc123  Think about categorical features.   Suppose A has a feature X with 3 possible values X_1, X_2, X_3,  then B could know the exact number of samples for each value of X.  If this could not be a leak, then people would doubt what could be called a leak.> @tanmc123 Think about categorical features. Suppose A has a feature X with 3 possible values X_1, X_2, X_3, then B could know the exact number of samples for each value of X. If this could not be a leak, then people would doubt what could be called a leak.

First of all, Party B should have a chance to know it is a categorical feature which is not so obviously through the binning. Then, party B cannot obtain what the feature means even if they could know that. So I still cannot get how to use this information to benefit party B. 

I don't think it's fair to say an algorithm is not safe just because ""if we could know something else, it is not safe"". 

As an engineer, we should always make trade off between it is completely safe and great usablity. Calculating WOE is very meaningful in practice but the risk is low enough. If you can provide any material  supporting it is not safe enough or there is some new knowledge saying that, FATE is open to fix it and making progress through the process. 

Thank you for participating in the construction of FATE. First of all , it's easy to know it's a categorical feature: if X_1 + X_2 + X_3 = total_sum, X is a categorical feature. If total_sum is big (e.g. 100,000+), there's little chance of false positives using this method.

Second, if the security comes from ""B not knowing the feature meanings"", why doesn't A just simply wipe the feature headers and send the data to B?  After all, B does not know what kind of features A have, and we also cannot provide any material supporting ""sending raw data without feature name is not safe enough"". 

And we do have a safe way which only outputs the WOE without leaking the number of samples in the bin: it's just a secure inner product and secure division using MPC (which is already included in  https://github.com/FederatedAI/FATE/tree/master/federatedml/secureprotol/spdz).  

FATE put GDPR at its first page, and includes fancy stuff such as homomorphic encryption, so we would naturally think that it was considering security and privacy in a serious way. Please don't discourage us. We do know it's not easy to maintain such a big open-source project, but we should show better respect to security , privacy , and cryptography.

Thanks.

> First of all , it's easy to know it's a categorical feature: if X_1 + X_2 + X_3 = total_sum, X is a categorical feature. If total_sum is big (e.g. 100,000+), there's little chance of false positives using this method.
> 
> Second, if the security comes from ""B not knowing the feature meanings"", why doesn't A just simply wipe the feature headers and send the data to B? After all, B does not know what kind of features A have, and we also cannot provide any material supporting ""sending raw data without feature name is not safe enough"".
> 
> And we do have a safe way which only outputs the WOE without leaking the number of samples in the bin: it's just a secure inner product and secure division using MPC (which is already included in https://github.com/FederatedAI/FATE/tree/master/federatedml/secureprotol/spdz).
> 
> FATE put GDPR at its first page, and includes fancy stuff such as homomorphic encryption, so we would naturally think that it was considering security and privacy in a serious way. Please don't discourage us. We do know it's not easy to maintain such a big open-source project, but we should show better respect to security , privacy , and cryptography.
> 
> Thanks.

At your first point, even if it is not a categorical feature, it still satisfy  X_1 + X_2 + X_3 = total_sum. I cannot get why this could be a proof of a feature being categorical. 

Well, as for the second point, the number in each bin is totally different with raw data. We are just saying, without the meaning of features, only having the number in each bin is safe. Please do not steal the concept. 

As for the MPC way of calculating WOE, that may be a good suggestion, we will try to think about it more detailly. 

FATE do put GDPR at its first page and that's why FATE is an open-source project. FATE open to discuss with our users and to make progress in every possible way. Thanks for you suggestion. "	7	2020-06-05 03:08:10	2021-07-02 08:41:32	2021-07-02 08:41:32
https://github.com/FederatedAI/FATE/issues/1410	[]	the model and the predict score has not been  displayed  in the host fateboard for the homo_lr algorithm	"the model and the predict score has not been  displayed  in the host fateboard for the homo_lr algorithm![image](https://user-images.githubusercontent.com/13013299/83101713-8b1b5280-a0e5-11ea-82ff-f8998162c5e5.png)
![image](https://user-images.githubusercontent.com/13013299/83101744-98d0d800-a0e5-11ea-83bf-20bf9cabc218.png)
![image](https://user-images.githubusercontent.com/13013299/83101816-c61d8600-a0e5-11ea-9b3d-ff14988ffcf7.png)
@ZhanqiLiu Do you set Paillier encrypt method for homo_lr? If so, this is what they are expected to be. 

Since if you set the model as encrypted, that means you don't want host obtain the final model. Thus model will not be shown. What's more, if the predict score is provided, host can also infer the model. Thus, predict score will not be transferred back neither. thank you , this issue has been solved according to your guidance"	2	2020-05-28 05:21:50	2020-06-16 07:48:43	2020-06-16 07:48:43
https://github.com/FederatedAI/FATE/issues/1409	[]	"The error after the command ""docker-compose down and docker-compose up -d"" for the KubeFATE 1.4"	"The error after the command ""docker-compose down and docker-compose up -d"" for the KubeFATE 1.4When the container is restarted, the table which is uploaded in the last container cann't be accessed  again in the new job, and the job which was run in the last container cann't be readed from the fateboard also.

![image](https://user-images.githubusercontent.com/13013299/83089937-1f77bc00-a0ca-11ea-93cc-c1dc226392c1.png)
![image](https://user-images.githubusercontent.com/13013299/83089959-269eca00-a0ca-11ea-8676-87db8fee6806.png)
![image](https://user-images.githubusercontent.com/13013299/83089976-2c94ab00-a0ca-11ea-9ad4-38756c46f326.png)
@ZhanqiLiu hi thank you for your feedback, this issue has been addressed by this [PR](https://github.com/FederatedAI/KubeFATE/pull/146)"	1	2020-05-28 02:13:38	2020-06-01 11:25:17	2020-06-01 11:25:17
https://github.com/FederatedAI/FATE/issues/1408	['bug']	homo nn: problem with sparse_categorical_crossentropy loss in v1.4.0	"homo nn: problem with sparse_categorical_crossentropy loss in v1.4.0**Describe the bug**
In v1.4.0 homo nn, when `softmax` activation and `sparse_categorical_crossentropy` loss are used, the performance of the model is extremely poor.

**To Reproduce**
Steps to reproduce the behavior:
1. Upload data

<details>
  <summary>Guest (click to expand)</summary>

```
{
    ""file"": ""examples/data/breast_homo_guest.csv"",
    ""head"": 1,
    ""partition"": 16,
    ""work_mode"": 1,
    ""table_name"": ""homo_breast_guest"",
    ""namespace"": ""homo_breast_guest""
}
```
</details>

<details>
  <summary>Host (click to expand)</summary>

```
{
    ""file"": ""examples/data/breast_homo_host.csv"",
    ""head"": 1,
    ""partition"": 16,
    ""work_mode"": 1,
    ""table_name"": ""homo_breast_host"",
    ""namespace"": ""homo_breast_host""
}
```
</details>

2. Submit job

<details>
  <summary>dsl (click to expand)</summary>

```
{
  ""components"": {
    ""dataio_0"": {
      ""module"": ""DataIO"",
      ""input"": {
        ""data"": {
          ""data"": [
            ""args.train_data""
          ]
        }
      },
      ""output"": {
        ""data"": [
          ""train""
        ],
        ""model"": [
          ""dataio""
        ]
      }
    },
    ""homo_nn_0"": {
      ""module"": ""HomoNN"",
      ""input"": {
        ""data"": {
          ""train_data"": [
            ""dataio_0.train""
          ]
        }
      },
      ""output"": {
        ""data"": [
          ""train""
        ],
        ""model"": [
          ""homo_nn""
        ]
      }
    },
    ""homo_nn_1"": {
      ""module"": ""HomoNN"",
      ""input"": {
        ""data"": {
          ""eval_data"": [
            ""dataio_0.train""
          ]
        },
        ""model"": [
          ""homo_nn_0.homo_nn""
        ]
      },
      ""output"": {
        ""data"": [
          ""train2""
        ],
        ""model"": [
          ""homo_nn2""
        ]
      }
    },
    ""evaluation_0"": {
      ""module"": ""Evaluation"",
      ""input"": {
        ""data"": {
          ""data"": [
            ""homo_nn_1.train2""
          ]
        }
      },
      ""output"": {
        ""data"": [
          ""evaluate""
        ]
      }
    }
  }
}
```
</details>

<details>
  <summary>conf (click to expand)</summary>

```
{
  ""initiator"": {
    ""role"": ""guest"",
    ""party_id"": 10000
  },
  ""job_parameters"": {
    ""work_mode"": 1
  },
  ""role"": {
    ""guest"": [
      10000
    ],
    ""host"": [
      9999
    ],
    ""arbiter"": [
      10000
    ]
  },
  ""role_parameters"": {
    ""guest"": {
      ""args"": {
        ""data"": {
          ""train_data"": [
            {
              ""name"": ""homo_breast_guest"",
              ""namespace"": ""homo_breast_guest""
            }
          ]
        }
      },
      ""dataio_0"": {
        ""with_label"": [
          true
        ],
        ""label_name"": [
          ""y""
        ],
        ""label_type"": [
          ""int""
        ],
        ""output_format"": [
          ""dense""
        ]
      }
    },
    ""host"": {
      ""args"": {
        ""data"": {
          ""train_data"": [
            {
              ""name"": ""homo_breast_host"",
              ""namespace"": ""homo_breast_host""
            }
          ]
        }
      },
      ""dataio_0"": {
        ""with_label"": [
          true
        ],
        ""label_name"": [
          ""y""
        ],
        ""label_type"": [
          ""int""
        ],
        ""output_format"": [
          ""dense""
        ]
      }
    }
  },
  ""algorithm_parameters"": {
    ""homo_nn_0"": {
      ""config_type"": ""nn"",
      ""nn_define"": [
        {
          ""layer"": ""Dense"",
          ""units"": 6,
          ""activation"": ""relu""
        },
        {
          ""layer"": ""Dense"",
          ""units"": 2,
          ""activation"": ""softmax""
        }
      ],
      ""batch_size"": -1,
      ""optimizer"": {
        ""optimizer"": ""Adam"",
        ""learning_rate"": 0.05
      },
      ""early_stop"": {
        ""early_stop"": ""diff"",
        ""eps"": 1e-4
      },
      ""loss"": ""sparse_categorical_crossentropy"",
      ""metrics"": [
        ""accuracy""
      ],
      ""max_iter"": 5
    },
    ""evaluation_0"": {
      ""eval_type"": ""binary""
    }
  }
}
```
</details>

3. Check data output and model performance

![softmax_data_output_v14](https://user-images.githubusercontent.com/10785873/82991928-0111b200-a031-11ea-92c2-5d94d7268e38.PNG)

![softmax_eval_v14](https://user-images.githubusercontent.com/10785873/82991996-17b80900-a031-11ea-9c91-600f7c847ef6.PNG)

**Expected behavior**
Performance should be consistent across different versions of FATE when the same algorithm are used on the same data.

**Screenshots**
As attached.

**Desktop (please complete the following information):**
 - OS: Ubuntu 18.04 LTS
 - Browser: Chrome

**Smartphone (please complete the following information):**
 - N.A.

**Additional context**
- In `v1.3.0`, with the same data, dsl, and conf, the results are like this:

![softmax_data_output_v13](https://user-images.githubusercontent.com/10785873/82992059-31595080-a031-11ea-9af6-068e9fc6e561.PNG)

![softmax_eval_v13](https://user-images.githubusercontent.com/10785873/82992074-361e0480-a031-11ea-8e87-5d4078bb6684.PNG)
> **Describe the bug**
> In v1.4.0 homo nn, when `softmax` activation and `sparse_categorical_crossentropy` loss are used, the performance of the model is extremely poor.
> 
> **To Reproduce**
> Steps to reproduce the behavior:
> 
> 1. Upload data
> 
> Guest (click to expand)
> Host (click to expand)
> 1. Submit job
> 
> dsl (click to expand)
> conf (click to expand)
> 1. Check data output and model performance
> 
> ![softmax_data_output_v14](https://user-images.githubusercontent.com/10785873/82991928-0111b200-a031-11ea-92c2-5d94d7268e38.PNG)
> 
> ![softmax_eval_v14](https://user-images.githubusercontent.com/10785873/82991996-17b80900-a031-11ea-9c91-600f7c847ef6.PNG)
> 
> **Expected behavior**
> Performance should be consistent across different versions of FATE when the same algorithm are used on the same data.
> 
> **Screenshots**
> As attached.
> 
> **Desktop (please complete the following information):**
> 
> * OS: Ubuntu 18.04 LTS
> * Browser: Chrome
> 
> **Smartphone (please complete the following information):**
> 
> * N.A.
> 
> **Additional context**
> 
> * In `v1.3.0`, with the same data, dsl, and conf, the results are like this:
> 
> ![softmax_data_output_v13](https://user-images.githubusercontent.com/10785873/82992059-31595080-a031-11ea-9af6-068e9fc6e561.PNG)
> 
> ![softmax_eval_v13](https://user-images.githubusercontent.com/10785873/82992074-361e0480-a031-11ea-8e87-5d4078bb6684.PNG)

Thanks for the detailed report!  
We fix this issue with pr #1419 problem which will be released alone with next mirror version.
Thanks! Looking forward to your next release."	2	2020-05-27 07:56:30	2020-06-29 07:37:48	2020-06-29 07:37:48
https://github.com/FederatedAI/FATE/issues/1399	[]	a little bug in hetero_decision_tree_guest.py file	"a little bug in hetero_decision_tree_guest.py fileIn the 315 line, which is in the function of  find_best_split_guest_and_host(), the  value of 1 should be modified as 2.
![image](https://user-images.githubusercontent.com/13013299/82445526-8d732080-9ad7-11ea-8c7d-d1c8dba016e3.png)

It wastes one time of comparision, but will not affect the result correctnessyes, it will not affects the  result correctness"	2	2020-05-20 12:26:47	2020-06-16 07:50:33	2020-06-16 07:50:32
https://github.com/FederatedAI/FATE/issues/1377	[]	单机版fate1.4在运行推荐模型时报错	"单机版fate1.4在运行推荐模型时报错版本：单机版1.4
运行用例shell脚本如下：
```
#!/bin/bash

MODEL_DIR=""examples/federatedrec-examples/hetero_svd""
python fate_flow/fate_flow_client.py -f upload -c ${MODEL_DIR}/upload_data_guest.json
sleep 3s
python fate_flow/fate_flow_client.py -f upload -c ${MODEL_DIR}/upload_data_host.json
sleep 3s
python fate_flow/fate_flow_client.py -f submit_job -d ${MODEL_DIR}/test_hetero_svd_train_job_dsl.json -c ${MODEL_DIR}/test_hetero_svd_train_job_conf.json
```
报如下错误

> [ERROR] [2020-05-18 06:56:00,745] [6994:140016906028864] - task_executor.py[line:140]: Attempt to operate on closed/deleted/dropped object.
> Traceback (most recent call last):
> File ""/fate/fate_flow/driver/task_executor.py"", line 127, in run_task
> input_dsl=task_input_dsl)
> File ""/fate/fate_flow/driver/task_executor.py"", line 203, in get_task_run_args
> name=data_table.get_name(), options=save_as_options)
> File ""/fate/arch/api/utils/profile_util.py"", line 32, in _fn
> rtn = func(*args, **kwargs)
> File ""/fate/arch/api/impl/based_1x/table.py"", line 58, in save_as
> persistent_engine=persistent_engine)
> File ""/fate/arch/standalone/standalone/eggroll.py"", line 696, in save_as
> dup.put_all(self.collect(use_serialize=use_serialize), use_serialize=use_serialize)
> File ""/fate/arch/standalone/standalone/eggroll.py"", line 650, in put_all
> for k, v in kv_list:
> File ""/fate/arch/standalone/standalone/eggroll.py"", line 728, in _merge
> if it.next():
> lmdb.Error: Attempt to operate on closed/deleted/dropped object.您好 

> 版本：单机版1.4
> 运行用例shell脚本如下：
> 
> ```
> #!/bin/bash
> 
> MODEL_DIR=""examples/federatedrec-examples/hetero_svd""
> python fate_flow/fate_flow_client.py -f upload -c ${MODEL_DIR}/upload_data_guest.json
> sleep 3s
> python fate_flow/fate_flow_client.py -f upload -c ${MODEL_DIR}/upload_data_host.json
> sleep 3s
> python fate_flow/fate_flow_client.py -f submit_job -d ${MODEL_DIR}/test_hetero_svd_train_job_dsl.json -c ${MODEL_DIR}/test_hetero_svd_train_job_conf.json
> ```
> 
> 报如下错误
> 
> > [ERROR] [2020-05-18 06:56:00,745] [6994:140016906028864] - task_executor.py[line:140]: Attempt to operate on closed/deleted/dropped object.
> > Traceback (most recent call last):
> > File ""/fate/fate_flow/driver/task_executor.py"", line 127, in run_task
> > input_dsl=task_input_dsl)
> > File ""/fate/fate_flow/driver/task_executor.py"", line 203, in get_task_run_args
> > name=data_table.get_name(), options=save_as_options)
> > File ""/fate/arch/api/utils/profile_util.py"", line 32, in _fn
> > rtn = func(*args, **kwargs)
> > File ""/fate/arch/api/impl/based_1x/table.py"", line 58, in save_as
> > persistent_engine=persistent_engine)
> > File ""/fate/arch/standalone/standalone/eggroll.py"", line 696, in save_as
> > dup.put_all(self.collect(use_serialize=use_serialize), use_serialize=use_serialize)
> > File ""/fate/arch/standalone/standalone/eggroll.py"", line 650, in put_all
> > for k, v in kv_list:
> > File ""/fate/arch/standalone/standalone/eggroll.py"", line 728, in _merge
> > if it.next():
> > lmdb.Error: Attempt to operate on closed/deleted/dropped object.

您好，我遇到同样的问题，请问您解决了么？
没有解决，可以试试最新的1.6.0版本> 没有解决，可以试试最新的1.6.0版本

您好，使用1.3.1版本就可以解决了，应该是1.4没注册那个算法"	3	2020-05-18 07:20:58	2021-04-16 10:16:24	2021-04-14 08:16:49
https://github.com/FederatedAI/FATE/issues/1376	['bug']	使用全连接神经网络横向联邦学习进行手写体识别任务，报错	"使用全连接神经网络横向联邦学习进行手写体识别任务，报错**Describe the bug**

使用全连接神经网络横向联邦学习进行手写体识别任务。数据集使用mnist，按标签01234和56789划分为两个数据集，分别上传。每个角色没有其他类别标签的数据。分类任务设为5或者10均报错。
对于数据特征相同的分类任务，不同角色拥有的数据标签完全不同时，推断报错。

**To Reproduce**
Steps to reproduce the behavior:
1. guest、host分别上传数据
2. 运行相应的配置文件、dsl文件
3.fateboard查看运行状态


**Expected behavior**

算法正常运行。




在横向任务中，每个本地节点，数据label必须一样，比如guest{0123456789}host{0123456789}It works in 1.5.0, close issue.> It works in 1.5.0, close issue.

OK，looking forward to it."	3	2020-05-18 07:13:36	2020-11-02 07:35:26	2020-11-02 07:32:44
https://github.com/FederatedAI/FATE/issues/1374	[]	component_output_data api 导出的数据量问题	"component_output_data api 导出的数据量问题**Describe the bug**
参考文档 https://fate.readthedocs.io/en/latest/fate_flow/doc/fate_flow_cli.html
使用 component_output_data  api时
1. 数据量不一致的问题
总数据量（训练+验证）1万时，发现导出数据量
    output_data.csv 数据量 == train + eval
总数据量（训练+验证）10万时，发现导出数据量（有时）
    output_data.csv 数据量 == train
总数据量 （训练+验证）> 5万时，发现数据量有一定波动性，但是均为
    output_data.csv 数据量 < train + eval
 2. 重启fate后数据不见了的问题
    重启之后发现无法导出了

**To Reproduce**
Steps to reproduce the behavior:
1. 训练一个secureboost任务
2. 使用api：python fate_flow_client.py -f component_output_data -j $job_id -r $role -p $party_id -cpn $component_name -o $output_path
导出 out_data.csv
3. cat output_data.csv |wc -l
4. 数量不对劲

**Expected behavior**
希望导出数据量能与 训练+验证 一致
不排除是训练过程中丢包什么导致的数据量不一致，重复使用out_data.csv 导出数据量一致
使用 submit_job api 中 predict 的方法，多试 predict 的 out_data.csv 的数据量有一定随机性且很少与 输入的数据量一致
由于没有报错信息，不知道数据量不一致具体原因

**Screenshots**
1万数据量一致
![1万数据量一致](https://user-images.githubusercontent.com/20585352/82003959-4a0e5180-9694-11ea-8471-b05a27672c41.png)
10万数据量只有训练集
![10万数据量只有训练集](https://user-images.githubusercontent.com/20585352/82003967-51355f80-9694-11ea-98eb-3a2b0aae962b.png)
重启之后再无法导出
![重启之后再无法导出](https://user-images.githubusercontent.com/20585352/82003982-58f50400-9694-11ea-9c76-f484609c1aba.png)


**Desktop (please complete the following information):**
 - OS: centos7
 - Version fate1.3

经过排查大概率可能是 训练过程的丢包导致的，对于这种情况能否处理一下，重新打分也好，保证数据量一致的，否则线下很难评估FATE v1.4 已经fixed这个bug，也做了检测。可以试验下。> FATE v1.4 已经fixed这个bug，也做了检测。可以试验下。

好的 这两天会试一下> FATE v1.4 已经fixed这个bug，也做了检测。可以试验下。

v1.4 output_data.csv 数据量与训练+测试已一致"	4	2020-05-15 02:11:04	2020-05-27 02:03:13	2020-05-27 02:03:13
https://github.com/FederatedAI/FATE/issues/1373	[]	fate_flow service fail to start	"fate_flow service fail to startFor Fate1.4.0 cluster-deploy, fate_flow service failed to start on host.

Logs from /data/projects/fate/python/logs/error.log:
![f01-2020-05-14-16-17-00](https://user-images.githubusercontent.com/24994791/81995778-1da8f580-9600-11ea-9bcb-83147672fd86.png)
![f01-2020-05-14-16-17-36](https://user-images.githubusercontent.com/24994791/81995782-1eda2280-9600-11ea-8c01-db80f6bbd46c.png)

How can I solve it?Solved after re-deployed eggroll&fate"	1	2020-05-14 23:35:14	2020-05-15 00:07:29	2020-05-15 00:06:46
https://github.com/FederatedAI/FATE/issues/1328	[]	intersection 匹配率不为1且不固定	"intersection 匹配率不为1且不固定**Describe the bug**
intersection 会匹配率不为1且不固定
已检查id一致，匹配率也不是一个固定的值，在0-1之间的一个浮点数

**To Reproduce**
Steps to reproduce the behavior:
1.提交任务
2.检查intersection

**Expected behavior**
希望匹配率稳定为1，且增加丢包检查

**Screenshots**
![微信图片_20200507101212](https://user-images.githubusercontent.com/20585352/81247311-3cc9e500-904c-11ea-9158-d6e6699a809f.png)

![微信图片_20200507101137](https://user-images.githubusercontent.com/20585352/81246917-574f8e80-904b-11ea-9910-58c9e2cd5ce3.png)



**Desktop (please complete the following information):**
 - fate1.3

**Additional context**
看了 issue 里面好像没有相关问题，不知道我这种是不是个例我这也有相同的问题，没找到解决方法FATE v1.4 已经解决，可以试用下> FATE v1.4 已经解决，可以试用下

谢谢啦 最近试试> FATE v1.4 已经解决，可以试用下

已尝试，数据量问题1.4 已解决"	4	2020-05-07 02:18:54	2020-05-27 01:56:18	2020-05-27 01:56:18
https://github.com/FederatedAI/FATE/issues/1247	['bug']	Wrong Party ID in Feature Names on Board for Stepwise	"Wrong Party ID in Feature Names on Board for Stepwise**Describe the bug**
FATE Board always uses local party's id when making feature name anonyms. 


**To Reproduce**
Steps to reproduce the behavior:
1. Set host/guest party id to different numbers in stepwise job configuration 
2. Run the stepwise job and check Board for where feature anonyms are presented. 

Fixed in commit c10906e"	1	2020-04-27 07:31:53	2020-04-27 07:36:05	2020-04-27 07:36:05
https://github.com/FederatedAI/FATE/issues/1162	[]	 hetero_nn model : the  error of Backward Propagation Part II in README.md 	" hetero_nn model : the  error of Backward Propagation Part II in README.md According to the papers and code, the description should be modified as follows， @ is the modification location, the total error number is 16 :
1、Party B calculates the error delta_act of activation function's output by delta.
2、Party B propagates delta_bottomB = delta_act * W_B to bottom model, then updates W_B(W_B -= eta * delta_act * alpha_B).
3、Party B generates noise epsilon_B, calculates [delta_act* @alpha_A + epsilon_B] and sends it to party A.
4、Party A encrypts epsilon_acc, sends [epsilon_acc] to party B.
Then party @A decrypts the received value, generates noise epsilon_A, adds epsilon_A / eta to decrypted result(delta_act * @alpha_A  + epsilon_B + epsilon_A / eta) and epsilon_A to accumulate noise epsilon_acc(epsilon_acc += epsilon_A). Party A sends the addition result to party B. (delta_act * @alpha_A + epsilon_B + epsilon_A / eta)
5、Party B receives [epsilon_acc] and delta_act * @alpha_A  + epsilon_B + epsilon_A / eta. Firstly it sends party A's bottom model output' error [ @delta_act * @(W_A + epsilon_acc)] to host. Secondly updates W_A -= eta * (delta_act * alpha_A + epsilon_B + epsilon_A / eta - epsilon_B @) = eta * delta_act * @alpha_A  @+ @epsilon_A,  @ W_A =W_TRUE - epsilon_acc. Where W_TRUE represents the actually weights.
6、Party A decrypts [@delta_act * (W_A + @epsilon_acc)] and passes @delta_act * (W_A + @epsilon_acc) to its bottom model.
@ZhanqiLiu Thanks for your detailed modification comments，we will fix it soon. Sorry for misleading,  refer to the attached flow diagram will be much better. "	1	2020-04-15 02:39:06	2020-06-16 12:06:03	2020-06-16 12:06:03
https://github.com/FederatedAI/FATE/issues/1157	['bug', 'federatedml']	"横向联邦100w数据量在做predict的时候报错【ERROR: 'NoneType' object has no attribute 'unboxed'"" 】"	"横向联邦100w数据量在做predict的时候报错【ERROR: 'NoneType' object has no attribute 'unboxed'"" 】""2020-04-13 09:31:55,560 - homo_lr_arbiter.py[line:95] - INFO: Start predict task""
82""2020-04-13 09:31:55,901 - task_executor.py[line:132] - ERROR: 'NoneType' object has no attribute 'unboxed'""
83Traceback (most recent call last):
84File ""/home/fate/fate/python/fate_flow/driver/task_executor.py"", line 119, in run_task
85run_object.run(parameters, task_run_args)
86File ""/home/fate/fate/python/federatedml/model_base.py"", line 91, in run
87this_data_output = func(*params)
88File ""/home/fate/fate/python/federatedml/linear_model/logistic_regression/homo_logsitic_regression/homo_lr_arbiter.py"", line 100, in predict
89LOGGER.debug(""Loaded arbiter model: {}"".format(self.model_weights.unboxed))
90AttributeError: 'NoneType' object has no attribute 'unboxed'
91""2020-04-13 09:31:55,951 - api_utils.py[line:69] - INFO: grpc api response: header {@JackLi529 According to the parameters settings, max_iter has been set as 1 which may cause fail to aggregate model in arbiter. Therefore, arbiter cannot access the aggregated model yet before entering predict process. However, this is still a problem for arbiter fail to aggregate. This will be fix in FATE-1.4.
"	2	2020-04-13 02:02:13	2020-06-15 05:49:54	2020-06-15 05:49:54
https://github.com/FederatedAI/FATE/issues/1156	[]	有虚拟网桥的离线环境下安装集群模式后 toy example 不能正常运行	"有虚拟网桥的离线环境下安装集群模式后 toy example 不能正常运行**Describe the bug**
离线环境下，两台 Centos 7.6 的虚拟机，利用提供的脚本安装后，在 guset 节点上执行 `python run_toy_example.py 9999 10000 1` 无法正常运行，提示的日志如下：

![image](https://user-images.githubusercontent.com/8924378/79070752-62dcbd80-7d0a-11ea-9194-4a4205d5e86f.png)

后来我们发现图片里面显示的 IP 192.168.122.1 ，这个是虚拟网桥 virbr0 的 IP 地址，因此我们将这个虚拟网桥关闭后重新安装了一次，但仍然无法正常运行 toy_example 提示的问题如下：

![image](https://user-images.githubusercontent.com/8924378/79070963-83f1de00-7d0b-11ea-9e25-83f78b3cf325.png)

抛出的错误提示从 192.168.122.1:8011 变成了 null:8011。

**Expected behavior**
Toy Example 能够正常运行。

**Desktop (please complete the following information):**
 - OS: Centos
 - Browser chrome
 - Version v1.3.0

最终定位问题是 eggroll 1.x 版本的一个 BUG，在 [RuntimeUtils.java](https://github.com/WeBankFinTech/eggroll/blob/v1.x/core/src/main/java/com/webank/ai/eggroll/core/utils/RuntimeUtils.java) 的47~67行里有如下的代码：

```java
public String getMySiteLocalAddress() {
        if (siteLocalAddress == null) {
            Enumeration<NetworkInterface> networkInterfaces = null;
            try {
                networkInterfaces = NetworkInterface.getNetworkInterfaces();

                for (NetworkInterface ni : Collections.list(networkInterfaces)) {
                    Enumeration<InetAddress> inetAddresses = ni.getInetAddresses();
                    for (InetAddress ia : Collections.list(inetAddresses)) {
                        if (ia.isSiteLocalAddress()) {
                            siteLocalAddress = StringUtils.substringAfterLast(ia.toString(), ""/"");
                        }
                    }
                }
            } catch (SocketException e) {
                siteLocalAddress = ""127.0.0.1"";
            }
        }

        return siteLocalAddress;
    }
```

里面调用了 `isSiteLocalAddress()` 这个方法，这个方法无法把我使用的虚拟机的 ip 地址 128.x.x.x 识别为本地地址，而会把 192.168 开头的虚拟网桥地址识别为 LocalAddress，从而导致 grpc 服务监听的地址错误。

 eggroll 2.0 版本已经修复了这个 bug， 而 FATE 1.3.0 安装包里面使用的还是 eggroll 1.1.4 的版本，因而出现了这个问题。

"	1	2020-04-12 14:20:53	2020-04-14 07:50:44	2020-04-14 07:50:44
https://github.com/FederatedAI/FATE/issues/1089	['bug', 'enhancement', 'federatedml']	Cannot Evaluate Multi-Class Prediction from Local Baseline	"Cannot Evaluate Multi-Class Prediction from Local Baseline**Describe the bug**
When trying to evaluate multi-class results from Local Baseline module, an Error is raised. It appears to be due to prediction result being type ""str"", different from ""int"" type as in data set.

**To Reproduce**
Steps to reproduce the behavior:
1. siting evaluation type to ""multi""
2. run a local baseline case with multi-class instead of binary labels. 

**Expected behavior**
The Evaluation module should present the multi-class evaluation results. 
This issue is due to a type misspecification when converting between data instance table and numpy array. In addition, Local Baseline module was not designed to also support multi-class cases. Support for multi-class will be added in a newer release."	1	2020-03-11 07:43:32	2020-06-15 05:48:10	2020-06-15 05:48:10
https://github.com/FederatedAI/FATE/issues/1055	[]	table info - the count of upload data is 0	"table info - the count of upload data is 0when I deployed the cluster version, and test the min_test_task as follow codes:
```
source /data/projects/fate/init_env.sh
cd /data/projects/fate/python/examples/min_test_task/
sh run.sh host fast 
```
I meet a problem that **the count of upload data is 0**, the console is outputed as follows. I don't know how to handle with this problem.
```
(venv) [app@hadoop-slave1 min_test_task]$ sh run.sh host fast
role is host
task is fast
upload_task, table_name:host_table_name_1583256848_2084
upload_task, namespace:host_table_namespace_1583256848_2084
Upload data config json: {'file': '/data/projects/fate/python/examples/min_test_task/../data/breast_a.csv', 'head': 1, 'partition': 10, 'work_mode': 1, 'table_name': 'host_table_name_1583256848_2084', 'namespace': 'host_table_namespace_1583256848_2084'}
Start task: ['python', '/data/projects/fate/python/examples/min_test_task/../../fate_flow/fate_flow_client.py', '-f', 'upload', '-c', '/data/projects/fate/python/examples/min_test_task/test/upload_host.config_1583256848_3983']
Upload output is {'data': {'board_url': 'http://192.168.1.192:8080/index.html#/dashboard?job_id=2020030401340924436620&role=local&party_id=0', 'job_dsl_path': '/data/projects/fate/python/jobs/2020030401340924436620/job_dsl.json', 'job_runtime_conf_path': '/data/projects/fate/python/jobs/2020030401340924436620/job_runtime_conf.json', 'logs_directory': '/data/projects/fate/python/logs/2020030401340924436620', 'namespace': 'host_table_namespace_1583256848_2084', 'table_name': 'host_table_name_1583256848_2084'}, 'jobId': '2020030401340924436620', 'retcode': 0, 'retmsg': 'success'}
Start task: ['python', '/data/projects/fate/python/examples/min_test_task/../../fate_flow/fate_flow_client.py', '-f', 'table_info', '-t', 'host_table_name_1583256848_2084', '-n', 'host_table_namespace_1583256848_2084']
{'data': {'count': 0, 'namespace': 'host_table_namespace_1583256848_2084', 'partition': 1, 'table_name': 'host_table_name_1583256848_2084'}, 'retcode': 0, 'retmsg': 'success'}
Upload Data, role: host, count: {'data': {'count': 0, 'namespace': 'host_table_namespace_1583256848_2084', 'partition': 1, 'table_name': 'host_table_name_1583256848_2084'}, 'retcode': 0, 'retmsg': 'success'}
The table name and namespace is needed by GUEST. To start a modeling task, please inform GUEST with the table name and namespace.
finish upload intersect data
*********************
*******finish!*******
```Hello, you can check if there is an error message in ‘/data/projects/fate/python/logs/2020030401340924436620/local/0' or '/data/projects/fate/python/logs/fate_flow/ERROR.log'The error log is showed in '/data/projects/fate/python/logs/fate_flow/ERROR.log' as follows:
```
  self.on_connect()
  File ""/data/projects/fate/common/python/venv/lib/python3.6/site-packages/redis/connection.py"", line 570, in on_connect
    if nativestr(self.read_response()) != 'OK':
  File ""/data/projects/fate/common/python/venv/lib/python3.6/site-packages/redis/connection.py"", line 638, in read_response
    raise response
redis.exceptions.ResponseError: Client sent AUTH, but no password is set
""2020-03-03 00:00:45,731 - data_access_app.py[line:32] - ERROR: push job into queue failed""
Traceback (most recent call last):
  File ""/data/projects/fate/python/fate_flow/driver/job_controller.py"", line 98, in submit_job
    RuntimeConfig.JOB_QUEUE.put_event(job_event)
  File ""/data/projects/fate/python/fate_flow/manager/queue_manager.py"", line 80, in put_event
    raise e
  File ""/data/projects/fate/python/fate_flow/manager/queue_manager.py"", line 75, in put_event
    ret = conn.lpush(self.queue_name, json.dumps(event))
  File ""/data/projects/fate/common/python/venv/lib/python3.6/site-packages/redis/client.py"", line 1554, in lpush
    return self.execute_command('LPUSH', name, *values)
  File ""/data/projects/fate/common/python/venv/lib/python3.6/site-packages/redis/client.py"", line 754, in execute_command
    connection.send_command(*args)
  File ""/data/projects/fate/common/python/venv/lib/python3.6/site-packages/redis/connection.py"", line 619, in send_command
    self.send_packed_command(self.pack_command(*args))
  File ""/data/projects/fate/common/python/venv/lib/python3.6/site-packages/redis/connection.py"", line 594, in send_packed_command
    self.connect()
  File ""/data/projects/fate/common/python/venv/lib/python3.6/site-packages/redis/connection.py"", line 502, in connect
    self.on_connect()
  File ""/data/projects/fate/common/python/venv/lib/python3.6/site-packages/redis/connection.py"", line 570, in on_connect
    if nativestr(self.read_response()) != 'OK':
  File ""/data/projects/fate/common/python/venv/lib/python3.6/site-packages/redis/connection.py"", line 638, in read_response
    raise response
redis.exceptions.ResponseError: Client sent AUTH, but no password is set
```
The redis process is showed as follows:
```
[app@hadoop-slave1 fate_flow]$ ps aux|grep redis
app       98604  0.0  0.0 112712   964 pts/1    S+   18:14   0:00 grep --color=auto redis
app      183604  0.1  0.0 153884  3300 pts/1    Sl   01:33   1:10 /data/projects/fate/common/redis/redis-5.0.2/bin/redis-server 0.0.0.0:6379
```
I don't know how to do next to deal with the redis problem, thanks very muchI kill all the process of fate and stop all the modules as follows
```
kill -s 9 `ps -aux | grep fate | awk '{print $2}'`
cd /data/projects/fate
sh services.sh all stop
```
and restart all the modules
```
cd /data/projects/fate
sh services.sh all start

```
it solve the problem. Thanks very much"	3	2020-03-03 09:41:23	2020-03-04 03:54:33	2020-03-04 03:31:30
https://github.com/FederatedAI/FATE/issues/1047	['bug', 'federatedml']	Transfer Variable Cleaned before Being Sent by LinR & Poisson Host	"Transfer Variable Cleaned before Being Sent by LinR & Poisson Host**Describe the bug**
The ""host_partial_prediction"" variable is cleaned before Host sending it to Guest during cross validation. 

**To Reproduce**
1. Set ""validation_freqs"" in configuration file to be real value. 
2. Run a poisson or linear regression cross validation task. 

**Expected behavior**
Guest keeps waiting on Host sending host_partial_prediction at the end of first fold, with no error message. 
Fixed & Merged . "	1	2020-03-02 14:57:45	2020-03-03 02:34:58	2020-03-03 02:34:58
https://github.com/FederatedAI/FATE/issues/1009	['bug', 'enhancement', 'federatedml']	Fix HeteroSecureBoost's error when host feature histogram is large.	"Fix HeteroSecureBoost's error when host feature histogram is large.**Is your feature request related to a problem? Please describe.**
In FATE-v1.2 or lower version, HeteroSecureBoost will raise an error when host size's encrypted feature histogram is larger than 32M.It's easy to reproduce this if host's feature shape is large (for example, 1k). In FATE-1.3, mapPartition2 api will be use to avoid this situation,  making training data with thousands features is possible using Paillier Encryption

In FATE-1.3， only host's feature histogram generation and finding split process will be optimize. In later version, guest's feature histogram, histogram accumulating process, host's split infos exchaning and federated finding processor  should also be optimize too."	1	2020-02-20 07:45:36	2020-03-06 12:25:55	2020-03-06 12:25:55
https://github.com/FederatedAI/FATE/issues/938	[]	SPARK_HOME not found	"SPARK_HOME not foundHi, I deployed FATE 1.2 using docker deploy. When I test the spark backend it raise an error:

Traceback (most recent call last):
  File ""/data/projects/fate/python/fate_flow/driver/task_scheduler.py"", line 318, in start_task
    raise EnvironmentError(""SPARK_HOME not found"")
OSError: SPARK_HOME not found

Dose it mean that I should deploy spark+hadoop manually to use the spark backend?
Thanks!
If Yes, should I deploy spark+hadoop in the containers of ""federatedai/python:1.2.0-release"" in both guest and host devices, or other containers?@linjieccc you should deploy spark manually, both for guest and  and host devices. no further response, close this issue"	3	2020-01-14 03:18:00	2020-04-20 07:03:41	2020-04-20 07:03:41
https://github.com/FederatedAI/FATE/issues/927	[]	can't run job in 1.2	"can't run job in 1.2First, i have no issue to run a job on a cluster mode for 1.1 . For 1.2, I able to run a job on a single machine  (guest and host on the same machine). However, when host and guest are on different machines, i get below error in egg log.

```

 [ERROR] 2020-01-08T07:39:32,907 [grpcServiceExecutor-9] [GrpcServerWrapper:54] - java.lang.IllegalStateException: sessionId 202001080739241686922_dataio_0_guest_10000 does not exist
	at com.webank.ai.eggroll.framework.egg.manager.EggSessionManager.getComputeEngine(EggSessionManager.java:163)
	at com.webank.ai.eggroll.framework.egg.api.grpc.server.EggSessionServiceImpl.lambda$getComputingEngine$2(EggSessionServiceImpl.java:72)
	at com.webank.ai.eggroll.core.api.grpc.server.GrpcServerWrapper.wrapGrpcServerRunnable(GrpcServerWrapper.java:52)
	at com.webank.ai.eggroll.framework.egg.api.grpc.server.EggSessionServiceImpl.getComputingEngine(EggSessionServiceImpl.java:70)
	at com.webank.ai.eggroll.api.framework.egg.SessionServiceGrpc$MethodHandlers.invoke(SessionServiceGrpc.java:357)
	at io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:171)
	at io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:283)



	at io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:710)
	at io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
```
additional info: 202001080739241686922_dataio_0_guest_10000 folder exist in /data/projects/fate/data-dir/lmdb/ 


Also, i notice the route table is different from 1.1 . On 1.2 , another machine info is inside the route table. On 1.1, the route table shows only info about the exchange serveri able to get it running, after making sure egg is running on port 7778"	1	2020-01-08 08:33:48	2020-01-10 06:40:53	2020-01-10 06:40:53
https://github.com/FederatedAI/FATE/issues/897	[]	"[hetero Poisson regression] The ""aggregate_forward"" is suspected to be mistakenly computed"	"[hetero Poisson regression] The ""aggregate_forward"" is suspected to be mistakenly computed**Describe the bug and Expected Behavior**
Have a look at [Line 57](https://github.com/FederatedAI/FATE/blob/master/federatedml/optim/gradient/hetero_poisson_gradient_and_loss.py#L57) of File [hetero_poisson_gradient_and_loss](https://github.com/FederatedAI/FATE/blob/master/federatedml/optim/gradient/hetero_poisson_gradient_and_loss.py). This is where the Guest compute the ""aggregated forward"".

To point out a potential bug, let's follow the annotations and process depicted in your illustration, i.e., File [HeteroPoisson.png](https://github.com/FederatedAI/FATE/blob/master/federatedml/linear_model/poisson_regression/images/HeteroPoisson.png).

As we can see, in Line 57 of the code file, `self.host_forwards[0]` contains `[[ exp(W^H X^H) ]]` of each sample, while `self.forwards`t consists of `exp(W^G X^G)` of each sample. To my knowledge, you have already overridden `+` operation for the encrypted elements in `self.host_forwards[0]`. Thus, to obtain `[[ exp(W^H X^H) + exp(W^G X^G) ]]`, one should simple ""add"" `exp(W^G X^G)` to `[[ exp(W^H X^H) ]]`, i.e., I think maybe the line should be

```
self.aggregated_forwards = self.forwards.join(self.host_forwards[0], lambda g, h: g + h)
```

instead of

```
self.aggregated_forwards = self.forwards.join(self.host_forwards[0], lambda g, h: g * h)
```

I think this issue is just a theoretical discussion and therefore have not found any way to reproduce this ""bug"". Hope that I have made things clear enough for you.Thank you for pointing out a mistake in the README doc. We will correct this illustration mistake in the next release. The intermediate result should be [[exp(W^H X^H + W^G X^G)]]. By product rule of exponents, the computation is thus equivalently [[exp(W^H X^H ]] * exp(W^G X^G).Solved in latest release 357af97 "	2	2019-12-27 07:03:41	2020-01-16 02:15:49	2020-01-16 02:08:18
https://github.com/FederatedAI/FATE/issues/887	[]	Can't execute the predict task	"Can't execute the predict taskhetero_lr_task.
guest_tarin_data: breast_b((id:0-499) total:500) host_train_data:breast_a((id:0-499) total:500)
guest_eval_data: breast_b((id:500-568) total:69) host_eval_data:breast_a((id:500-568) total:69)
My Step:

upload_guest_train_data
upload_host_train_data
start modeling (I add the 'need_deploy'=[true] to the xxx_dsl.json)
upload_guest_eval_data
upload_host_eval_data
predict
step 1-5 is success in fate_board.
I checked the the error log of 'step6.predict' and found there is an error about ""input data's schema for fit and transform should be same"".
Can anybody help me to solve this problem?
Here are data and config files. 链接: https://pan.baidu.com/s/138eq7yhkonFbBWs2U_DwrQ 提取码: 413hSame with #925 "	1	2019-12-25 06:27:07	2020-02-13 10:09:31	2020-02-13 10:09:30
https://github.com/FederatedAI/FATE/issues/872	[]	Onehot moduel error when set need_run is false	"Onehot moduel error when set need_run is false**Describe the bug**
When need_run parameter is set as false in onehot module, the export model function cannot access empty model meta. Therefore, it occurs error in this case. 
Already fix in v1.1.2"	1	2019-12-23 03:41:33	2020-02-17 04:05:16	2020-02-17 04:05:16
https://github.com/FederatedAI/FATE/issues/869	[]	"[hetero linear regression] The host sends its ""forwards"" and ""loss_regular"" directly without encryption"	"[hetero linear regression] The host sends its ""forwards"" and ""loss_regular"" directly without encryption**Describe the bug**
Have a look at [Line 131](https://github.com/FederatedAI/FATE/blob/efae2b1add20d9f98ac05a669298e36369f91497/federatedml/optim/gradient/hetero_linr_gradient_and_loss.py#L131) of File [hetero_linr_gradient_and_loss](https://github.com/FederatedAI/FATE/blob/master/federatedml/optim/gradient/hetero_linr_gradient_and_loss.py). This is where the Host compute part of the loss (in your word, loss intermediate). Note that **""forwards"" is plain text**, and hence the result ""self_wx_square"" is also plain text. As a result, the guest will know the intermediate loss of the host.

Similar also happen at [Line 134](https://github.com/FederatedAI/FATE/blob/efae2b1add20d9f98ac05a669298e36369f91497/federatedml/optim/gradient/hetero_linr_gradient_and_loss.py#L134) of the same file. Note that **""loss_regular"" is plain text as well**.

**To Reproduce**
One can simply add a line following [Line 131](https://github.com/FederatedAI/FATE/blob/efae2b1add20d9f98ac05a669298e36369f91497/federatedml/optim/gradient/hetero_linr_gradient_and_loss.py#L131) to print the type of the variable `self_wx_square`. According to my test, it is `numpy.float64`. The same thing happens with the variable `loss_regular` when I added a line following [Line 134](https://github.com/FederatedAI/FATE/blob/efae2b1add20d9f98ac05a669298e36369f91497/federatedml/optim/gradient/hetero_linr_gradient_and_loss.py#L134) to check its type.

**Expected behavior**
We should **encrypt ""self_wx_square"" and ""loss_regular"" before sending it to the guest**. In other words, the type of `self_wx_square` and `loss_regular` are both expected to be `Federatedml.secureprotol.fate_paillier.PaillierEncryptedNumber` (or something like that depending on the encryption method we use).

**Additional context**
You may not notice the problem before, as these bugs **do not harm the precision of the loss**. This is because the intermediate loss of the host, though not encrypted at the host, will be encrypted at the guest before producing the final encrypted loss.
@SamuelGong Thanks for you feedback. We have checked this bug report and find that the ""self_wx_square"" and ""loss_regular"" are not encrypted indeed. These two values are two statistical intermediate variables which leak few data information. 

However, it still makes more sense to encrypt them before transmission. We will fix this problem in next version. Thank you again for pointing out this problem for us. Fixed in FATE-1.2 357af97"	2	2019-12-19 13:07:09	2020-02-17 03:49:22	2020-02-17 03:49:21
https://github.com/FederatedAI/FATE/issues/843	[]	Can't start modeling task.	"Can't start modeling task.1.I have uploaded data (Firstly  python ../fate_flow_client.py -f upload -c upload_data.json(guest) ;Then python ../fate_flow_client.py -f upload -c upload_data.json(host) ).  And the status is success in fate_board.
2. I started my modeling task, but failed.(python ../fate_flow_client.py -f Submit_job -d hetero_logistic_regression / test_hetero_lr_train_job_dsl.json -c hetero_logistic_regression / test_hetero_lr_train_job_conf.json) The retmsg is success in terminal, however the status is failed in fate_board. 
I checked the guest task's log, ERROR: Count of data_instance is 0"" 
In addition, when I run the ""python quick_run.py ""  the status is success in fate_board. 
Can anyone help me ???
FATE:standalone
task:hetero_logistic_regression
ubuntu 18.04
docker version 18.06.3-ce
docker-compose version 1.24.0
If the ""count of data"" instance is 0 ""appears in the log, it means that the role side has not imported data, or there is a problem with data configuration@KathyKing Thanks very much.  I checked my data configuration and found no problem. Can you tell me the correct steps to achieve the hetero_lr task without quick_run.py?@KathyKing  I finally solved the problem. The reason is that table_name and space_name are inconsistent with the config setting. Thanks again ~ "	3	2019-12-12 12:57:20	2019-12-14 07:54:27	2019-12-14 07:54:27
https://github.com/FederatedAI/FATE/issues/830	[]	how to limit number of job running	how to limit number of job runninghow to configure each party to execute only one job at at time and the rest wait in queue. Currently multiple jobs will be executing at the same time and leads to out of memory and egg will crash.Modify the fate_flow/settings.py: MAX_CONCURRENT_JOB_RUN = 1 and restart fate_flow。	1	2019-12-09 07:58:03	2020-01-02 08:21:50	2020-01-02 08:21:49
https://github.com/FederatedAI/FATE/issues/827	[]	query for all tables	"query for all tablesCan party_id = A (fate_flow_client) query party_id= B to get a list of all table name and namespace uploaded successfully?

can this https://github.com/FederatedAI/FATE/blob/9d1d9010cbad9943a7657eed248069f0ed6160ee/fate_flow/doc/fate_flow_rest_api.md  be used to query another party's information. 

I have a scenario where as a party A, I would like to know table,namespace uploaded by party B. What is your advice?At present, there is no interface for querying the list of successfully uploaded table names and namespaces. Version 1.2 only provides an interface for querying the list of table names and namespaces uploaded by itself. For the query of other parties, it does not currently provide an interface.This is an unsafe operation which party A  can query info<name, namespace> in party B."	2	2019-12-06 08:56:13	2020-01-02 08:32:05	2020-01-02 08:32:05
https://github.com/FederatedAI/FATE/issues/824	[]	homo_breast_* example evaluation	"homo_breast_* example evaluationI able to run the homo_breast_* example with config file :test_multi_host_job_conf.json,  By default ""evaluation"" is run on the guest. 

When i change the config file evaluation_0 for ""Host"" to true in test_multi_host_job_conf.json, the job will fail to run. Can help to explain on this?

Also, where can we see the output of the model after ran the job successfully?

@cometta 

In the predict task, host send wx to arbiter and arbiter make the judgement of which class a sample belongs to. Therefore, a host has no way to get the predict score of samples which means the host cannot calculate the evaluation indicators such as auc etc. That's why we make evaluation module Inoperable. 

As for the second question, if you have deploy a fate-board, the model results will be avaiable in the visual interface. However, that is not your case, we recommend you obtain the model info by fate-flow cli whose documentation is located here:  https://github.com/FederatedAI/FATE/blob/master/fate_flow/doc/fate_flow_cli.md#component_output_model

Hope that is useful for you. 
"	1	2019-12-05 09:17:51	2019-12-06 16:17:31	2019-12-06 16:17:31
https://github.com/FederatedAI/FATE/issues/792	[]	logic in quick_run.py may not right.	"logic in quick_run.py may not right.In quick_run.py:if \__name\__ == '\__main\__'(),  the if/else statement below would print ValueError if the host only does `upload_data()'. However this is actually not an error which using a host to initiate a prediction. For example, if a user wants to do LR, he/she should use quick_run to upload host's data first. If doing so, the ValueError would be raised.

    try:
        args = parser.parse_args()
        upload_data()
        if TASK == 'train' and args.role == GUEST:
            submit_job()
        else:
            if args.role == HOST:
                raise ValueError(""Predict task can be initialed by guest only"")
            predict_task()


@TerrenceKao 

Thanks for your question. Quick_run is designed for user experience FATE quickly. What we designed in quick_run contains uploading data only in host (For training purpose), uploading and starting training in guest and starting predict task in guest. In predict task, we use the previews trained model as well as the trained data. That's why we have the logic you mentioned. 

However, it is really a good suggestion to develop scrips for easily using FATE which is not purpose on experiencement only. And we do working on it. Please look forward to our future releases. 

Thanks again for your question and hope that is useful for you. > @TerrenceKao
> 
> Thanks for your question. Quick_run is designed for user experience FATE quickly. What we designed in quick_run contains uploading data only in host (For training purpose), uploading and starting training in guest and starting predict task in guest. In predict task, we use the previews trained model as well as the trained data. That's why we have the logic you mentioned.
> 
> However, it is really a good suggestion to develop scrips for easily using FATE which is not purpose on experiencement only. And we do working on it. Please look forward to our future releases.
> 
> Thanks again for your question and hope that is useful for you.

got it. thanks!"	2	2019-11-25 09:30:37	2019-11-26 11:05:28	2019-11-26 11:05:28
https://github.com/FederatedAI/FATE/issues/788	[]	ERROR.log was not found on the guest side	"ERROR.log was not found on the guest side**Describe the bug**
On FATE v1.1, while running the toy example on the guest side, The fate flow server would report the `ERROR.log` was not found some time.

**Expected behavior**
Unknown, maybe it should not print this message.

**Screenshots**
The details of the error.
```
job status is running
Traceback (most recent call last):
  File ""run_toy_example.py"", line 196, in <module>
    exec_toy_example(runtime_config)
  File ""run_toy_example.py"", line 171, in exec_toy_example
    show_log(jobid, ""error"")
  File ""run_toy_example.py"", line 149, in show_log
    with open(error_log, ""r"") as fin:
FileNotFoundError: [Errno 2] No such file or directory: '/data/projects/fate/python/examples/toy_example/19112203250928712616_log/guest/10000/secure_add_example_0/ERROR.log'
```Thanks for your feedback: our tips will be more friendly in the future.
You can go to the corresponding job under fate_flow_schedule.log to see if there is an error log.Thank you for your reply, close now."	2	2019-11-23 07:54:43	2019-11-28 09:34:22	2019-11-28 09:34:22
https://github.com/FederatedAI/FATE/issues/773	[]	Quick Start-Cluster Version，task failed	"Quick Start-Cluster Version，task failedIn the host party,I run this command:   python quick_run.py -r host
In the guest party,I run the command:  python quick_run.py -r guest
The in the logs file ,I find the following message,How should I do?
`""2019-11-13 03:37:06,755 - dag_scheduler.py[line:60] - ERROR: there are no components in dsl, please have a check!""
Traceback (most recent call last):
  File ""/data/projects/fate/python/fate_flow/driver/dag_scheduler.py"", line 58, in handle_event
    return TaskScheduler.run_job(**job_event)
  File ""/data/projects/fate/python/fate_flow/driver/task_scheduler.py"", line 74, in run_job
    train_runtime_conf=train_runtime_conf)
  File ""/data/projects/fate/python/fate_flow/utils/job_utils.py"", line 162, in get_job_dsl_parser
    mode=job_type)
  File ""/data/projects/fate/python/fate_flow/driver/dsl_parser.py"", line 632, in run
    self._init_components(pipeline_dsl, mode)
  File ""/data/projects/fate/python/fate_flow/driver/dsl_parser.py"", line 113, in _init_components
    raise ValueError(""there are no components in dsl, please have a check!"")
ValueError: there are no components in dsl, please have a check!
`Now you can not submit task in hostI have the same Error when  I run min_test_task, @dylan-fan  Can explain these problem more detailed? Thank you very much！"	2	2019-11-12 10:52:35	2020-03-02 13:39:02	2020-03-02 13:39:02
https://github.com/FederatedAI/FATE/issues/733	[]	The first time I run ”python quick_run.py“, I get an error when I run it again.	"The first time I run ”python quick_run.py“, I get an error when I run it again.The first time I run **python quick_run.py**, I get an error when I run it again.

`Upload data config json: {'file': 'examples/data/breast_b.csv', 'head': 1, 'partition': 10, 'work_mode': 0, 'table_name': 'breast_b', 'namespace': 'breast_b_guest'}
stdout:{
    ""retcode"": 100,
    ""retmsg"": ""HTTPConnectionPool(host='127.0.0.1', port=9380): Max retries exceeded with url: /v1/data/upload (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f99233845f8>: Failed to establish a new connection: [Errno 111] Connection refused',))"",
    ""traceback"": [
        ""Traceback (most recent call last):\n"",
        ""  File \""/usr/local/lib/python3.6/site-packages/urllib3/connection.py\"", line 159, in _new_conn\n    (self._dns_host, self.port), self.timeout, **extra_kw)\n"",
        ""  File \""/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py\"", line 80, in create_connection\n    raise err\n"",
        ""  File \""/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py\"", line 70, in create_connection\n    sock.connect(sa)\n"",
        ""ConnectionRefusedError: [Errno 111] Connection refused\n"",
        ""\nDuring handling of the above exception, another exception occurred:\n\n"",
        ""Traceback (most recent call last):\n"",
        ""  File \""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py\"", line 600, in urlopen\n    chunked=chunked)\n"",
        ""  File \""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py\"", line 354, in _make_request\n    conn.request(method, url, **httplib_request_kw)\n"",
        ""  File \""/usr/local/lib/python3.6/http/client.py\"", line 1254, in request\n    self._send_request(method, url, body, headers, encode_chunked)\n"",
        ""  File \""/usr/local/lib/python3.6/http/client.py\"", line 1300, in _send_request\n    self.endheaders(body, encode_chunked=encode_chunked)\n"",
        ""  File \""/usr/local/lib/python3.6/http/client.py\"", line 1249, in endheaders\n    self._send_output(message_body, encode_chunked=encode_chunked)\n"",
        ""  File \""/usr/local/lib/python3.6/http/client.py\"", line 1036, in _send_output\n    self.send(msg)\n"",
        ""  File \""/usr/local/lib/python3.6/http/client.py\"", line 974, in send\n    self.connect()\n"",
        ""  File \""/usr/local/lib/python3.6/site-packages/urllib3/connection.py\"", line 181, in connect\n    conn = self._new_conn()\n"",
        ""  File \""/usr/local/lib/python3.6/site-packages/urllib3/connection.py\"", line 168, in _new_conn\n    self, \""Failed to establish a new connection: %s\"" % e)\n"",
        ""urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f99233845f8>: Failed to establish a new connection: [Errno 111] Connection refused\n"",
        ""\nDuring handling of the above exception, another exception occurred:\n\n"",
        ""Traceback (most recent call last):\n"",
        ""  File \""/usr/local/lib/python3.6/site-packages/requests/adapters.py\"", line 449, in send\n    timeout=timeout\n"",
        ""  File \""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py\"", line 638, in urlopen\n    _stacktrace=sys.exc_info()[2])\n"",
        ""  File \""/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py\"", line 399, in increment\n    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n"",
        ""urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=9380): Max retries exceeded with url: /v1/data/upload (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f99233845f8>: Failed to establish a new connection: [Errno 111] Connection refused',))\n"",
        ""\nDuring handling of the above exception, another exception occurred:\n\n"",
        ""Traceback (most recent call last):\n"",
        ""  File \""/usr/FATE/examples/federatedml-1.0-examples/../../fate_flow/fate_flow_client.py\"", line 213, in <module>\n    response = call_fun(args.function, config_data, dsl_path, config_path)\n"",
        ""  File \""/usr/FATE/examples/federatedml-1.0-examples/../../fate_flow/fate_flow_client.py\"", line 145, in call_fun\n    response = requests.post(\""/\"".join([server_url, \""data\"", func]), json=config_data)\n"",
        ""  File \""/usr/local/lib/python3.6/site-packages/requests/api.py\"", line 116, in post\n    return request('post', url, data=data, json=json, **kwargs)\n"",
        ""  File \""/usr/local/lib/python3.6/site-packages/requests/api.py\"", line 60, in request\n    return session.request(method=method, url=url, **kwargs)\n"",
        ""  File \""/usr/local/lib/python3.6/site-packages/requests/sessions.py\"", line 524, in request\n    resp = self.send(prep, **send_kwargs)\n"",
        ""  File \""/usr/local/lib/python3.6/site-packages/requests/sessions.py\"", line 637, in send\n    r = adapter.send(request, **kwargs)\n"",
        ""  File \""/usr/local/lib/python3.6/site-packages/requests/adapters.py\"", line 516, in send\n    raise ConnectionError(e, request=request)\n"",
        ""requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=9380): Max retries exceeded with url: /v1/data/upload (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f99233845f8>: Failed to establish a new connection: [Errno 111] Connection refused',))\n""
    ]
}


{
    ""retcode"": 100,
    ""retmsg"": [
        ""Traceback (most recent call last):\n"",
        ""  File \""quick_run.py\"", line 368, in <module>\n    upload_data()\n"",
        ""  File \""quick_run.py\"", line 348, in upload_data\n    upload(GUEST)\n"",
        ""  File \""quick_run.py\"", line 239, in upload\n    stdout = exec_upload_task(json_info, role)\n"",
        ""  File \""quick_run.py\"", line 120, in exec_upload_task\n    \""[Upload task]exec fail, status:{}, stdout:{}\"".format(status, stdout))\n"",
        ""ValueError: [Upload task]exec fail, status:100, stdout:{'retcode': 100, 'retmsg': \""HTTPConnectionPool(host='127.0.0.1', port=9380): Max retries exceeded with url: /v1/data/upload (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f99233845f8>: Failed to establish a new connection: [Errno 111] Connection refused',))\"", 'traceback': ['Traceback (most recent call last):\\n', '  File \""/usr/local/lib/python3.6/site-packages/urllib3/connection.py\"", line 159, in _new_conn\\n    (self._dns_host, self.port), self.timeout, **extra_kw)\\n', '  File \""/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py\"", line 80, in create_connection\\n    raise err\\n', '  File \""/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py\"", line 70, in create_connection\\n    sock.connect(sa)\\n', 'ConnectionRefusedError: [Errno 111] Connection refused\\n', '\\nDuring handling of the above exception, another exception occurred:\\n\\n', 'Traceback (most recent call last):\\n', '  File \""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py\"", line 600, in urlopen\\n    chunked=chunked)\\n', '  File \""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py\"", line 354, in _make_request\\n    conn.request(method, url, **httplib_request_kw)\\n', '  File \""/usr/local/lib/python3.6/http/client.py\"", line 1254, in request\\n    self._send_request(method, url, body, headers, encode_chunked)\\n', '  File \""/usr/local/lib/python3.6/http/client.py\"", line 1300, in _send_request\\n    self.endheaders(body, encode_chunked=encode_chunked)\\n', '  File \""/usr/local/lib/python3.6/http/client.py\"", line 1249, in endheaders\\n    self._send_output(message_body, encode_chunked=encode_chunked)\\n', '  File \""/usr/local/lib/python3.6/http/client.py\"", line 1036, in _send_output\\n    self.send(msg)\\n', '  File \""/usr/local/lib/python3.6/http/client.py\"", line 974, in send\\n    self.connect()\\n', '  File \""/usr/local/lib/python3.6/site-packages/urllib3/connection.py\"", line 181, in connect\\n    conn = self._new_conn()\\n', '  File \""/usr/local/lib/python3.6/site-packages/urllib3/connection.py\"", line 168, in _new_conn\\n    self, \""Failed to establish a new connection: %s\"" % e)\\n', 'urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f99233845f8>: Failed to establish a new connection: [Errno 111] Connection refused\\n', '\\nDuring handling of the above exception, another exception occurred:\\n\\n', 'Traceback (most recent call last):\\n', '  File \""/usr/local/lib/python3.6/site-packages/requests/adapters.py\"", line 449, in send\\n    timeout=timeout\\n', '  File \""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py\"", line 638, in urlopen\\n    _stacktrace=sys.exc_info()[2])\\n', '  File \""/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py\"", line 399, in increment\\n    raise MaxRetryError(_pool, url, error or ResponseError(cause))\\n', \""urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=9380): Max retries exceeded with url: /v1/data/upload (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f99233845f8>: Failed to establish a new connection: [Errno 111] Connection refused',))\\n\"", '\\nDuring handling of the above exception, another exception occurred:\\n\\n', 'Traceback (most recent call last):\\n', '  File \""/usr/FATE/examples/federatedml-1.0-examples/../../fate_flow/fate_flow_client.py\"", line 213, in <module>\\n    response = call_fun(args.function, config_data, dsl_path, config_path)\\n', '  File \""/usr/FATE/examples/federatedml-1.0-examples/../../fate_flow/fate_flow_client.py\"", line 145, in call_fun\\n    response = requests.post(\""/\"".join([server_url, \""data\"", func]), json=config_data)\\n', '  File \""/usr/local/lib/python3.6/site-packages/requests/api.py\"", line 116, in post\\n    return request(\\'post\\', url, data=data, json=json, **kwargs)\\n', '  File \""/usr/local/lib/python3.6/site-packages/requests/api.py\"", line 60, in request\\n    return session.request(method=method, url=url, **kwargs)\\n', '  File \""/usr/local/lib/python3.6/site-packages/requests/sessions.py\"", line 524, in request\\n    resp = self.send(prep, **send_kwargs)\\n', '  File \""/usr/local/lib/python3.6/site-packages/requests/sessions.py\"", line 637, in send\\n    r = adapter.send(request, **kwargs)\\n', '  File \""/usr/local/lib/python3.6/site-packages/requests/adapters.py\"", line 516, in send\\n    raise ConnectionError(e, request=request)\\n', \""requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=9380): Max retries exceeded with url: /v1/data/upload (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f99233845f8>: Failed to establish a new connection: [Errno 111] Connection refused',))\\n\""]}\n""
    ]
}
`Execute **sh /FATE/fate_flow/service.sh restart**, it's OK"	1	2019-10-29 12:17:15	2019-11-05 06:24:28	2019-11-05 06:24:28
https://github.com/FederatedAI/FATE/issues/701	[]	Float Cannot be Used as Random Seed	"Float Cannot be Used as Random Seed**Describe the bug**
When using float as random seed, it fails.

**To Reproduce**
Give float as a random seed in a training model job configuration file.

**Expected behavior**
Error indicates that float cannot be used as a random seed.
Float is not accepted as a random seed for bumpy random number generator. The check is not updated to give error message when float random seed is given."	1	2019-10-21 10:52:01	2019-10-21 10:54:43	2019-10-21 10:54:43
https://github.com/FederatedAI/FATE/issues/700	[]	Fix Encrypt Param Check	"Fix Encrypt Param Check**Describe the bug**
Encrypt param check fails to report error when invalid encrypt method is given.

**To Reproduce**
Set encrypt param's 'method' to any string value other than ""paillier."" Then submit training task. 

**Expected behavior**
Fails without error message on encrypt param.

Fix param check. Encrypt method check added. "	1	2019-10-21 10:05:25	2019-10-21 10:06:01	2019-10-21 10:06:01
https://github.com/FederatedAI/FATE/issues/699	[]	Fix Linear Regression Param Check	"Fix Linear Regression Param Check**Describe the bug**
Param check fails when learning rate or decay set to integer value.

**To Reproduce**
Set learning rate or decay in job configuration file to an integer. Then submit a training or CV job task.

**Expected behavior**
The job fails and gives error message indicating that the value is illegal. 
Fixed. 'float' type is now acceptable type for learning rate & decay input. "	1	2019-10-21 09:58:17	2019-10-21 09:58:44	2019-10-21 09:58:44
https://github.com/FederatedAI/FATE/issues/698	['bug']	Fix param check for Poisson Regression 	"Fix param check for Poisson Regression **Describe the bug**
Param check fails when learning rate or decay set to integer value.

**To Reproduce**
Set learning rate or decay in job configuration file to an integer. Then submit a training or CV job task.

**Expected behavior**
The job fails and gives error message indicating that the value is illegal. 
'float' is now added as acceptable type of learning rate & decay rate input. "	1	2019-10-21 09:56:16	2019-10-21 09:57:31	2019-10-21 09:57:31
https://github.com/FederatedAI/FATE/issues/697	['bug']	Fix Poisson Regression Predict BUG	"Fix Poisson Regression Predict BUG**Describe the bug**

When calling predict for evaluation during training, dataset's header does not match with the data. The original header is edited during training. 

**To Reproduce**
Submit a Poisson Regression training task. Within the configuration file, specify the exposure column name. The exposure column actually exists in the dataset.  

**Expected behavior**
The eggroll reports dimension mismatch. 
Bug fixed by creating another copy of header during training. "	1	2019-10-21 09:52:30	2019-10-21 09:53:14	2019-10-21 09:53:14
https://github.com/FederatedAI/FATE/issues/695	['bug']	Fix secureboost export_model bug when run cross validation	"Fix secureboost export_model bug when run cross validation**Describe the bug**
return None instead of raise error.fix this since FATE-1.1"	1	2019-10-21 09:50:38	2019-11-04 11:20:40	2019-11-04 11:20:40
https://github.com/FederatedAI/FATE/issues/693	['bug']	"Fix bugs of model_base's flowid, parameter check of some module, dsl_parser bug"""	"Fix bugs of model_base's flowid, parameter check of some module, dsl_parser bug""**Describe the bug**
Fix bugs of model_base's flowid, parameter check of some module(e.g. encrypted_model_calculator, encrypt, l, dsl_parser bug""
Fix this since FATE-1.1"	1	2019-10-21 09:43:13	2019-11-04 11:22:03	2019-11-04 11:22:03
https://github.com/FederatedAI/FATE/issues/685	[]	Unreasonable time consumption, in an epoch of the hetero LR.	"Unreasonable time consumption, in an epoch of the hetero LR.My input data size is 350,000, there are 6 features on the guest side, 6 features on the host side, running hetero LR on this data, it takes about 1 minute to run an epoch, we think the time is too long, not reasonable.

From the log, we counted the time consumption of each step:
（1）Guest compute the compute_forward (computation time): 15s （Is the “join” in compute_forward function consumes too long time?）
（2）Guest get host_forward from host (Communication time)：8s 
（3）Guest compute fore_gradient (computation time): 6s
（4）Host get fore_gradient from guest (Communication time)：16s
（5）Guest compute guest_gradient and loss (computation time)：13s
（6）Arbiter get guest_gradient (Communication time)：< 1s
（7）Guest get optim_guest_gradient from arbiter（Communication time）：< 1s

is the time consumption reasonable ,on the current data size? 

the dsl file : 
[test_hetero_lr_train_job_dsl.txt](https://github.com/FederatedAI/FATE/files/3743074/test_hetero_lr_train_job_dsl.txt)
the conf file ：
[test_hetero_lr_train_job_conf.txt](https://github.com/FederatedAI/FATE/files/3743086/test_hetero_lr_train_job_conf.txt)

the guest log ：
![image](https://user-images.githubusercontent.com/5690422/67081135-30259280-f1c9-11e9-97e9-a021963e09f5.png)
the host log ：
![image](https://user-images.githubusercontent.com/5690422/67081181-403d7200-f1c9-11e9-8bc1-2ca88a33a43d.png)
the arbiter log ：
![image](https://user-images.githubusercontent.com/5690422/67081220-51867e80-f1c9-11e9-96e0-b3922f7b0825.png)
@EmilyMu This time comsuming is normal. ""Join"" action is time comsuming for distributed computing. More importantly, the whole computation is finished in encryption mode. The Paillier encrypt method and computing through encryted number is time comsuming. 

Hope than is useful for you.@tanmc123 It seems that fake encryption is applied which costs no time
      ""encrypt_param"": {
         ""method"": ""Fake"",
         ""key_length"": 1024
      },
Both computation and communication takes more time than expected. Does the join op in computation cost much? It takes 8 seconds for the guest to receive 350k x 3 x 4=4.2MB info. from the host. Here, 3 is for tuple3 and 4 for bytes of float."	2	2019-10-18 09:04:47	2019-10-28 13:24:25	2019-10-28 11:18:10
https://github.com/FederatedAI/FATE/issues/683	[]	task failed, but task_executor.py on port 9380 still be alive	"task failed, but task_executor.py on port 9380 still be alive**Describe the bug**
    当我的任务失败时，发现9380端口上的服务还存在，并没有随着任务失败被关闭。
    我第一次使用hetero_lr/rmsprop/batch_size=2000训练数据，auc0.76是成功的，所以进行第二次尝试，将optimizer改为sgd，但是这次运行到iter=27时出错了，查看arbiter的日志，发现错误是""ask_executor.py[line:125] - ERROR: Overflow detected in decode number""。这时guest和host上的任务都显示失败了，虽然没有错误原因，但确实都显示task failed。但我查看系统进程，发现guest上的9380的服务并没有被杀掉，“python3 /data/projects/fate/python/fate_flow/driver/task_executor.py -j 2019101719574797565013 -n hetero_lr_0 -t 2019101719574797565013_hetero_lr_0 -r guest -p 10000 -c /data/projects/fate/python/jobs/2019101719574797565013/guest/10000/hetero_lr_0/task_config.json --job_server 127.0.0.1:9380”，如果这个进程还在，将会影响下一个任务的运行。所以我觉得这可能是个bug，这里我只能自己手动kill掉这个进程了。
    （顺便说一下，我任务中报的这个错误，发现是因为loss值太大了，已经e134次幂了，这可能因为我的数据引起的，改了sgd后，损失计算的问题，需要我进一步分析了。）
    不知这是否是一个bug，多谢开源！
@bigcash 
Thanks for your question and I apology that the question need to be answered in English. 

As you mentioned, there indeed exists a bug in fate-flow for killing failure task. in FATE1.0. When running a federated task, if the task in one party, let say Host party, failed, the task in Guest party will not be killed simultaneously even though it is killed in host. This bug will be fix in FATE1.1. Sorry for the misinformation. 

As for the exposure of loss, this might be caused by the un-normalized input data. Since we use Talor expansion to fit original loss function in encryption mode, it is quite sensitive for the scale of input data. 

Hope that is useful for you.@tanmc123 thank you, hope for new release FATE1.1."	2	2019-10-18 02:28:17	2019-11-05 01:38:45	2019-11-05 01:38:45
https://github.com/FederatedAI/FATE/issues/679	[]	wrong comments on function aggregate_forward() in hetero_lr_guest.py	"wrong comments on function aggregate_forward() in hetero_lr_guest.pyi doubt whether the comment on function aggregate_forward() in hetero_lr_guest.py is correct.
![image](https://user-images.githubusercontent.com/46129889/66902627-7c69aa80-eff0-11e9-838b-a6e2e075057c.png)


i think the context with red rectangle in above screenshot should be 
 [[ (wx_g + wx_h)^2 ]] = [[ wx_g^2 ]] + [[ wx_h^2 ]] + 2 * wx_g* [[ wx_h ]]

looking forward to your reply.Here, we use ""en_"" prefix to represent Paillier encryption. Therefore, the above formula is actually the same as yours. However, it is a good suggestion to replace them by [[ ]] symbol. Thank you for pointing out this problem. "	1	2019-10-16 08:46:50	2019-10-18 08:46:36	2019-10-18 08:46:36
https://github.com/FederatedAI/FATE/issues/660	[]	Bin num not match bug	"Bin num not match bug**Describe the bug**
In binning module, if the bin number smaller than the parameter bin_num, extra useless bin will be created. 
Already Finished"	1	2019-10-11 11:21:26	2019-10-14 08:52:15	2019-10-14 08:52:15
https://github.com/FederatedAI/FATE/issues/646	['bug']	Fix bugs of use same flowid in predicting when validating train and validate data during each training epoch	"Fix bugs of use same flowid in predicting when validating train and validate data during each training epoch**Describe the bug**
Use same flowid in predicting when validating train and validate data during each training epoch, which may cause some bugs in some algorithm.

fixed, see pr #647"	1	2019-10-10 07:42:23	2019-10-10 10:23:59	2019-10-10 10:23:59
https://github.com/FederatedAI/FATE/issues/640	[]	Cluster Host&Guest cannot receive pallier public key when running Hetero Logistic Regression training	"Cluster Host&Guest cannot receive pallier public key when running Hetero Logistic Regression trainingThe Guest and Hosts are waiting to get the keys but the Arbiter has already remote it. How do I go about debugging this?  Thank you
I suspect that the transferStatus is not updated, hence the Host/Guest keep waiting for the status to change from 0 to 3.

**Debug log from Guest (party id 10000), same for the Host as well(party id 90000)**
""2019-10-03 05:24:55,693 - task_executor.py[line:111] - INFO: {'data': {'data': ['intersection_0.train']}}""
""2019-10-03 05:24:55,694 - encrypt_param.py[line:65] - DEBUG: Finish encrypt parameter check!""
""2019-10-03 05:24:55,694 - model_base.py[line:61] - DEBUG: need_run: True, need_cv: False""
""2019-10-03 05:24:55,695 - model_base.py[line:223] - DEBUG: set flowid to transfer_variable, flowid: 201910030524353448356_hetero_lr_0.fit""
""2019-10-03 05:24:55,695 - hetero_lr_guest.py[line:102] - INFO: Enter hetero_lr_guest fit""
""2019-10-03 05:24:55,855 - federation.py[line:205] - DEBUG: [GET] guest 10000 :getting remote object HeteroLRTransferVariable.paillier_pubkey.201910030524353448356_hetero_lr_0.fit from arbiter [90000]""

**Debug log from Arbiter(party id 90000)**
""2019-10-03 05:22:00,112 - hetero_lr_arbiter.py[line:83] - INFO: Enter hetero_lr_arbiter fit""
""2019-10-03 05:22:00,120 - hetero_lr_arbiter.py[line:94] - INFO: public_key:<PaillierPublicKey ce341411cf>""
""2019-10-03 05:22:00,130 - eggroll.py[line:246] - DEBUG: created table: storage_type: LMDB, namespace: 201910030524353448356_hetero_lr_0, name: __federation__, partitions: 10, in_place_computing: False""
""2019-10-03 05:22:00,184 - federation.py[line:177] - DEBUG: [REMOTE] Sending 201910030524353448356_hetero_lr_0-HeteroLRTransferVariable.paillier_pubkey-HeteroLRTransferVariable.paillier_pubkey.201910030524353448356_hetero_lr_0.train-arbiter-90000-host-90000""
""2019-10-03 05:22:00,191 - federation.py[line:183] - DEBUG: [REMOTE] Sent HeteroLRTransferVariable.paillier_pubkey for job jobId: ""201910030524353448356_hetero_lr_0""
""2019-10-03 05:22:00,191 - hetero_lr_arbiter.py[line:100] - INFO: remote public_key to host""
""2019-10-03 05:22:00,206 - eggroll.py[line:246] - DEBUG: created table: storage_type: LMDB, namespace: 201910030524353448356_hetero_lr_0, name: __federation__, partitions: 10, in_place_computing: False""
""2019-10-03 05:22:00,266 - federation.py[line:177] - DEBUG: [REMOTE] Sending 201910030524353448356_hetero_lr_0-HeteroLRTransferVariable.paillier_pubkey-HeteroLRTransferVariable.paillier_pubkey.201910030524353448356_hetero_lr_0.train-arbiter-90000-guest-10000""
""2019-10-03 05:22:00,268 - federation.py[line:183] - DEBUG: [REMOTE] Sent HeteroLRTransferVariable.paillier_pubkey for job jobId: ""201910030524353448356_hetero_lr_0""
""2019-10-03 05:22:00,268 - hetero_lr_arbiter.py[line:107] - INFO: remote public_key to guest""Please check the deployment configuration, focusing on the Federation service."	1	2019-10-03 05:49:59	2019-11-05 06:29:12	2019-11-05 06:29:12
https://github.com/FederatedAI/FATE/issues/632	[]	run_toy_example.py——job running time exceed, please check federation or eggroll log——io.grpc.netty.shaded.io.netty.handler.codec.http2.Http2Exception$HeaderListSizeException: Header size exceeded max allowed size (8192)	"run_toy_example.py——job running time exceed, please check federation or eggroll log——io.grpc.netty.shaded.io.netty.handler.codec.http2.Http2Exception$HeaderListSizeException: Header size exceeded max allowed size (8192)**Describe the bug**
job running time exceed
io.grpc.netty.shaded.io.netty.handler.codec.http2.Http2Exception$HeaderListSizeException: Header size exceeded max allowed size (8192)

**To Reproduce**
### 1.when I run the:

**python run_toy_example.py 10001 10002 1**

I got this:
...
 job status is running
job status is running
Traceback (most recent call last):
  File ""run_toy_example.py"", line 197, in <module>
    exec_toy_example(runtime_config)
  File ""run_toy_example.py"", line 179, in exec_toy_example
    raise ValueError(""job running time exceed, please check federation or eggroll log"")
ValueError: job running time exceed, please check federation or eggroll log_

When I change the MAX_TIME from 10 to 30,the error is not changed.


### 2.then I check the egg and roll log
when I cat the **error.log on /data/projects/fate/roll/logs**

I got this:
Warning: Stream Error
io.grpc.netty.shaded.io.netty.handler.codec.http2.Http2Exception$HeaderListSizeException: Header size exceeded max allowed size (8192)
        at io.grpc.netty.shaded.io.netty.handler.codec.http2.Http2Exception.headerListSizeError(Http2Exception.java:171)
        at io.grpc.netty.shaded.io.netty.handler.codec.http2.Http2CodecUtil.headerListSizeExceeded(Http2CodecUtil.java:228)
        at io.grpc.netty.shaded.io.netty.handler.codec.http2.HpackEncoder.encodeHeadersEnforceMaxHeaderListSize(HpackEncoder.java:122)
        at io.grpc.netty.shaded.io.netty.handler.codec.http2.HpackEncoder.encodeHeaders(HpackEncoder.java:106)
        at io.grpc.netty.shaded.io.netty.handler.codec.http2.DefaultHttp2HeadersEncoder.encodeHeaders(DefaultHttp2HeadersEncoder.java:68)
        at io.grpc.netty.shaded.io.netty.handler.codec.http2.DefaultHttp2FrameWriter.writeHeadersInternal(DefaultHttp2FrameWriter.java:499)
        at io.grpc.netty.shaded.io.netty.handler.codec.http2.DefaultHttp2FrameWriter.writeHeaders(DefaultHttp2FrameWriter.java:266)
        at io.grpc.netty.shaded.io.netty.handler.codec.http2.Http2OutboundFrameLogger.writeHeaders(Http2OutboundFrameLogger.java:60)
        at io.grpc.netty.shaded.io.netty.handler.codec.http2.DecoratingHttp2FrameWriter.writeHeaders(DecoratingHttp2FrameWriter.java:53)
        at io.grpc.netty.shaded.io.grpc.netty.NettyServerHandler$WriteMonitoringFrameWriter.writeHeaders(NettyServerHandler.java:948)
        at io.grpc.netty.shaded.io.netty.handler.codec.http2.DefaultHttp2ConnectionEncoder.writeHeaders(DefaultHttp2ConnectionEncoder.java:205)
        at io.grpc.netty.shaded.io.netty.handler.codec.http2.DefaultHttp2ConnectionEncoder.writeHeaders(DefaultHttp2ConnectionEncoder.java:146)
        at io.grpc.netty.shaded.io.grpc.netty.NettyServerHandler.sendResponseHeaders(NettyServerHandler.java:638)
        at io.grpc.netty.shaded.io.grpc.netty.NettyServerHandler.write(NettyServerHandler.java:575)
        at io.grpc.netty.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
        at io.grpc.netty.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
        at io.grpc.netty.shaded.io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:816)
        at io.grpc.netty.shaded.io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:723)
        at io.grpc.netty.shaded.io.netty.channel.DefaultChannelPipeline.write(DefaultChannelPipeline.java:1061)
        at io.grpc.netty.shaded.io.netty.channel.AbstractChannel.write(AbstractChannel.java:295)
        at io.grpc.netty.shaded.io.grpc.netty.WriteQueue$AbstractQueuedCommand.run(WriteQueue.java:174)
        at io.grpc.netty.shaded.io.grpc.netty.WriteQueue.flush(WriteQueue.java:112)
        at io.grpc.netty.shaded.io.grpc.netty.WriteQueue.access$000(WriteQueue.java:32)
        at io.grpc.netty.shaded.io.grpc.netty.WriteQueue$1.run(WriteQueue.java:44)
        at io.grpc.netty.shaded.io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
        at io.grpc.netty.shaded.io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404)
        at io.grpc.netty.shaded.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:462)
        at io.grpc.netty.shaded.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
        at io.grpc.netty.shaded.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:748)


### when I cat the **/data/projects/fate/roll/logs/console.log**
I get this :

java.lang.RuntimeException: java.lang.reflect.InvocationTargetException
        at com.webank.ai.fate.eggroll.roll.api.grpc.client.EggProcessServiceClient.unaryProcessToStorageLocatorUnaryCall(EggProcessServiceClient.java:140)
        at com.webank.ai.fate.eggroll.roll.api.grpc.client.EggProcessServiceClient.mapValues(EggProcessServiceClient.java:58)
        at com.webank.ai.fate.eggroll.roll.service.async.processor.MapValuesServiceProcessor.call(MapValuesServiceProcessor.java:35)
        at com.webank.ai.fate.eggroll.roll.service.async.processor.MapValuesServiceProcessor.call(MapValuesServiceProcessor.java:26)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.reflect.InvocationTargetException
        at com.webank.ai.fate.core.api.grpc.client.GrpcStreamingClientTemplate.calleeStreamingRpcWithImmediateDelayedResult(GrpcStreamingClientTemplate.java:155)
        at com.webank.ai.fate.eggroll.roll.api.grpc.client.EggProcessServiceClient.unaryProcessToStorageLocatorUnaryCall(EggProcessServiceClient.java:138)
        ... 7 more
Caused by: io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
        at io.grpc.Status.asRuntimeException(Status.java:526)
        at io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:434)
        at io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39)
        at io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23)
        at io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40)
        at io.grpc.internal.CensusStatsModule$StatsClientInterceptor$1$1.onClose(CensusStatsModule.java:678)
        at io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39)
        at io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23)
        at io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40)
        at io.grpc.internal.CensusTracingModule$TracingClientInterceptor$1$1.onClose(CensusTracingModule.java:397)
        at io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:459)
        at io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:63)
        at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:546)
        at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:467)
        at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:584)
        at io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
        at io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
        ... 3 more
Caused by: io.grpc.netty.shaded.io.netty.channel.AbstractChannel$AnnotatedConnectException: 拒绝连接: /172.16.1.123:50013
        at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
        at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
        at io.grpc.netty.shaded.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
        at io.grpc.netty.shaded.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
        at io.grpc.netty.shaded.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
        at io.grpc.netty.shaded.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
        at io.grpc.netty.shaded.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
        at io.grpc.netty.shaded.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
        at io.grpc.netty.shaded.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
        at io.grpc.netty.shaded.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        ... 1 more
Caused by: java.net.ConnectException: 拒绝连接
        ... 11 more
        at com.webank.ai.fate.core.error.exception.MultipleRuntimeThrowables.<init>(MultipleRuntimeThrowables.java:32)
        ... 12 more


How can I deal with this problemI restart all the servers and the problem not be repeated"	1	2019-09-27 04:06:24	2019-09-28 01:06:04	2019-09-28 01:04:49
https://github.com/FederatedAI/FATE/issues/626	['bug']	Fix import error in eggroll api doc 	"Fix import error in eggroll api doc **Describe the bug**
There are some import path eggroll in eggroll_api doc, should be fixedalready pr, closed"	1	2019-09-26 10:01:26	2019-09-26 10:07:07	2019-09-26 10:07:07
https://github.com/FederatedAI/FATE/issues/625	[]	"when uploaded data with dimension 2.5 million * 150, it came up with ""_end_unary_response_blocking"" error"	"when uploaded data with dimension 2.5 million * 150, it came up with ""_end_unary_response_blocking"" error**Describe the bug**
Hi :
      when tried to upload data whose dimension is 2.5 million * 150, it came up with error logs in fate/python/jobs/*job_id*/std.log.

**logs**
 File ""/data/projects/fate/venv/lib/python3.6/site-packages/grpc/_channel.py"", line 625, in __call__
    return _end_unary_response_blocking(state, call, False, None)
  File ""/data/projects/fate/venv/lib/python3.6/site-packages/grpc/_channel.py"", line 467, in _end_unary_response_blocking
    raise _Rendezvous(state, None, None, deadline)
grpc._channel._Rendezvous: <_Rendezvous of RPC that terminated with:
        status = StatusCode.UNKNOWN
        details = ""Exception iterating requests!""
        debug_error_string = ""None""

This situation didn't appearance when upload small data set. I doubt whether it was caused by the data set is large. And what's the proper way to upload large data set.
![image](https://user-images.githubusercontent.com/46129889/65652763-645ec680-e002-11e9-920b-6322e36fd8df.png)
Please provide a log of the roll at the time, thank you.@zengjice sorry, i had delete the related logs. And after i change to another machine with bigger disk space to upload data, the issue was disappeared. I will attach the logs if encounter this issue in the future. thank you all the same."	2	2019-09-26 02:15:54	2019-11-05 06:32:34	2019-11-05 06:32:34
https://github.com/FederatedAI/FATE/issues/619	[]	secboost example run failed	"secboost example run failedHello,

I followed the README files and started fate_flow and fateboard successfully, and also successfully ran the lr example in `examples/federatedml-1.0-examples/hetero_logistic_regression`, however, task failed when I tried secboost example in `examples/federatedml-1.0-examples/hetero_secureboost`.

Below is my config:

version: v1.0.2
fate_flow server: standanloe mode, use sqlite db.

In examples/federatedml-1.0-examples/quick_run.py:
DSL_PATH = 'hetero_secureboost/test_secureboost_train_dsl.json'
SUBMIT_CONF_PATH = 'hetero_secureboost/test_secureboost_train_binary_conf.json'

and then quick_run.py prints:
```
Upload data config json: {'file': 'examples/data/breast_b.csv', 'head': 1, 'partition': 10, 'work_mode': 0, 'table_name': 'breast_b', 'namespace': 'breast_b_guest'}
stdout:{
    ""data"": {
        ""namespace"": ""breast_b_guest"",
        ""pid"": 24848,
        ""table_name"": ""breast_b""
    },
    ""jobId"": ""201909251558299848924"",
    ""meta"": null,
    ""retcode"": 0,
    ""retmsg"": ""success""
}


Upload data config json: {'file': 'examples/data/breast_a.csv', 'head': 1, 'partition': 10, 'work_mode': 0, 'table_name': 'breast_a', 'namespace': 'breast_a_host'}
stdout:{
    ""data"": {
        ""namespace"": ""breast_a_host"",
        ""pid"": 24853,
        ""table_name"": ""breast_a""
    },
    ""jobId"": ""201909251558331064515"",
    ""meta"": null,
    ""retcode"": 0,
    ""retmsg"": ""success""
}


dsl_path: /home/yuwen/repo/github/FATE/examples/federatedml-1.0-examples/user_config/train_dsl.config_1569398316_1861, conf_path: /home/yuwen/repo/github/FATE/examples/federatedml-1.0-examples/user_config/train_conf.config_1569398316_2790
stdout:{
    ""data"": {
        ""board_url"": ""http://30.54.206.135:8080/index.html#/dashboard?job_id=201909251558362437256&role=guest&party_id=10000"",
        ""job_dsl_path"": ""/home/yuwen/repo/github/FATE/jobs/201909251558362437256/job_dsl.json"",
        ""job_runtime_conf_path"": ""/home/yuwen/repo/github/FATE/jobs/201909251558362437256/job_runtime_conf.json"",
        ""model_info"": {
            ""model_id"": ""arbiter-10000#guest-10000#host-10000#model"",
            ""model_version"": ""201909251558362437256""
        }
    },
    ""jobId"": ""201909251558362437256"",
    ""meta"": null,
    ""retcode"": 0,
    ""retmsg"": ""success""
}

Please check your task in fate-board, url is : http://30.54.206.135:8080/index.html#/dashboard?job_id=201909251558362437256&role=guest&party_id=10000
The log info is located in /home/yuwen/repo/github/FATE/examples/federatedml-1.0-examples/../../logs/201909251558362437256
Task is running, wait time: 10.356188535690308
Task Failed
```

The job failed in dataio_1 section:
![image](https://user-images.githubusercontent.com/3414971/65581800-b8d85680-dfae-11e9-8127-12ad260c2ed9.png)

logs:
```
""2019-09-25 15:58:42,495 - model_manager.py[line:74] - INFO: parse DataIOMeta proto object normal""
""2019-09-25 15:58:42,503 - model_manager.py[line:74] - INFO: parse DataIOParam proto object normal""
""2019-09-25 15:58:42,628 - api_utils.py[line:70] - INFO: local api request: http://30.54.206.135:9380/v1/schedule/201909251558362437256/dataio_1/201909251558362437256_dataio_1/host/10000/status""
""2019-09-25 15:58:42,736 - api_utils.py[line:73] - INFO: {""data"":null,""jobId"":null,""meta"":null,""retcode"":0,""retmsg"":""success""}
""
""2019-09-25 15:58:42,736 - api_utils.py[line:75] - INFO: local api response: /v1/schedule/201909251558362437256/dataio_1/201909251558362437256_dataio_1/host/10000/status {'data': None, 'jobId': None, 'meta': None, 'retcode': 0, 'retmsg': 'success'}""
""2019-09-25 15:58:42,736 - task_executor.py[line:109] - INFO: run 201909251558362437256 dataio_1 201909251558362437256_dataio_1 host 10000 task""
""2019-09-25 15:58:42,736 - task_executor.py[line:110] - INFO: {'DataIOParam': {'input_format': 'dense', 'delimitor': ',', 'data_type': 'float64', 'tag_with_value': False, 'tag_value_delimitor': ':', 'missing_fill': False, 'default_value': 0, 'missing_fill_method': None, 'missing_impute': None, 'outlier_replace': False, 'outlier_replace_method': None, 'outlier_impute': None, 'outlier_replace_value': 0, 'with_label': True, 'label_idx': 0, 'label_type': 'int', 'output_format': 'dense'}, 'initiator': {'role': 'guest', 'party_id': 10000}, 'job_parameters': {'work_mode': 0, 'model_id': 'arbiter-10000#guest-10000#host-10000#model', 'model_version': '201909251558362437256'}, 'role': {'guest': [10000], 'host': [10000], 'arbiter': [10000]}, 'config': '/home/yuwen/repo/github/FATE/examples/federatedml-1.0-examples/user_config/train_conf.config_1569398316_2790', 'dsl': '/home/yuwen/repo/github/FATE/examples/federatedml-1.0-examples/user_config/train_dsl.config_1569398316_1861', 'function': 'submit_job', 'local': {'role': 'host', 'party_id': 10000}, 'CodePath': 'federatedml/util/data_io.py/DataIO', 'module': 'DataIO'}""
""2019-09-25 15:58:42,736 - task_executor.py[line:111] - INFO: {'data': {'data': ['args.eval_data']}, 'model': ['dataio_0.dataio']}""
""2019-09-25 15:58:42,736 - data_io.py[line:108] - INFO: start to read dense data and change data to instance""
""2019-09-25 15:58:42,747 - task_executor.py[line:123] - ERROR: Count of data_instance is 0""
Traceback (most recent call last):
  File ""/home/yuwen/repo/github/FATE/fate_flow/driver/task_executor.py"", line 112, in run_task
    run_object.run(parameters, task_run_args)
  File ""/home/yuwen/repo/github/FATE/federatedml/model_base.py"", line 188, in run
    self._run_data(args[""data""], stage)
  File ""/home/yuwen/repo/github/FATE/federatedml/model_base.py"", line 161, in _run_data
    self.data_output = self.transform(data)
  File ""/home/yuwen/repo/github/FATE/federatedml/util/data_io.py"", line 741, in transform
    return self.reader.read_data(data_inst, ""transform"")
  File ""/home/yuwen/repo/github/FATE/federatedml/util/data_io.py"", line 110, in read_data
    abnormal_detection.empty_table_detection(input_data)
  File ""/home/yuwen/repo/github/FATE/federatedml/util/abnormal_detection.py"", line 25, in empty_table_detection
    raise ValueError(""Count of data_instance is 0"")
ValueError: Count of data_instance is 0
""2019-09-25 15:58:42,747 - api_utils.py[line:70] - INFO: local api request: http://30.54.206.135:9380/v1/schedule/201909251558362437256/dataio_1/201909251558362437256_dataio_1/host/10000/status""
""2019-09-25 15:58:42,917 - api_utils.py[line:73] - INFO: {""data"":null,""jobId"":null,""meta"":null,""retcode"":0,""retmsg"":""success""}
""
""2019-09-25 15:58:42,917 - api_utils.py[line:75] - INFO: local api response: /v1/schedule/201909251558362437256/dataio_1/201909251558362437256_dataio_1/host/10000/status {'data': None, 'jobId': None, 'meta': None, 'retcode': 0, 'retmsg': 'success'}""
""2019-09-25 15:58:42,917 - task_executor.py[line:137] - INFO: finish 201909251558362437256 dataio_1 201909251558362437256_dataio_1 host 10000 failed task""
```

It seems like input data is empty, but `dataio_0` do have output data successfully, so can you help me?hello! could you include your quick_run.py code? I suspect the problem lies in the ""submit_job"" function @usafchn Dataio_0  not passes data to dataio_1, it only passes model to dataio_1, so you should also upload dataio_1's data. @mgqa34 thanks, I solved this problemhello~ I have met the same problem, Could you tell me how to solve this problem.@4Details   example 中默认的 DSL 定义有问题，节点`dataio_1`只有模型输入，没有数据输入，改一下 DSL 配置就行了"	5	2019-09-25 08:23:07	2019-11-25 08:16:48	2019-10-11 12:25:47
https://github.com/FederatedAI/FATE/issues/588	[]	Support  validation data evaluation during training process. 	"Support  validation data evaluation during training process. **Is your feature request related to a problem? Please describe.**
Support validation data evaluate during training process, for examples, evaluates validation data after each epoch. Since FATE-1.1, hetero(homo)-lr\secureboost\hetero-linr\hetero-poisson-regression support evaluate data during training ! "	1	2019-09-18 02:29:26	2019-11-04 11:26:00	2019-11-04 11:26:00
https://github.com/FederatedAI/FATE/issues/584	[]	An InterSect  Issue	"An InterSect  Issue**Describe the bug**
A clear and concise description of what the bug is.

**To Reproduce**
Steps to reproduce the behavior:
1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error

**Expected behavior**
A clear and concise description of what you expected to happen.

**Screenshots**
If applicable, add screenshots to help explain your problem.

**Desktop (please complete the following information):**
 - OS: [e.g. iOS]
 - Browser [e.g. chrome, safari]
 - Version [e.g. 22]

**Smartphone (please complete the following information):**
 - Device: [e.g. iPhone6]
 - OS: [e.g. iOS8.1]
 - Browser [e.g. stock browser, safari]
 - Version [e.g. 22]

**Additional context**
Add any other context about the problem here.
Some Editing:

run.sh guest fast host_table_name_1567432160_7370 host_table_namespace_1567432160_7370 

then something occured below,and there is no errors in logs; .... 

[Intersect] Start intersect job status checker, status counter: 56, jobid:201909022152082643742 [Intersect] cur job status:running, wait_time: 583.2567648887634 
[Intersect] Start intersect job status checker, status counter: 57, jobid:201909022152082643742 [Intersect] cur job status:running, wait_time: 593.5020263195038 
[Intersect] Start intersect job status checker, status counter: 58, jobid:201909022152082643742 [Intersect] cur job status:running, wait_time: 603.73965716362 
[Intersect] reach max intersect time:{}, intersect task may be failed, and exit now Traceback (most recent call last): File ""/data/projects/fate/python/examples/min_test_task/run_task.py"", line 500, in  raise ValueError(""intersect task is failed"") ValueError: intersect task is failed

In FATE-Official-Technical-Exchange Wechat group, I saw that your problem have fixed. Do you have any other question ?  If not, this issue will be closed soon. "	2	2019-09-16 02:06:48	2019-09-17 05:52:31	2019-09-17 05:52:31
https://github.com/FederatedAI/FATE/issues/583	[]	How to change the default selected evaluation scores?	"How to change the default selected evaluation scores?I use the docker version of FATE over Standalone. And I run the experiment about the hetero_secure_boost algorithm with my data by quick_run.py.

In the evaluation_0 module of the FATE board,  I found the default selected evaluation scores are AUC and K-S. 

If I want to use the accuracy with thresholds and the auc, what should I do? Another question: what is the meaning of party id in quick_run.py? If I adopt a different dataset, should I modify its value?please check the figure of evaluation in board， it should has accuracy， roc .... if not, check the log of evaluation to find if something error or warning. the party id is the ID of role, for example, guest:9999, host:10000. It is nothing to do with what dataset you use![image](https://user-images.githubusercontent.com/17498125/65022169-0b889180-d963-11e9-9bf2-ed0d225ce662.png)
I mean in this figure, how to change the auc and ks to auc and acc?

> please check the figure of evaluation in board， it should has accuracy， roc .... if not, check the log of evaluation to find if something error or warning.

![image](https://user-images.githubusercontent.com/19305597/65025832-01b65c80-d96a-11e9-9e34-d8967d580c8f.png)
I could obtain these curves. But I want to display the above table with different items. In here,  they are auc and ks. But if I want to use auc and acc, what should I do?You can not do this only if you change the code of evaluation. FATE's evaluation now support fixed format of evaluate output.> You can not do this only if you change the code of evaluation. FATE's evaluation now support fixed format of evaluate output.

Fine, thanks your help."	8	2019-09-15 08:48:26	2019-09-17 09:16:46	2019-09-17 09:16:46
https://github.com/FederatedAI/FATE/issues/579	[]	io_exception rpc	"io_exception rpchelp!
when i run  python run_toy_example.py 9999 10000 1,it get errors,
what cause this error,how can i slove it?

Traceback (most recent call last):
  File ""/data/projects/fate/python/fate_flow/utils/api_utils.py"", line 55, in remote_api
    _return = stub.unaryCall(_packet)
  File ""/home/app/anaconda3/lib/python3.6/site-packages/grpc/_channel.py"", line 533, in __call__
    return _end_unary_response_blocking(state, call, False, None)
  File ""/home/app/anaconda3/lib/python3.6/site-packages/grpc/_channel.py"", line 467, in _end_unary_response_blocking
    raise _Rendezvous(state, None, None, deadline)
grpc._channel._Rendezvous: <_Rendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = ""io exception""
	debug_error_string = ""{""created"":""@1568210336.533187742"",""description"":""Error received from peer"",""file"":""src/core/lib/surface/call.cc"",""file_line"":1017,""grpc_message"":""io exception"",""grpc_status"":14}""this is my ports desc
<img width=""368"" alt=""image"" src=""https://user-images.githubusercontent.com/26199641/64704519-0483fe00-d4e1-11e9-9edb-f2d7d91ac2ee.png"">
processor的服务没启动： 1、cd /data/projects/fate/egg sh service.sh stop 
2、cd /data/projects/fate/python sh service.sh start sh service.sh stop
 3、cd /data/projects/fate/egg sh service.sh start my processor is on, but the problem is still confuse me!
the error  occur again "	3	2019-09-11 14:09:29	2019-09-17 05:52:59	2019-09-17 05:52:59
https://github.com/FederatedAI/FATE/issues/566	[]	Sometimes misreporting occurs, ValueError: job running time exceed, please check federation or eggroll log	"Sometimes misreporting occurs, ValueError: job running time exceed, please check federation or eggroll logwhen I run :
`python run_toy_example.py 10000 10000 1`
I got this:
```
...
job status is running
job status is running
Traceback (most recent call last):
  File ""run_toy_example.py"", line 197, in <module>
    exec_toy_example(runtime_config)
  File ""run_toy_example.py"", line 179, in exec_toy_example
    raise ValueError(""job running time exceed, please check federation or eggroll log"")
ValueError: job running time exceed, please check federation or eggroll log
```

I checked run_toy_example.py and found `MAX_TIME = 10`
This value may be too small. It should be changed to 20.In ToyExample' default runtime conf , data size is 1000, and partition num is 10, there are only several kilobytes network transmission, so we think 10 seconds are enough.  By the way, after changed to 20s, do your job finish successfully ? If it is 10, it will fail for the first time. If it changes to 20, it will always succeed.We will take this issue into consideration. Thanks for your feedback!We  change MAX_TIME = 10 to MAX_TIME = 100 since FATE-1.1, hope this will help."	4	2019-09-09 07:21:37	2019-11-04 11:27:04	2019-11-04 11:27:03
https://github.com/FederatedAI/FATE/issues/549	[]	No module named 'federatedml.param.param' when run 'run_ftl_ct_standalone.sh'	"No module named 'federatedml.param.param' when run 'run_ftl_ct_standalone.sh'**Describe the bug**
When I run the script `run_ftl_ct_standalone.sh`, it raise ModuleNotFoundError. Like this:
```
Traceback (most recent call last):
  File ""run_arbiter.py"", line 19, in <module>
    from workflow.hetero_ftl_workflow.hetero_arbiter_workflow import FTLArbiterWorkFlow
  File ""/fate/workflow/hetero_ftl_workflow/hetero_arbiter_workflow.py"", line 19, in <module>
    from federatedml.ftl.hetero_ftl.hetero_ftl_arbiter import HeteroFTLArbiter
  File ""/fate/federatedml/ftl/hetero_ftl/hetero_ftl_arbiter.py"", line 24, in <module>
    from federatedml.param.param import FTLModelParam
ModuleNotFoundError: No module named 'federatedml.param.param'
```

**To Reproduce**
Steps to reproduce the behavior:
1. Go to folder `hetero_ftl`
2. Run the script `sh run_ftl_ct_standalone.sh 123`
3. See error on `arbiter.log`
hello,
Please provide the version of the FATE you deployed. And you can check the PYTHONPATH."	1	2019-09-05 08:50:04	2019-11-05 06:30:49	2019-11-05 06:30:49
https://github.com/FederatedAI/FATE/issues/540	[]	KFold remote index bug	"KFold remote index bug**Describe the bug**
When synchronizing data in KFold, the index  is mismatched.  
Already Fixed"	1	2019-09-04 09:49:39	2019-09-16 02:59:50	2019-09-16 02:59:49
https://github.com/FederatedAI/FATE/issues/522	[]	sh run.sh guest fast ${host_table} ${host_namespace} failed	"sh run.sh guest fast ${host_table} ${host_namespace} failedHello!
When I run:
sh run.sh guest fast host_table_name_1567432160_7370  host_table_namespace_1567432160_7370
then something occured below,and there is no errors in logs;
....
[Intersect] Start intersect job status checker, status counter: 56, jobid:201909022152082643742
[Intersect] cur job status:running, wait_time: 583.2567648887634
[Intersect] Start intersect job status checker, status counter: 57, jobid:201909022152082643742
[Intersect] cur job status:running, wait_time: 593.5020263195038
[Intersect] Start intersect job status checker, status counter: 58, jobid:201909022152082643742
[Intersect] cur job status:running, wait_time: 603.73965716362
[Intersect] reach max intersect time:{}, intersect task may be failed, and exit now
Traceback (most recent call last):
  File ""/data/projects/fate/python/examples/min_test_task/run_task.py"", line 500, in <module>
    raise ValueError(""intersect task is failed"")
ValueError: intersect task is failed
*********************
*******finish!*******i meet this problem，can you tell me hwo do you slove it!i meet this problem too，can you tell me hwo do you slove it!"	2	2019-09-02 14:08:08	2019-09-27 09:23:15	2019-09-12 01:14:39
https://github.com/FederatedAI/FATE/issues/518	['bug']	Fix bug: when run quick_run.py raise ImportError: cannot import name 'itemgetter'	"Fix bug: when run quick_run.py raise ImportError: cannot import name 'itemgetter'**Describe the bug**
When run the script of quick_run.py, it will rasie ImportError like this:
```
stdout:Traceback (most recent call last):
  File ""/home/wy/FATE/examples/federatedml-1.0-examples/../../fate_flow/fate_flow_client.py"", line 17, in <module>
    import argparse
  File ""/home/wy/.pyenv/versions/3.6.0/lib/python3.6/argparse.py"", line 86, in <module>
    import collections as _collections
  File ""/home/wy/.pyenv/versions/3.6.0/lib/python3.6/collections/__init__.py"", line 26, in <module>
    from operator import itemgetter as _itemgetter, eq as _eq
ImportError: cannot import name 'itemgetter'
```

**To Reproduce**
Steps to reproduce the behavior:
1. Go to 'python quick_run.py'
2. See error
@shikanon this error is relative to python's import system behavior.  The module `collections` fails to  import the standards module `operator`  because there is a same file named `operator` under the same directory with fate_flow_client.  But this won't be a problem in python 3.6 unless fate_flow/  was manually added to  `PATHTHONPATH` environment. "	1	2019-08-29 16:35:51	2019-09-05 12:23:13	2019-09-05 12:23:13
https://github.com/FederatedAI/FATE/issues/506	[]	Host should be able to store models with non-encrypted version in HomoLR	"Host should be able to store models with non-encrypted version in HomoLR**Is your feature request related to a problem? Please describe.**
Currently, there is no way for homo-lr host party to store models.
May I get your wechat please? I have some questions to ask you...I am a PHD student from Xi'an jiaotong university."	2	2019-08-26 02:52:30	2019-11-05 01:40:15	2019-11-05 01:40:15
https://github.com/FederatedAI/FATE/issues/502	['bug']	meet a bug when running logistic regression example	"meet a bug when running logistic regression exampleHi, I met a python bug when runing ""homo_logistic_regression"" example.It is shown blow:
```shell
sh-4.2$ python /data/projects/FATE/fate_flow/fate_flow_client.py -f submit_job -c /data/projects/FATE/examples/federatedml-1.0-examples/homo_logistic_regression/test_homolr_evaluate_job_conf.json -d /data/projects/FATE/examples/federatedml-1.0-examples/homo_logistic_regression/test_homolr_evaluate_job_dsl.json
Traceback (most recent call last):
  File ""/data/projects/FATE/fate_flow/fate_flow_client.py"", line 17, in <module>
    import argparse
  File ""/data/projects/common/miniconda3/lib/python3.7/argparse.py"", line 87, in <module>
    import re as _re
  File ""/data/projects/common/miniconda3/lib/python3.7/re.py"", line 125, in <module>
    import functools
  File ""/data/projects/common/miniconda3/lib/python3.7/functools.py"", line 21, in <module>
    from collections import namedtuple
  File ""/data/projects/common/miniconda3/lib/python3.7/collections/__init__.py"", line 21, in <module>
    from operator import itemgetter as _itemgetter, eq as _eq
ImportError: cannot import name 'itemgetter' from 'operator' (/data/projects/FATE/fate_flow/operator/__init__.py)
```

I dont know where is the missing lib from, FATE project or standard python libs？And how can I solve the problem?https://github.com/FederatedAI/FATE/issues/518ok, thank you"	2	2019-08-23 06:50:56	2019-09-02 08:21:10	2019-09-02 08:21:10
https://github.com/FederatedAI/FATE/issues/459	['bug']	The Process running WorkFlow cannot stop	"The Process running WorkFlow cannot stop**Describe the bug**
When put Workflow subclasses such as IntersectHostWorkFlow, IntersectGuestWorkFlow in a Process and start it in ** STANDALONE ** mode, the process will not return from join()

**To Reproduce**
Run the following code under the root directory and it will not stop. The root cause is Executor in Standalone does not  call shutdown after submit futures.
```
import uuid

import sys
from multiprocessing import Process

from arch.api import eggroll, RuntimeInstance
from arch.api.storage import save_data
from examples.load_file.load_file import read_data
from workflow.intersect_workflow.intersect_guest_workflow import IntersectGuestWorkFlow
from workflow.intersect_workflow.intersect_host_workflow import IntersectHostWorkFlow

guest_partyid=10000
host_partyid=9999
work_mode=0
a_file = r'examples/data/breast_a.csv'
b_file = r'examples/data/breast_b.csv'
a_table = 'a_table'
b_table = 'b_table'
namespace = 'test_workflow'


def upload_file(file, table):
    data = read_data(a_file)
    save_data(data, table, namespace)

def start_guest(job_id):
    guest_conf = '''
    {
  ""local"": {
    ""role"": ""guest"",
    ""party_id"": 10000
  },
  ""role"": {
    ""host"": [
      9999
    ],
    ""guest"": [
      10000
    ]
  },
  ""DataIOParam"": {
    ""with_label"": false,
    ""partition"": 1
  },
  ""WorkFlowParam"": {
    ""method"": ""intersect"",
    ""data_input_table"": ""a_table"",
    ""data_input_namespace"": ""test_workflow"",
    ""intersect_data_output_table"": ""guest_output_table"",
    ""intersect_data_output_namespace"": ""output"",
    ""work_mode"": 0
  },
  ""IntersectParam"": {
    ""intersect_method"": ""rsa"",
    ""random_bit"": 128,
    ""is_send_intersect_ids"": true,
    ""is_get_intersect_ids"": true,
    ""join_role"": ""host"",
    ""with_encode"": true,
    ""only_output_key"": true
  },
  ""EncodeParam"": {
    ""encode_method"": ""sha256"",
    ""salt"": ""12345"",
    ""base64"": false
  }
}
'''
    with open('guest.conf', 'w') as f:
        f.write(guest_conf)
    sys.argv.extend(['-c', 'guest.conf', '-j', job_id])
    guest_wf = IntersectGuestWorkFlow()
    print('guest_wf start running')
    guest_wf.run()
    print('guest_wf stop running')


def start_host(job_id):
    host_conf = '''
    {
  ""local"": {
    ""role"": ""host"",
    ""party_id"": 9999
  },
  ""role"": {
    ""host"": [
      9999
    ],
    ""guest"": [
      10000
    ]
  },
  ""DataIOParam"": {
    ""with_label"": false,
    ""partition"": 1
  },
  ""WorkFlowParam"": {
    ""method"": ""intersect"",
    ""data_input_table"": ""b_table"",
    ""data_input_namespace"": ""test_workflow"",
    ""intersect_data_output_table"": ""host_output_table"",
    ""intersect_data_output_namespace"": ""output"",
    ""work_mode"": 0
  },
  ""IntersectParam"": {
    ""intersect_method"": ""rsa"",
    ""random_bit"": 128,
    ""is_send_intersect_ids"": true,
    ""is_get_intersect_ids"": true,
    ""join_role"": ""host"",
    ""with_encode"": true,
    ""only_output_key"": true
  },
  ""EncodeParam"": {
    ""encode_method"": ""sha256"",
    ""salt"": ""12345"",
    ""base64"": false
  }
}
'''
    with open('host.conf', 'w') as f:
        f.write(host_conf)
    sys.argv.extend(['-c', 'host.conf', '-j', job_id])
    host_wf = IntersectHostWorkFlow()
    print('host_wf start running')
    host_wf.run()
    print('host_wf stop running')


if __name__ == '__main__':
    job_id = str(uuid.uuid1().hex)
    eggroll.init(job_id=job_id, mode=0)
    ps = [Process(target=upload_file, args=(file, table))for file, table in ((a_file, a_table), (b_file, b_table))]
    for p in ps:
        p.start()
    for p in ps:
        p.join()
    job_id = 'intersection_' + str(uuid.uuid1())
    print('job_id:', job_id)
    ps = [Process(target=fun, args=(job_id,)) for fun in (start_guest, start_host)]
    for p in ps:
        p.start()
    for p in ps:
        p.join()
```


hello，can you give me your email， we can discuss detail about your pr requestHi, my email is cleaner.leon@outlook.com<mailto:cleaner.leon@outlook.com>. I am also in wechat group “FinTechathon  AI赛道十强群” with name “F4-卫巍”, and we may talk about the issue in wechat.

Sent from Mail<https://go.microsoft.com/fwlink/?LinkId=550986> for Windows 10

________________________________
发件人: dylan-fan <notifications@github.com>
发送时间: Wednesday, August 21, 2019 11:22:09 AM
收件人: WeBankFinTech/FATE <FATE@noreply.github.com>
抄送: cleanerleon <cleaner.leon@outlook.com>; Author <author@noreply.github.com>
主题: Re: [WeBankFinTech/FATE] The Process running WorkFlow cannot stop (#459)


hello，can you give me your email， we can discuss detail about your pr request

―
You are receiving this because you authored the thread.
Reply to this email directly, view it on GitHub<https://github.com/WeBankFinTech/FATE/issues/459?email_source=notifications&email_token=AE4E35ZCA5LOFLA2TVIPBWDQFSYGDA5CNFSM4IMLFX22YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD4YJWHI#issuecomment-523279133>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AE4E355HUZEIN4QKXHIGSLLQFSYGDANCNFSM4IMLFX2Q>.
"	2	2019-08-16 17:07:57	2019-11-05 06:22:26	2019-11-05 06:22:26
https://github.com/FederatedAI/FATE/issues/453	[]	Question about the usage of ftl	"Question about the usage of ftlHi, I've read the code and the paper about ftl. In my mind, the typical scene of using ftl is when there are not so many overlapped samples. But during the inference or serving, seems we still need to make sure that the sample to be predict appears in both sides. Does it mean we should use ftl in scenes when we have rare overlapped samples during training but have enough overlapped samples for predicting?I read the paper again and maybe I misunderstood the transfer algorithm. During the inference process, we need features from the host(B side) and caculated phi from guest(A side), so there is no need for overlapping, right?
"	1	2019-08-16 07:52:42	2021-07-02 08:07:20	2021-07-02 08:07:20
https://github.com/FederatedAI/FATE/issues/392	[]	the prediction can only predict part of the input data table	"the prediction can only predict part of the input data tableHello, when I run the ""predict"" mode in the cluster form, initially, the prediction work well for about 20000 samples when the num_trees = 2, while when the model is trained by the num_trees = 10, the prediction can only predict part of the input data table. 

And I found the problem can be associated with the processor launched by the ""egg"" module. However, there is no place that I can find the exception information in the egg nor in the processor logs file. And the port range from 50001 to 50008 which are all active after checking.

I am confused about the stability of the trained model, can anyone give me some suggestions?Can you check logs in roll ? Maybe help with error\console.log under roll's log directory"	1	2019-08-08 08:52:12	2019-08-22 10:09:33	2019-08-22 10:09:33
https://github.com/FederatedAI/FATE/issues/390	[]	Cluster deployment problem	"Cluster deployment problemHello, I meet a problem when I deploy the cluster version FATE in a linux server, the OS of the server is centos6.5. 
It failed in the step of running ""bash auto-deploy.sh"".  
<img width=""800"" alt=""image-20190808094139603"" src=""https://user-images.githubusercontent.com/9210893/62669614-c61b9080-b9c2-11e9-9ac4-dc8a79395fde.png"">
The result is shown like above. When I typed the password of user ""app"" which I masked in screenshot, it was blocked for a while and then disconnected from the server. 
BTW, I edited ""configurations.sh"" file following the issue https://github.com/WeBankFinTech/FATE/issues/278. And just modify the ip, I wonder if there is problem with my process, Thank you.The operating system requires centos7.2, and it is recommended to use 7.2.
In addition, the app user needs to be free from sudo to root and needs to be configured.
please try,thanks.> The operating system requires centos7.2, and it is recommended to use 7.2.
> In addition, the app user needs to be free from sudo to root and needs to be configured.
> please try,thanks.

Ok, I will try the deployment on Centos7.2.
I have given the app user root right, and you mentioned ""the app user needs to be configured"", I am not sure which step you mean, would you mind be more specific, thank you so much!"	2	2019-08-08 01:55:27	2019-08-22 09:55:57	2019-08-22 09:55:57
https://github.com/FederatedAI/FATE/issues/385	[]	"when i run logistic_regression,i come to ""fail to post status running"" problem"	"when i run logistic_regression,i come to ""fail to post status running"" problemconfig path is /opt/FATE/examples/hetero_logistic_regression/conf/arbiter_runtime_conf.json_hetero_logistic_regression_example_standalone_20190806234846
jobid is hetero_logistic_regression_example_standalone_20190806234846
fail to post status running
Finish encrypt parameter check!
Finish evaluation parameter check!
Finish predict parameter check!
Finish predict parameter check!
Finish evaluation parameter check!
Finish workerflow parameter check!
Finish init parameter check!
Finish encode parameter check!
Finish encode parameter check!
Finish intersect parameter check!
Finish init parameter check!
Finish encrypt parameter check!
Finish logistic parameter check!
Finish encrypt parameter check!
Finish scale parameter check!
Finish one_vs_rest parameter check!
Finish all parameter checkers
Get in base workflow initialize
Finish init parameter check!
Finish encrypt parameter check!
Finish logistic parameter check!
Finish predict parameter check!
Finish evaluation parameter check!
Finish workerflow parameter check!if the PYTHONPATH been set ?long time no reply, close this issue"	2	2019-08-06 15:59:08	2019-08-20 14:08:04	2019-08-20 14:08:04
https://github.com/FederatedAI/FATE/issues/299	[]	bug when test FATE	"bug when test FATEbug report:
start to run test /fate/federatedml/test/../feature/test/quantile_binning_test.py
.E
======================================================================
ERROR: test_quantile_binning (__main__.TestQuantileBinningSpeed)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/fate/federatedml/test/../feature/test/quantile_binning_test.py"", line 140, in test_quantile_binning
    split_points = quan_bin.fit_split_points(self.table)
  File ""/fate/federatedml/feature/binning/quantile_binning.py"", line 76, in fit_split_points
    summary_dict = data_instances.mapPartitions(f)
  File ""/fate/arch/api/standalone/eggroll.py"", line 703, in mapPartitions
    results = self._submit_to_pool(func, do_map_partitions)
  File ""/fate/arch/api/standalone/eggroll.py"", line 687, in _submit_to_pool
    results.append(Standalone.get_instance().pool.submit(_do_func, _p))
  File ""/usr/local/lib/python3.6/concurrent/futures/process.py"", line 466, in submit
    self._start_queue_management_thread()
  File ""/usr/local/lib/python3.6/concurrent/futures/process.py"", line 427, in _start_queue_management_thread
    self._adjust_process_count()
  File ""/usr/local/lib/python3.6/concurrent/futures/process.py"", line 446, in _adjust_process_count
    p.start()
  File ""/usr/local/lib/python3.6/multiprocessing/process.py"", line 105, in start
    self._popen = self._Popen(self)
  File ""/usr/local/lib/python3.6/multiprocessing/context.py"", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File ""/usr/local/lib/python3.6/multiprocessing/context.py"", line 277, in _Popen
    return Popen(process_obj)
  File ""/usr/local/lib/python3.6/multiprocessing/popen_fork.py"", line 19, in __init__
    self._launch(process_obj)
  File ""/usr/local/lib/python3.6/multiprocessing/popen_fork.py"", line 66, in _launch
    self.pid = os.fork()
OSError: [Errno 12] Cannot allocate memory
----------------------------------------------------------------------
Ran 2 tests in 14.053s

FAILED (errors=1)
start to run test /fate/federatedml/test/../feature/test/quantile_summaries_test.py
min_rank: 89800, found_rank: 89932, max_rank: 90200
.min_rank: 89800, found_rank: 90047, max_rank: 90200
min_rank: 89800, found_rank: 90045, max_rank: 90200
min_rank: 89800, found_rank: 90033, max_rank: 90200
min_rank: 89800, found_rank: 89916, max_rank: 90200
min_rank: 89800, found_rank: 89979, max_rank: 90200
question:
how pass the errorThis might cause by the data size in test case is too large. I will change it. Thanks for your report. "	1	2019-07-19 09:58:34	2019-08-08 02:49:09	2019-08-08 02:49:09
https://github.com/FederatedAI/FATE/issues/291	[]	运行run_toy_example_cluster.sh guest一直卡住	运行run_toy_example_cluster.sh guest一直卡住部署好host和guest两台机器之后，运行run_toy_example_cluster.sh 示例，但是guest端一直卡住了。但是查看各个模块的日志，也没有发现错误。Can you please give more information? like roll logsLong time no reply, close it, if needed, please reopen the issue	2	2019-07-16 14:51:48	2019-08-20 14:11:06	2019-08-20 14:11:06
https://github.com/FederatedAI/FATE/issues/286	['bug']	v0.3.1 first test task fix bugs	"v0.3.1 first test task fix bugsfix some bugs:
a. scale transform func not return header
b. scale module column selection parameter repeat problem
c. scale param_checker problem
d. fit iv_percentile bug when percentile = 1.0, the selected length would exceed total list.

other change:
1. add ""fast""  to workflow param_validation.json
2. remove scale module limit for the column what has same valueclosed with pr #285 "	1	2019-07-11 05:32:27	2019-08-29 14:20:41	2019-07-11 09:32:51
https://github.com/FederatedAI/FATE/issues/272	[]	"About the new dependency ""redis"""	"About the new dependency ""redis""Hi,

Could you please give a bried introduction about what does the redis works for?

Does it word as a monitor for task queue? If it does, what kind of task is in the queue?

Thank you very much!!Now redis in only used in fate-serving.Hi yangjie,

In the current version redis is only used by fate-serving. It is mainly used to cache the inference results of remote parties  to reduce the elapsed of federated inference. However, future redis will be used for other system.
Thanks."	2	2019-07-05 09:52:28	2019-07-11 14:08:57	2019-07-11 14:08:57
https://github.com/FederatedAI/FATE/issues/270	[]	Data question of Hetero_lr 	"Data question of Hetero_lr Hello!
In hetero_lr, the data of breast_a and breast_b both have x0~x9 labels, are these labels consistent?Actually, x* in breast_a and breast_b including x0~x9 are the features of data, the label of this data is in breast_b with title ""y""thanks,  but I have another question.
In the prediction of hetero_lr, guest has x0~x9 features, host has x0~x19 features.
So, if we have a sample with x0~x19 features, but guest don't have all features, how should we predict?If the size of train_data's features is different from predict data's, it will cause a error. So you should make they same, for example, set the missing feature to 0, but actually it is not recommended to do so.
"	3	2019-07-05 07:47:41	2019-07-09 03:28:09	2019-07-09 03:28:09
https://github.com/FederatedAI/FATE/issues/267	[]	Minimization testing issue	"Minimization testing issueWhen I just run this command 'sh run.sh host fast ', there is a stuck like 

role is host
task is fast
Traceback (most recent call last):
  File ""/data/projects/fate/python/examples/min_test_task/run_task.py"", line 455, in <module>
    data_file)
  File ""/data/projects/fate/python/examples/min_test_task/run_task.py"", line 137, in import_id_library
    stdout = exec_task(json_info, ""upload"", role)
  File ""/data/projects/fate/python/examples/min_test_task/run_task.py"", line 72, in exec_task
    stdout = json.loads(stdout)
  File ""/home/mi/anaconda3/envs/FATE/lib/python3.6/json/__init__.py"", line 354, in loads
    return _default_decoder.decode(s)
  File ""/home/mi/anaconda3/envs/FATE/lib/python3.6/json/decoder.py"", line 339, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File ""/home/mi/anaconda3/envs/FATE/lib/python3.6/json/decoder.py"", line 357, in raw_decode
    raise JSONDecodeError(""Expecting value"", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
finish upload intersect data
{'file': '/data/projects/fate/python/examples/min_test_task/../data/breast_a.csv', 'head': 1, 'partition': 10, 'gen_table_info': True, 'local': {'party_id': 10000, 'role': 'host'}, 'role': {'guest': [9999], 'host': [10000], 'arbiter': [10000]}, 'data_type': 'train_input'}
Traceback (most recent call last):
  File ""/data/projects/fate/python/examples/min_test_task/run_task.py"", line 458, in <module>
    data_file, data_type)
  File ""/data/projects/fate/python/examples/min_test_task/run_task.py"", line 164, in upload
    stdout = exec_task(json_info, ""upload"", role)
  File ""/data/projects/fate/python/examples/min_test_task/run_task.py"", line 72, in exec_task
    stdout = json.loads(stdout)
  File ""/home/mi/anaconda3/envs/FATE/lib/python3.6/json/__init__.py"", line 354, in loads
    return _default_decoder.decode(s)
  File ""/home/mi/anaconda3/envs/FATE/lib/python3.6/json/decoder.py"", line 339, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File ""/home/mi/anaconda3/envs/FATE/lib/python3.6/json/decoder.py"", line 357, in raw_decode
    raise JSONDecodeError(""Expecting value"", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
finish upload train data
{'file': '/data/projects/fate/python/examples/min_test_task/../data/breast_a.csv', 'head': 1, 'partition': 10, 'gen_table_info': True, 'local': {'party_id': 10000, 'role': 'host'}, 'role': {'guest': [9999], 'host': [10000], 'arbiter': [10000]}, 'data_type': 'predict_input'}
Traceback (most recent call last):
  File ""/data/projects/fate/python/examples/min_test_task/run_task.py"", line 458, in <module>
    data_file, data_type)
  File ""/data/projects/fate/python/examples/min_test_task/run_task.py"", line 164, in upload
    stdout = exec_task(json_info, ""upload"", role)
  File ""/data/projects/fate/python/examples/min_test_task/run_task.py"", line 72, in exec_task
    stdout = json.loads(stdout)
  File ""/home/mi/anaconda3/envs/FATE/lib/python3.6/json/__init__.py"", line 354, in loads
    return _default_decoder.decode(s)
  File ""/home/mi/anaconda3/envs/FATE/lib/python3.6/json/decoder.py"", line 339, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File ""/home/mi/anaconda3/envs/FATE/lib/python3.6/json/decoder.py"", line 357, in raw_decode
    raise JSONDecodeError(""Expecting value"", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
finish upload predict data
*********************
*******finish!*******


actually I can run successful for the stand alone testing but the minimization testing has this problem. Why is that, thank you. please check this ""ps -ef | grep task_manager"" to find if the server of task_manager is runningHave you solved this problem? I came across the same issue. @wwwwww1020 "	2	2019-07-02 07:59:27	2019-08-22 06:49:25	2019-08-22 06:49:25
https://github.com/FederatedAI/FATE/issues/262	[]	input_data.mapValues() returns null result in cluster deploy mode	"input_data.mapValues() returns null result in cluster deploy mode**Describe the bug**
In line 101 of file `federatedml/util/data_io.py`, the input_data.mapValues(lambda ...) returns an empty `_DTable`. This function is supposed to split the str value of `input_data` as it does in standalone mode.

This line seems to publish tasks in the MySQL server and wait for `egg`s to finished the tasks. But when I turn to MySQL, the `task` table is empty. The `job_info` and `job_queue` table in database `task_manager` is also empty.

No error logs found in egg's and roll's log file. The `status_tracer_decorator.log` reports NoneType error (because of the empty `_DTable` returned by `mapValues(...)`)

**To Reproduce**
Steps to reproduce the behavior:
1. Deploy all services as suggested in the cluster-deploy instructions.
2. Breakpoint debuging `hetero_host_workflow.py`, step into `gen_data_instance` then step into `reader.read_data`
3. After loading input data in line 79 of `federatedml/util/data_io.py`, you can find that the input data are already loaded in `input_data`.
4. After line 101 `input_data_features = input_data.mapValues(...)`, evaluate `list(input_data_features.collect())` and you can find an empty result, while evaluating this to the `input_data` instance you can find the `input_data` is filled with values.

**Expected behavior**
It is expected to show the splited values as it was in standalone deployment mode.

**Desktop (please complete the following information):**
 - OS: Ubuntu server 18.04
 - Python 3.6
 - grpc 1.19

I am wondering where can I locate the bug and how can I fix it. Thanks!

> status_tracer_decorator.log

```
""2019-06-28 18:24:36,877 - status_tracer_decorator.py[line:74] - INFO: Traceback (most recent call last):
  File ""/home/FATE/workflow/status_tracer_decorator.py"", line 69, in wrapper
    res = func(self, *args, **kwargs)
  File ""/home/FATE/workflow/workflow.py"", line 690, in run
    self.workflow_param.train_input_namespace)
  File ""/home/FATE/workflow/workflow.py"", line 611, in gen_data_instance
    mode=mode)
  File ""/home/FATE/federatedml/util/data_io.py"", line 104, in read_data
    data_instance = self.fit(input_data_features, input_data_labels, table_name, namespace)
  File ""/home/FATE/federatedml/util/data_io.py"", line 113, in fit
    input_data_features = self.fill_missing_value(input_data_features, ""fit"")
  File ""/home/FATE/federatedml/util/data_io.py"", line 136, in fill_missing_value
    replace_value=self.default_value)
  File ""/home/FATE/federatedml/feature/imputer.py"", line 320, in fit
    process_data, replace_value = self.__replace(data, replace_method, replace_value, output_format)
  File ""/home/FATE/federatedml/feature/imputer.py"", line 277, in __replace
    replace_value = [replace_value for _ in range(shape)]
TypeError: 'NoneType' object cannot be interpreted as an integer
""
```
Can you please give more information about roll logs ? The logs are in roll/logs/fate-roll.logThanks for replying, sure thing, the roll log is attached as below:

[fate-roll.log](https://github.com/WeBankFinTech/FATE/files/3339123/fate-roll.log)

Thanks, we need another log to locate the error,  roll/logs/error.log,  sorry to trouble you again.When a task is started, the error.log remains empty until it exits. And it remains empty for a while after the task exit. Some WARNINGs appear in error.log about 20 minites after the task exits. (Seems not caused by the task itself)

The error.log is as follow:

```
Jun 28, 2019 10:42:36 AM io.grpc.netty.shaded.io.grpc.netty.NettyClientHandler$3 onGoAwayReceived
WARNING: Received GOAWAY with ENHANCE_YOUR_CALM. Debug data: {1}
Jun 28, 2019 10:42:36 AM io.grpc.internal.AtomicBackoff$State backoff
WARNING: Increased keepalive time nanos to 720,000,000,000
Jun 28, 2019 10:42:36 AM io.grpc.netty.shaded.io.grpc.netty.NettyClientHandler$3 onGoAwayReceived
WARNING: Received GOAWAY with ENHANCE_YOUR_CALM. Debug data: {1}
Jun 28, 2019 10:42:36 AM io.grpc.internal.AtomicBackoff$State backoff
WARNING: Increased keepalive time nanos to 720,000,000,000
Jun 28, 2019 10:48:36 AM io.grpc.netty.shaded.io.grpc.netty.NettyClientHandler$3 onGoAwayReceived
WARNING: Received GOAWAY with ENHANCE_YOUR_CALM. Debug data: {1}
Jun 28, 2019 10:48:36 AM io.grpc.internal.AtomicBackoff$State backoff
WARNING: Increased keepalive time nanos to 720,000,000,000
Jun 28, 2019 10:48:36 AM io.grpc.netty.shaded.io.grpc.netty.NettyClientHandler$3 onGoAwayReceived
WARNING: Received GOAWAY with ENHANCE_YOUR_CALM. Debug data: {1}
Jun 28, 2019 10:48:36 AM io.grpc.netty.shaded.io.grpc.netty.NettyClientHandler$3 onGoAwayReceived
WARNING: Received GOAWAY with ENHANCE_YOUR_CALM. Debug data: {1}
Jun 28, 2019 10:48:36 AM io.grpc.netty.shaded.io.grpc.netty.NettyClientHandler$3 onGoAwayReceived
WARNING: Received GOAWAY with ENHANCE_YOUR_CALM. Debug data: {1}
Jun 28, 2019 10:48:36 AM io.grpc.internal.AtomicBackoff$State backoff
WARNING: Increased keepalive time nanos to 720,000,000,000
Jun 28, 2019 10:48:36 AM io.grpc.internal.AtomicBackoff$State backoff
WARNING: Increased keepalive time nanos to 720,000,000,000
Jun 28, 2019 10:48:36 AM io.grpc.internal.AtomicBackoff$State backoff
WARNING: Increased keepalive time nanos to 720,000,000,000
Jun 28, 2019 10:48:36 AM io.grpc.netty.shaded.io.grpc.netty.NettyClientHandler$3 onGoAwayReceived
WARNING: Received GOAWAY with ENHANCE_YOUR_CALM. Debug data: {1}
Jun 28, 2019 10:48:36 AM io.grpc.internal.AtomicBackoff$State backoff
WARNING: Increased keepalive time nanos to 720,000,000,000

```Thanks for your replying again, could you please offer some details about what happens after `input_data.mapValues(...)` called in cluster mode? I think it would help me better understand FATE. Thanks in advanced!And some additional info for your reference, all services have been started and standby in the background, as shown in the following:

```
(FATE) user@ubuntu-18-04:~$ ps -aux | grep java
user   27091  0.1  2.5 4640052 211284 ?      Sl   18:02   0:09 java -cp conf/:lib/*:fate-federation.jar com.webank.ai.fate.driver.Federation -c conf/federation.properties
user   27120  0.2  3.5 5315800 287520 ?      Sl   18:02   0:18 java -cp conf/:lib/*:fate-meta-service.jar com.webank.ai.fate.eggroll.MetaService -c conf/meta-service.properties
user   27155  0.1  2.9 5572048 237900 ?      Sl   18:02   0:09 java -cp conf/:lib/*:fate-egg.jar com.webank.ai.fate.eggroll.Egg -c conf/egg.properties
user   27189  0.2  3.4 5789276 282948 ?      Sl   18:02   0:16 java -cp conf/:lib/*:fate-roll.jar com.webank.ai.fate.eggroll.Roll -c conf/roll.properties
user   27231  0.1  1.7 4833004 142716 ?      Sl   18:02   0:07 java -cp conf/:lib/*:fate-proxy.jar com.webank.ai.fate.networking.Proxy -c conf/proxy.properties
user   31061  0.0  0.0  13136  1008 pts/0    S+   20:14   0:00 grep --color=auto java
(FATE) user@ubuntu-18-04:~$ netstat -tupln | grep java
(Not all processes could be identified, non-owned process info
 will not be shown, you would have to be root to see it all.)
tcp6       0      0 :::8011                 :::*                    LISTEN      27189/java
tcp6       0      0 :::8590                 :::*                    LISTEN      27120/java
tcp6       0      0 :::7888                 :::*                    LISTEN      27155/java
tcp6       0      0 :::9394                 :::*                    LISTEN      27091/java
(FATE) user@ubuntu-18-04:~$ netstat -tupln | grep python
(Not all processes could be identified, non-owned process info
 will not be shown, you would have to be root to see it all.)
tcp        0      0 0.0.0.0:9380            0.0.0.0:*               LISTEN      27452/python
tcp6       0      0 :::9360                 :::*                    LISTEN      27452/python
tcp6       0      0 :::50001                :::*                    LISTEN      11293/python
tcp6       0      0 :::50002                :::*                    LISTEN      11307/python
tcp6       0      0 :::50003                :::*                    LISTEN      11309/python
tcp6       0      0 :::50004                :::*                    LISTEN      11311/python
```Can you provide the followings:
1. Running `ps aux | grep processor.py | grep -v grep` in terminal.
2. Open a new terminal and run the following script to test if `mapValues` is ok:

``` python
from arch.api import eggroll
eggroll.init('a', 1)
a = eggroll.parallelize(range(10), partition=2)
b = a.mapValues(lambda v:v+1)
list(b.collect())
```

3. Also, please check the following:

`lsof -i:7778`1. Running `ps aux ...`:

```
(FATE) user@ubuntu-18-04:~$ ps aux | grep processor.py | grep -v grep
user   11293  0.0  0.9 1028116 74436 ?       Sl   Jun27   0:21 python /home/user/FATE/python/arch/processor/processor.py -p 50001 -d /home/user/FATE/data-dir
user   11307  0.0  0.9 1028116 74444 ?       Sl   Jun27   0:20 python /home/user/FATE/python/arch/processor/processor.py -p 50002 -d /home/user/FATE/data-dir
user   11309  0.0  0.9 1028116 78016 ?       Sl   Jun27   0:20 python /home/user/FATE/python/arch/processor/processor.py -p 50003 -d /home/user/FATE/data-dir
user   11311  0.0  0.9 1028116 80748 ?       Sl   Jun27   0:21 python /home/user/FATE/python/arch/processor/processor.py -p 50004 -d /home/user/FATE/data-dir
```

2. Executing the python code returns an empty list [].

3. `lsof -i:7778`:

```
(FATE) user@ubuntu-18-04:~/FATE$ lsof -i:7778
COMMAND     PID   USER   FD   TYPE DEVICE SIZE/OFF NODE NAME
java      27189 user  133u  IPv6 988801      0t0  TCP node1:41118->node1:7778 (ESTABLISHED)
storage-s 27267 user    5u  IPv6 948124      0t0  TCP *:7778 (LISTEN)
storage-s 27267 user    9u  IPv6 989793      0t0  TCP node1:7778->node1:41118 (ESTABLISHED)
```

And the `roll/logs/error.log` have nothing new, new logs in `roll/logs/fate-roll.log` are as follow:

```
[INFO ] 2019-06-28T12:22:43,979 [grpcServiceExecutor-19] [RollKvServiceImpl:113] - Kv.createIfAbsent request received. request: {""storageLocator"":{""type"":""LMDB"",""namespace"":""a"",""name"":""__federation__"",""fragment"":0},""fragmentCount"":10}
[INFO ] 2019-06-28T12:22:43,981 [grpcServiceExecutor-19] [BaseCrudClient:95] - [COMMON] invalid channel. status: SHUTDOWN
[INFO ] 2019-06-28T12:22:43,981 [pool-3-thread-15] [GrpcChannelFactory:79] - [COMMON][CHANNEL][REMOVE] removed for ip: node1, port: 7778, hostname: . reason: EXPIRED
[INFO ] 2019-06-28T12:22:43,982 [pool-3-thread-15] [GrpcChannelFactory:85] - [COMMON][CHANNEL][REMOVE] removed channel state: isShutdown: false, isTerminated: false
[INFO ] 2019-06-28T12:22:43,983 [pool-3-thread-15] [GrpcChannelFactory:108] - [COMMON][CHANNEL][CREATE] creating insecure channel for endpoint: ip: node1, port: 8590, hostname: 
[INFO ] 2019-06-28T12:22:43,983 [pool-3-thread-15] [GrpcChannelFactory:200] - [COMMON][CHANNEL][CREATE] creating channel to {""ip"":""node1"",""port"":8590,""hostname"":""""}, isSecure: false
[INFO ] 2019-06-28T12:22:43,984 [pool-3-thread-15] [GrpcChannelFactory:230] - [COMMON][CHANNEL][CREATE] created channel to {""ip"":""node1"",""port"":8590,""hostname"":""""}, isSecure: false
[INFO ] 2019-06-28T12:22:43,985 [grpcServiceExecutor-19] [GrpcStubFactory:41] - [CORE] create stub. channel status: isShutdown: false, isTerminated: false
[INFO ] 2019-06-28T12:22:52,574 [grpcServiceExecutor-19] [RollKvServiceImpl:113] - Kv.createIfAbsent request received. request: {""storageLocator"":{""type"":""IN_MEMORY"",""namespace"":""a"",""name"":""735b7222-999f-11e9-b797-005056bbda3d"",""fragment"":0},""fragmentCount"":2}
[WARN ] 2019-06-28T12:22:52,600 [grpcServiceExecutor-19] [StoreInfo:45] - no fragment in store info
[INFO ] 2019-06-28T12:22:52,601 [grpcServiceExecutor-19] [RollKvServiceImpl:178] - Kv.putAll request received: [""com.webank.ai.fate.core.io.StoreInfo"",{""type"":""IN_MEMORY"",""nameSpace"":""a"",""tableName"":""735b7222-999f-11e9-b797-005056bbda3d""}]
[INFO ] 2019-06-28T12:22:52,601 [grpcServiceExecutor-19] [GrpcStubFactory:41] - [CORE] create stub. channel status: isShutdown: false, isTerminated: false
[INFO ] 2019-06-28T12:22:52,602 [grpcServiceExecutor-19] [GrpcStubFactory:41] - [CORE] create stub. channel status: isShutdown: false, isTerminated: false
[INFO ] 2019-06-28T12:22:52,602 [grpcServiceExecutor-19] [GrpcStubFactory:41] - [CORE] create stub. channel status: isShutdown: false, isTerminated: false
[INFO ] 2019-06-28T12:22:52,625 [asyncThreadPool-49] [StorageServiceClient:120] - [ROLL][PUTALL][SUBTASK] putAll subTask request received: [""com.webank.ai.fate.core.io.StoreInfo"",{""type"":""IN_MEMORY"",""nameSpace"":""a"",""tableName"":""735b7222-999f-11e9-b797-005056bbda3d"",""fragment"":1}]
[INFO ] 2019-06-28T12:22:52,628 [pool-3-thread-15] [GrpcChannelFactory:108] - [COMMON][CHANNEL][CREATE] creating insecure channel for endpoint: ip: node1, port: 7778, hostname: 
[INFO ] 2019-06-28T12:22:52,629 [pool-3-thread-15] [GrpcChannelFactory:200] - [COMMON][CHANNEL][CREATE] creating channel to {""ip"":""node1"",""port"":7778,""hostname"":""""}, isSecure: false
[INFO ] 2019-06-28T12:22:52,629 [pool-3-thread-15] [GrpcChannelFactory:230] - [COMMON][CHANNEL][CREATE] created channel to {""ip"":""node1"",""port"":7778,""hostname"":""""}, isSecure: false
[INFO ] 2019-06-28T12:22:52,630 [asyncThreadPool-49] [GrpcStubFactory:41] - [CORE] create stub. channel status: isShutdown: false, isTerminated: false
[INFO ] 2019-06-28T12:22:52,631 [asyncThreadPool-50] [StorageServiceClient:120] - [ROLL][PUTALL][SUBTASK] putAll subTask request received: [""com.webank.ai.fate.core.io.StoreInfo"",{""type"":""IN_MEMORY"",""nameSpace"":""a"",""tableName"":""735b7222-999f-11e9-b797-005056bbda3d"",""fragment"":0}]
[INFO ] 2019-06-28T12:22:52,634 [asyncThreadPool-50] [GrpcStubFactory:41] - [CORE] create stub. channel status: isShutdown: false, isTerminated: false
[INFO ] 2019-06-28T12:22:52,637 [asyncThreadPool-50] [StorageKvPutAllRequestStreamProcessor:65] - [PUTALL][SUBTASK] actual completes putAll sub task. remaining: 0, entryCount: 5
[ERROR] 2019-06-28T12:22:52,646 [asyncThreadPool-50] [PutAllProcessorListenableFutureCallback:79] - [ROLL][KV][PUTALL][ONSUCCESS] put all success. storeInfo: StoreInfo(type=IN_MEMORY, nameSpace=a, tableName=735b7222-999f-11e9-b797-005056bbda3d, fragment=0), latch count: 2, address: node1:7778
[INFO ] 2019-06-28T12:22:52,682 [asyncThreadPool-49] [StorageKvPutAllRequestStreamProcessor:65] - [PUTALL][SUBTASK] actual completes putAll sub task. remaining: 0, entryCount: 5
[ERROR] 2019-06-28T12:22:52,691 [asyncThreadPool-49] [PutAllProcessorListenableFutureCallback:79] - [ROLL][KV][PUTALL][ONSUCCESS] put all success. storeInfo: StoreInfo(type=IN_MEMORY, nameSpace=a, tableName=735b7222-999f-11e9-b797-005056bbda3d, fragment=1), latch count: 1, address: node1:7778
[INFO ] 2019-06-28T12:22:52,692 [grpcServiceExecutor-19] [RollKvPutAllServerRequestStreamObserver:212] - [ROLL][KV][PUTALL] waiting put all to finish. storeInfo: StoreInfo(type=IN_MEMORY, nameSpace=a, tableName=735b7222-999f-11e9-b797-005056bbda3d, fragment=null), current latch count: 0, finished count: 2
[INFO ] 2019-06-28T12:22:52,692 [grpcServiceExecutor-19] [RollKvPutAllServerRequestStreamObserver:232] - [ROLL][PROCESS][PUTALL] put all completed. storeInfo: StoreInfo(type=IN_MEMORY, nameSpace=a, tableName=735b7222-999f-11e9-b797-005056bbda3d, fragment=null), totalCount: 10
[INFO ] 2019-06-28T12:23:00,506 [grpcServiceExecutor-19] [RollProcessServiceImpl:113] - [ROLL][PROCESS][MapValues] request received: {""info"":{""task_id"":""a"",""function_id"":""7815d028-999f-11e9-b797-005056bbda3d"",""function_bytes"":""gASVEgEAAAAAAACMGmFyY2guYXBpLnV0aWxzLmNsb3VkcGlja2xllIwOX2ZpbGxfZnVuY3Rpb26Uk5QoaACMD19tYWtlX3NrZWxfZnVuY5STlGgAjA1fYnVpbHRpbl90eXBllJOUjAhDb2RlVHlwZZSFlFKUKEsBSwBLAUsCS0NDCHwAZAEXAFMAlE5LAYaUKYwBdpSFlIwHPHN0ZGluPpSMCDxsYW1iZGE+lEsBQwCUKSl0lFKUSv////99lIeUUpR9lCiMB2dsb2JhbHOUfZSMCGRlZmF1bHRzlE6MBGRpY3SUfZSMBm1vZHVsZZSMCF9fbWFpbl9flIwOY2xvc3VyZV92YWx1ZXOUTowIcXVhbG5hbWWUaA91dFIu""},""operand"":{""type"":""IN_MEMORY"",""namespace"":""a"",""name"":""735b7222-999f-11e9-b797-005056bbda3d"",""fragment"":0}}
[INFO ] 2019-06-28T12:23:00,507 [grpcServiceExecutor-19] [RollProcessServiceImpl:238] - [ROLL][PROCESS][ProcessServiceTemplate] requestStorageLocator: {""type"":""IN_MEMORY"",""namespace"":""a"",""name"":""735b7222-999f-11e9-b797-005056bbda3d"",""fragment"":0}
[INFO ] 2019-06-28T12:23:00,507 [grpcServiceExecutor-19] [BaseCrudClient:95] - [COMMON] invalid channel. status: SHUTDOWN
[INFO ] 2019-06-28T12:23:00,508 [grpcServiceExecutor-19] [GrpcStubFactory:41] - [CORE] create stub. channel status: isShutdown: false, isTerminated: false
[INFO ] 2019-06-28T12:23:00,513 [grpcServiceExecutor-19] [BaseCrudClient:95] - [COMMON] invalid channel. status: SHUTDOWN
[INFO ] 2019-06-28T12:23:00,513 [grpcServiceExecutor-19] [GrpcStubFactory:41] - [CORE] create stub. channel status: isShutdown: false, isTerminated: false
[INFO ] 2019-06-28T12:23:00,523 [grpcServiceExecutor-19] [RollProcessServiceImpl:268] - [ROLL][PROCESS][ProcessServiceTemplate] storeInfoWithFragment: StoreInfo(type=IN_MEMORY, nameSpace=a, tableName=735b7222-999f-11e9-b797-005056bbda3d, fragment=0), fragmentNodeId: 4, storageNode: Node [Hash = -1659922994, nodeId=4, host=null, ip=node1, port=7778, type=STORAGE, status=HEALTHY, lastHeartbeatAt=null, createdAt=Fri Jun 28 16:37:21 UTC 2019, updatedAt=Fri Jun 28 16:37:21 UTC 2019], target: node1
[INFO ] 2019-06-28T12:23:00,527 [pool-3-thread-15] [GrpcChannelFactory:108] - [COMMON][CHANNEL][CREATE] creating insecure channel for endpoint: ip: node1, port: 7888, hostname: 
[INFO ] 2019-06-28T12:23:00,527 [pool-3-thread-15] [GrpcChannelFactory:200] - [COMMON][CHANNEL][CREATE] creating channel to {""ip"":""node1"",""port"":7888,""hostname"":""""}, isSecure: false
[INFO ] 2019-06-28T12:23:00,528 [pool-3-thread-15] [GrpcChannelFactory:230] - [COMMON][CHANNEL][CREATE] created channel to {""ip"":""node1"",""port"":7888,""hostname"":""""}, isSecure: false
[INFO ] 2019-06-28T12:23:00,530 [grpcServiceExecutor-19] [GrpcStubFactory:41] - [CORE] create stub. channel status: isShutdown: false, isTerminated: false
[INFO ] 2019-06-28T12:23:00,542 [grpcServiceExecutor-19] [RollProcessServiceImpl:268] - [ROLL][PROCESS][ProcessServiceTemplate] storeInfoWithFragment: StoreInfo(type=IN_MEMORY, nameSpace=a, tableName=735b7222-999f-11e9-b797-005056bbda3d, fragment=1), fragmentNodeId: 4, storageNode: Node [Hash = -1659922994, nodeId=4, host=null, ip=node1, port=7778, type=STORAGE, status=HEALTHY, lastHeartbeatAt=null, createdAt=Fri Jun 28 16:37:21 UTC 2019, updatedAt=Fri Jun 28 16:37:21 UTC 2019], target: node1
[INFO ] 2019-06-28T12:23:00,543 [pool-3-thread-15] [GrpcChannelFactory:79] - [COMMON][CHANNEL][REMOVE] removed for ip: 10.44.12.49, port: 50004, hostname: . reason: EXPIRED
[INFO ] 2019-06-28T12:23:00,543 [pool-3-thread-15] [GrpcChannelFactory:85] - [COMMON][CHANNEL][REMOVE] removed channel state: isShutdown: false, isTerminated: false
[INFO ] 2019-06-28T12:23:00,543 [pool-3-thread-15] [GrpcChannelFactory:79] - [COMMON][CHANNEL][REMOVE] removed for ip: 10.44.12.49, port: 50001, hostname: . reason: EXPIRED
[INFO ] 2019-06-28T12:23:00,543 [grpcServiceExecutor-19] [GrpcStubFactory:41] - [CORE] create stub. channel status: isShutdown: false, isTerminated: false
[INFO ] 2019-06-28T12:23:00,543 [pool-3-thread-15] [GrpcChannelFactory:85] - [COMMON][CHANNEL][REMOVE] removed channel state: isShutdown: false, isTerminated: false
[INFO ] 2019-06-28T12:23:00,543 [pool-3-thread-15] [GrpcChannelFactory:79] - [COMMON][CHANNEL][REMOVE] removed for ip: 10.44.12.49, port: 50003, hostname: . reason: EXPIRED
[INFO ] 2019-06-28T12:23:00,543 [pool-3-thread-15] [GrpcChannelFactory:85] - [COMMON][CHANNEL][REMOVE] removed channel state: isShutdown: false, isTerminated: false
[INFO ] 2019-06-28T12:23:00,544 [pool-3-thread-15] [GrpcChannelFactory:108] - [COMMON][CHANNEL][CREATE] creating insecure channel for endpoint: ip: 10.44.12.49, port: 50004, hostname: 
[INFO ] 2019-06-28T12:23:00,544 [pool-3-thread-15] [GrpcChannelFactory:200] - [COMMON][CHANNEL][CREATE] creating channel to {""ip"":""10.44.12.49"",""port"":50004,""hostname"":""""}, isSecure: false
[INFO ] 2019-06-28T12:23:00,544 [pool-3-thread-15] [GrpcChannelFactory:230] - [COMMON][CHANNEL][CREATE] created channel to {""ip"":""10.44.12.49"",""port"":50004,""hostname"":""""}, isSecure: false
[INFO ] 2019-06-28T12:23:00,545 [asyncThreadPool-49] [GrpcStubFactory:41] - [CORE] create stub. channel status: isShutdown: false, isTerminated: false
[INFO ] 2019-06-28T12:23:00,554 [pool-3-thread-15] [GrpcChannelFactory:108] - [COMMON][CHANNEL][CREATE] creating insecure channel for endpoint: ip: 10.44.12.49, port: 50001, hostname: 
[INFO ] 2019-06-28T12:23:00,555 [pool-3-thread-15] [GrpcChannelFactory:200] - [COMMON][CHANNEL][CREATE] creating channel to {""ip"":""10.44.12.49"",""port"":50001,""hostname"":""""}, isSecure: false
[INFO ] 2019-06-28T12:23:00,555 [pool-3-thread-15] [GrpcChannelFactory:230] - [COMMON][CHANNEL][CREATE] created channel to {""ip"":""10.44.12.49"",""port"":50001,""hostname"":""""}, isSecure: false
[INFO ] 2019-06-28T12:23:00,557 [asyncThreadPool-49] [GrpcStubFactory:41] - [CORE] create stub. channel status: isShutdown: false, isTerminated: false
[INFO ] 2019-06-28T12:23:00,562 [grpcServiceExecutor-19] [RollProcessServiceImpl:312] - [ROLL][PROCESS][ProcessServiceTemplate] valid result. ready to return storeInfo: StoreInfo(type=IN_MEMORY, nameSpace=a, tableName=735b7222-999f-11e9-b797-005056bbda3d, fragment=0), processType: MapValuesServiceProcessor
[INFO ] 2019-06-28T12:23:00,562 [grpcServiceExecutor-19] [ProcessServiceStorageLocatorResultHandler:41] - [HANDLE][RESULT] {""type"":""IN_MEMORY"",""namespace"":""a"",""name"":""7815d028-999f-11e9-b797-005056bbda3d"",""fragment"":0}, unprocessedResults.size: 2
[INFO ] 2019-06-28T12:23:00,564 [grpcServiceExecutor-19] [RollKvServiceImpl:113] - Kv.createIfAbsent request received. request: {""storageLocator"":{""type"":""IN_MEMORY"",""namespace"":""a"",""name"":""7815d028-999f-11e9-b797-005056bbda3d"",""fragment"":0},""fragmentCount"":2}
[WARN ] 2019-06-28T12:23:11,178 [grpcServiceExecutor-19] [StoreInfo:45] - no fragment in store info
[INFO ] 2019-06-28T12:23:11,179 [grpcServiceExecutor-19] [RollKvServiceImpl:230] - Kv.iterate request received: [""com.webank.ai.fate.core.io.StoreInfo"",{""type"":""IN_MEMORY"",""nameSpace"":""a"",""tableName"":""7815d028-999f-11e9-b797-005056bbda3d""}]
[INFO ] 2019-06-28T12:23:11,180 [grpcServiceExecutor-19] [GrpcStubFactory:41] - [CORE] create stub. channel status: isShutdown: false, isTerminated: false
[INFO ] 2019-06-28T12:23:11,180 [grpcServiceExecutor-19] [GrpcStubFactory:41] - [CORE] create stub. channel status: isShutdown: false, isTerminated: false
[INFO ] 2019-06-28T12:23:11,192 [asyncThreadPool-49] [IterateProcessor:123] - [ROLL][ITERATOR][PROCESSOR] final minChunkSize: 4194304
[INFO ] 2019-06-28T12:23:11,193 [asyncThreadPool-49] [GrpcStubFactory:41] - [CORE] create stub. channel status: isShutdown: false, isTerminated: false
[INFO ] 2019-06-28T12:23:11,195 [asyncThreadPool-49] [IterateProcessor:270] - [ROLL][KV][ITERATE][PROCESSOR] waiting latch for: StoreInfo(type=IN_MEMORY, nameSpace=a, tableName=7815d028-999f-11e9-b797-005056bbda3d, fragment=0)
[INFO ] 2019-06-28T12:23:11,195 [asyncThreadPool-49] [IterateProcessor:275] - [ROLL][KV][ITERATE][PROCESSOR] broker: StoreInfo(type=IN_MEMORY, nameSpace=a, tableName=7815d028-999f-11e9-b797-005056bbda3d, fragment=0), closable: true, ready: false
[INFO ] 2019-06-28T12:23:11,196 [asyncThreadPool-49] [IterateProcessor:284] - [ROLL][KV][ITERATE][PROCESSOR] data arrived. size: 0, fragment order: 0, node address: node1:7778, range start: , range end: 
[INFO ] 2019-06-28T12:23:11,196 [asyncThreadPool-49] [GrpcStubFactory:41] - [CORE] create stub. channel status: isShutdown: false, isTerminated: false
[INFO ] 2019-06-28T12:23:11,197 [asyncThreadPool-49] [IterateProcessor:270] - [ROLL][KV][ITERATE][PROCESSOR] waiting latch for: StoreInfo(type=IN_MEMORY, nameSpace=a, tableName=7815d028-999f-11e9-b797-005056bbda3d, fragment=1)
[INFO ] 2019-06-28T12:23:11,198 [asyncThreadPool-49] [IterateProcessor:275] - [ROLL][KV][ITERATE][PROCESSOR] broker: StoreInfo(type=IN_MEMORY, nameSpace=a, tableName=7815d028-999f-11e9-b797-005056bbda3d, fragment=1), closable: true, ready: false
[INFO ] 2019-06-28T12:23:11,198 [asyncThreadPool-49] [IterateProcessor:284] - [ROLL][KV][ITERATE][PROCESSOR] data arrived. size: 0, fragment order: 1, node address: node1:7778, range start: , range end: 
[INFO ] 2019-06-28T12:23:11,198 [asyncThreadPool-49] [RollKvServiceImpl:249] - [ROLL][KV][ITERATE] finished without error. storeInfo: StoreInfo(type=IN_MEMORY, nameSpace=a, tableName=7815d028-999f-11e9-b797-005056bbda3d, fragment=null), request: {""start"":"""",""end"":"""",""minChunkSize"":""0""}
[INFO ] 2019-06-28T12:23:11,198 [grpcServiceExecutor-19] [RollKvServiceImpl:283] - [ROLL][KV][ITERATE] roll iterate successfully. totalIterated: 0, storeInfo: StoreInfo(type=IN_MEMORY, nameSpace=a, tableName=7815d028-999f-11e9-b797-005056bbda3d, fragment=null), request: {""start"":"""",""end"":"""",""minChunkSize"":""0""}

```Duplicate of #276"	9	2019-06-28 10:54:27	2019-07-08 03:43:12	2019-07-08 03:43:12
https://github.com/FederatedAI/FATE/issues/256	[]	General cross validation module	"General cross validation module**Is your feature request related to a problem? Please describe.**
Make a general cross validation module so that every other modules can use it to process cv. Already finished"	1	2019-06-24 09:18:59	2019-07-23 08:03:48	2019-07-23 08:03:48
https://github.com/FederatedAI/FATE/issues/255	[]	Connection failed between parties after rebooting the server	"Connection failed between parties after rebooting the serverWe deployed FATE in our servers on Alibaba Cloud. While there are some connection problems after system rebooting. The bug can not be reproduced stably. And the error information is shown as follow: 

debug_error_string = ""{""created"":""@1560843215.697088846"",""description"":""Failed to create subchannel"",""file"":""src/core/ext/filters/client_channel/client_channel.cc"",""file_line"":2721,""referenced_errors"":[{""created"":""@1560843215.697086805"",""description"":""Pick Cancelled"",""file"":""src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc"",""file_line"":241,""referenced_errors"":[{""created"":""@1560843215.697078506"",""description"":""Connect Failed"",""file"":""src/core/ext/filters/client_channel/subchannel.cc"",""file_line"":689,""grpc_status"":14,""referenced_errors"":[{""created"":""@1560843215.697076865"",""description"":""OS Error"",""errno"":97,""file"":""src/core/lib/iomgr/socket_utils_common_posix.cc"",""file_line"":373,""os_error"":""Address family not supported by protocol"",""syscall"":""socket"",""target_address"":""[::1]:8011""}]}]}]}""@lytofd Did you manage to solve this issue? I'm facing the same problem."	1	2019-06-24 08:34:28	2020-06-10 13:34:13	2019-11-05 06:13:14
https://github.com/FederatedAI/FATE/issues/254	[]	[cluster version]toy example failed	"[cluster version]toy example failed**Describe the bug**
A clear and concise description of what the bug is.

**To Reproduce**
Steps to reproduce the behavior:
1. in host party:
    cd /data/projects/fate/python/examples/toy_example;
    bash run_toy_example_cluster.sh host test_0624_1 11 9;
2. in guest party:
    cd /data/projects/fate/python/examples/toy_example;
    bash run_toy_example_cluster.sh guest test_0624_1 11 9;
3. error occured: 
    jobid is test_0624_1
Running...
Finish, time cost is 0.0453
Secure Add Example Task Is FAIL!!!

**Screenshots**
task log in guest:
![image](https://user-images.githubusercontent.com/30313245/59999252-18fbeb80-9694-11e9-82da-c3a2c9ddd03b.png)
task log in host:
![image](https://user-images.githubusercontent.com/30313245/59999296-34ff8d00-9694-11e9-8694-fc5c6b6101ec.png)


**error log in host**
""2019-06-24 15:07:55,561 - status_tracer_decorator.py[line:73] - INFO: job status is failed""
""2019-06-24 15:07:55,561 - status_tracer_decorator.py[line:74] - INFO: Traceback (most recent call last):
  File ""/data/projects/fate/python/workflow/status_tracer_decorator.py"", line 69, in wrapper
    res = func(self, *args, **kwargs)
  File ""../../workflow/toy_example_workflow/secure_add_host_workflow.py"", line 66, in run
    self.secure_add_host_inst.run()
  File ""/data/projects/fate/python/federatedml/toy_example/secure_add_host.py"", line 68, in run
    self.secure()
  File ""/data/projects/fate/python/federatedml/toy_example/secure_add_host.py"", line 39, in secure
    y_shares = self.y.mapValues(self.share)
  File ""/data/projects/fate/python/arch/api/cluster/eggroll.py"", line 109, in mapValues
    return _EggRoll.get_instance().map_values(self, func)
  File ""/data/projects/fate/python/arch/api/cluster/eggroll.py"", line 302, in map_values
    resp = self.proc_stub.mapValues(unary_p)
  File ""/data/projects/common/miniconda3/lib/python3.6/site-packages/grpc/_channel.py"", line 533, in __call__
    return _end_unary_response_blocking(state, call, False, None)
  File ""/data/projects/common/miniconda3/lib/python3.6/site-packages/grpc/_channel.py"", line 467, in _end_unary_response_blocking
    raise _Rendezvous(state, None, None, deadline)
grpc._channel._Rendezvous: <_Rendezvous of RPC that terminated with:
	status = StatusCode.INTERNAL
	details = ""172.16.0.9:8011: com.webank.ai.fate.core.error.exception.MultipleRuntimeThrowables: error occured in sub tasks. processor type: MapValuesServiceProcessor
	at com.webank.ai.fate.eggroll.roll.api.grpc.server.RollProcessServiceImpl$ProcessServiceTemplate.run(RollProcessServiceImpl.java:324)
	at com.webank.ai.fate.core.api.grpc.server.GrpcServerWrapper.wrapGrpcServerRunnable(GrpcServerWrapper.java:51)
	at com.webank.ai.fate.eggroll.roll.api.grpc.server.RollProcessServiceImpl.mapValues(RollProcessServiceImpl.java:115)
	at com.webank.ai.fate.api.eggroll.processor.ProcessServiceGrpc$MethodHandlers.invoke(ProcessServiceGrpc.java:626)
	at io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:171)
	at io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:283)
	at io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:710)
	at io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.Throwable: idx: 0
java.lang.RuntimeException: java.lang.reflect.InvocationTargetException
	at com.webank.ai.fate.eggroll.roll.api.grpc.client.EggProcessServiceClient.unaryProcessToStorageLocatorUnaryCall(EggProcessServiceClient.java:146)
	at com.webank.ai.fate.eggroll.roll.api.grpc.client.EggProcessServiceClient.mapValues(EggProcessServiceClient.java:57)
	at com.webank.ai.fate.eggroll.roll.service.async.processor.MapValuesServiceProcessor.call(MapValuesServiceProcessor.java:35)
	at com.webank.ai.fate.eggroll.roll.service.async.processor.MapValuesServiceProcessor.call(MapValuesServiceProcessor.java:26)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.reflect.InvocationTargetException
	at com.webank.ai.fate.core.api.grpc.client.GrpcStreamingClientTemplate.calleeStreamingRpcWithImmediateDelayedResult(GrpcStreamingClientTemplate.java:155)
	at com.webank.ai.fate.eggroll.roll.api.grpc.client.EggProcessServiceClient.unaryProcessToStorageLocatorUnaryCall(EggProcessServiceClient.java:144)
	... 7 more
Caused by: io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at io.grpc.Status.asRuntimeException(Status.java:526)
	at io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:434)
	at io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39)
	at io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23)
	at io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40)
	at io.grpc.internal.CensusStatsModule$StatsClientInterceptor$1$1.onClose(CensusStatsModule.java:678)
	at io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39)
	at io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23)
	at io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40)
	at io.grpc.internal.CensusTracingModule$TracingClientInterceptor$1$1.onClose(CensusTracingModule.java:397)
	at io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:459)
	at io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:63)
	at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:546)
	at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:467)
	at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:584)
	at io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
	... 3 more
Caused by: io.grpc.netty.shaded.io.netty.channel.AbstractChannel$AnnotatedConnectException: 拒绝连接: /172.16.0.9:50001
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.grpc.netty.shaded.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at io.grpc.netty.shaded.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at io.grpc.netty.shaded.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at io.grpc.netty.shaded.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at io.grpc.netty.shaded.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at io.grpc.netty.shaded.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at io.grpc.netty.shaded.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at io.grpc.netty.shaded.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: 拒绝连接
	... 11 more



	at com.webank.ai.fate.core.error.exception.MultipleRuntimeThrowables.<init>(MultipleRuntimeThrowables.java:32)
	... 12 more
""
	debug_error_string = ""{""created"":""@1561360075.560867908"",""description"":""Error received from peer"",""file"":""src/core/lib/surface/call.cc"",""file_line"":1017,""grpc_message"":""172.16.0.9:8011: com.webank.ai.fate.core.error.exception.MultipleRuntimeThrowables: error occured in sub tasks. processor type: MapValuesServiceProcessor\n\tat com.webank.ai.fate.eggroll.roll.api.grpc.server.RollProcessServiceImpl$ProcessServiceTemplate.run(RollProcessServiceImpl.java:324)\n\tat com.webank.ai.fate.core.api.grpc.server.GrpcServerWrapper.wrapGrpcServerRunnable(GrpcServerWrapper.java:51)\n\tat com.webank.ai.fate.eggroll.roll.api.grpc.server.RollProcessServiceImpl.mapValues(RollProcessServiceImpl.java:115)\n\tat com.webank.ai.fate.api.eggroll.processor.ProcessServiceGrpc$MethodHandlers.invoke(ProcessServiceGrpc.java:626)\n\tat io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:171)\n\tat io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:283)\n\tat io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:710)\n\tat io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)\n\tat io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.Throwable: idx: 0\njava.lang.RuntimeException: java.lang.reflect.InvocationTargetException\n\tat com.webank.ai.fate.eggroll.roll.api.grpc.client.EggProcessServiceClient.unaryProcessToStorageLocatorUnaryCall(EggProcessServiceClient.java:146)\n\tat com.webank.ai.fate.eggroll.roll.api.grpc.client.EggProcessServiceClient.mapValues(EggProcessServiceClient.java:57)\n\tat com.webank.ai.fate.eggroll.roll.service.async.processor.MapValuesServiceProcessor.call(MapValuesServiceProcessor.java:35)\n\tat com.webank.ai.fate.eggroll.roll.service.async.processor.MapValuesServiceProcessor.call(MapValuesServiceProcessor.java:26)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.reflect.InvocationTargetException\n\tat com.webank.ai.fate.core.api.grpc.client.GrpcStreamingClientTemplate.calleeStreamingRpcWithImmediateDelayedResult(GrpcStreamingClientTemplate.java:155)\n\tat com.webank.ai.fate.eggroll.roll.api.grpc.client.EggProcessServiceClient.unaryProcessToStorageLocatorUnaryCall(EggProcessServiceClient.java:144)\n\t... 7 more\nCaused by: io.grpc.StatusRuntimeException: UNAVAILABLE: io exception\n\tat io.grpc.Status.asRuntimeException(Status.java:526)\n\tat io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:434)\n\tat io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39)\n\tat io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23)\n\tat io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40)\n\tat io.grpc.internal.CensusStatsModule$StatsClientInterceptor$1$1.onClose(CensusStatsModule.java:678)\n\tat io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39)\n\tat io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23)\n\tat io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40)\n\tat io.grpc.internal.CensusTracingModule$TracingClientInterceptor$1$1.onClose(CensusTracingModule.java:397)\n\tat io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:459)\n\tat io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:63)\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:546)\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:467)\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:584)\n\tat io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)\n\tat io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)\n\t... 3 more\nCaused by: io.grpc.netty.shaded.io.netty.channel.AbstractChannel$AnnotatedConnectException: \u00e6\u008b\u0092\u00e7\u00bb\u009d\u00e8\u00bf\u009e\u00e6\u008e\u00a5: /172.16.0.9:50001\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n\tat io.grpc.netty.shaded.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)\n\tat io.grpc.netty.shaded.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)\n\tat io.grpc.netty.shaded.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)\n\tat io.grpc.netty.shaded.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)\n\tat io.grpc.netty.shaded.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)\n\tat io.grpc.netty.shaded.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)\n\tat io.grpc.netty.shaded.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)\n\tat io.grpc.netty.shaded.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\nCaused by: java.net.ConnectException: \u00e6\u008b\u0092\u00e7\u00bb\u009d\u00e8\u00bf\u009e\u00e6\u008e\u00a5\n\t... 11 more\n\n\n\n\tat com.webank.ai.fate.core.error.exception.MultipleRuntimeThrowables.<init>(MultipleRuntimeThrowables.java:32)\n\t... 12 more\n"",""grpc_status"":13}""
>
""
Please check the 50001 port on the 172.16.0.9 and check if the processor is successfully started.
You can refer to processor.sh in the cluster-deploy/example-dir-tree/python directory.
Thanks.grpc server failed to start because of python env. thx> grpc server failed to start because of python env. thx

I also have the same error, how to run grpc server correctly?"	3	2019-06-24 07:28:37	2019-07-15 14:04:12	2019-06-25 06:23:50
https://github.com/FederatedAI/FATE/issues/253	[]	Cluster version cannot load data	"Cluster version cannot load dataWhen I use this command 'python $FATE_install_path/arch/task_manager/task_manager_client.py -f upload -c conf/load_file_tm_guest.json', it always have exception like failed to establish a new connection: [Errno 111] Connection refused. How can I fix it. Thank you.



**Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/site-packages/urllib3/connection.py"", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File ""/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py"", line 80, in create_connection
    raise err
  File ""/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py"", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 600, in urlopen
    chunked=chunked)
  File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File ""/usr/local/lib/python3.6/http/client.py"", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File ""/usr/local/lib/python3.6/http/client.py"", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File ""/usr/local/lib/python3.6/http/client.py"", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File ""/usr/local/lib/python3.6/http/client.py"", line 1026, in _send_output
    self.send(msg)
  File ""/usr/local/lib/python3.6/http/client.py"", line 964, in send
    self.connect()
  File ""/usr/local/lib/python3.6/site-packages/urllib3/connection.py"", line 181, in connect
    conn = self._new_conn()
  File ""/usr/local/lib/python3.6/site-packages/urllib3/connection.py"", line 168, in _new_conn
    self, ""Failed to establish a new connection: %s"" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fdfbd4d2b38>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/site-packages/requests/adapters.py"", line 449, in send
    timeout=timeout
  File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File ""/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py"", line 399, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=9380): Max retries exceeded with url: /data/upload (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fdfbd4d2b38>: Failed to establish a new connection: [Errno 111] Connection refused',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/fate/arch/task_manager/task_manager_client.py"", line 102, in <module>
    response = call_fun(args.function, config_data)
  File ""/fate/arch/task_manager/task_manager_client.py"", line 56, in call_fun
    response = requests.post(""/"".join([LOCAL_URL, ""data"", func]), json=config_data)
  File ""/usr/local/lib/python3.6/site-packages/requests/api.py"", line 116, in post
    return request('post', url, data=data, json=json, **kwargs)
  File ""/usr/local/lib/python3.6/site-packages/requests/api.py"", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File ""/usr/local/lib/python3.6/site-packages/requests/sessions.py"", line 524, in request
    resp = self.send(prep, **send_kwargs)
  File ""/usr/local/lib/python3.6/site-packages/requests/sessions.py"", line 637, in send
    r = adapter.send(request, **kwargs)
  File ""/usr/local/lib/python3.6/site-packages/requests/adapters.py"", line 516, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=9380): Max retries exceeded with url: /data/upload (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fdfbd4d2b38>: Failed to establish a new connection: [Errno 111] Connection refused',))**
Hi, 
This seems to be that the task manager server is not started. 
Are you deploying with the automated deployment script provided by FATE? 
Please check if the task manager server is deployed completely. You can refer to the service.sh startup script which in arch/task_manager/. And also check that this configuration file is configured correctly.
Thanks.There is no communication for a long time, closed it.
Thank you."	2	2019-06-24 02:48:18	2019-07-14 11:58:29	2019-07-14 11:58:29
https://github.com/FederatedAI/FATE/issues/245	[]	Stop when runing the homo LR	"Stop when runing the homo LRHi,

After successfully deploy 2 machine as 2 party. The homoLR example stop, the host is succeed to fetch the weight by federation.get(). However, when the ""host"" use federation.get() to fetch the ""converge_flag"" by 

###
converge_flag = federation.get(name=self.transfer_variable.converge_flag.name,
                                           tag=converge_flag_id,
                                           idx=0)
###

It is stuck

while as for the ""guest"", it stops to fetch the weight by

###
w = federation.get(name=self.transfer_variable.final_model.name,
                               tag=model_transfer_id,
                               idx=0)
###

Each ""fate-*.log"" file seems to be normal in the logs directory. Could you please help me that where can I check the probable error appear?

Thanks a lot~I find a exceptiong in the ""fate-federation.log"" which shows that

-----------------------------------------------

[INFO ] 2019-06-18T15:28:46,862 [transferJobSchedulerExecutor-17] [GrpcStubFactory:41] - [CORE] create stub. channel status: isShutdown: false, isTerminated: false
[INFO ] 2019-06-18T15:28:46,866 [grpcClientExecutor-9] [UnaryCallServerRequestStreamObserver:50] - UnaryCallServerRequestStreamObserver source streaming error: io.grpc.StatusRuntimeException: INTERNAL: HTTP/2 error code: INTERNAL_ERROR
Received Rst Stream
        at io.grpc.Status.asRuntimeException(Status.java:526)
        at io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:434)
        at io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39)
        at io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23)
        at io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40)
        at io.grpc.internal.CensusStatsModule$StatsClientInterceptor$1$1.onClose(CensusStatsModule.java:678)
        at io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39)
        at io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23)
        at io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40)
        at io.grpc.internal.CensusTracingModule$TracingClientInterceptor$1$1.onClose(CensusTracingModule.java:397)
        at io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:459)
        at io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:63)
        at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:546)
        at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:467)
        at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:584)
        at io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
        at io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)

[ERROR] 2019-06-18T15:28:46,866 [transferJobSchedulerExecutor-17] [SendProcessor:94] - java.lang.RuntimeException: java.lang.reflect.InvocationTargetException
        at com.webank.ai.fate.driver.federation.transfer.api.grpc.client.ProxyClient.unaryCall(ProxyClient.java:130)
        at com.webank.ai.fate.driver.federation.transfer.api.grpc.client.ProxyClient.requestSendStart(ProxyClient.java:141)
        at com.webank.ai.fate.driver.federation.transfer.communication.processor.SendProcessor.run(SendProcessor.java:74)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.reflect.InvocationTargetException
        at com.webank.ai.fate.core.api.grpc.client.GrpcStreamingClientTemplate.calleeStreamingRpcWithImmediateDelayedResult(GrpcStreamingClientTemplate.java:155)
        at com.webank.ai.fate.driver.federation.transfer.api.grpc.client.ProxyClient.unaryCall(ProxyClient.java:128)
        ... 7 more
Caused by: io.grpc.StatusRuntimeException: INTERNAL: HTTP/2 error code: INTERNAL_ERROR
Received Rst Stream
-------------------------------

Could you please help me that which stage and reason can cause this exception, thank you very much"	1	2019-06-18 05:48:16	2019-11-05 06:12:59	2019-11-05 06:12:59
https://github.com/FederatedAI/FATE/issues/238	['bug', 'enhancement']	fix federatedml serving bug and add key hit rate statistics	"fix federatedml serving bug and add key hit rate statistics1. fix federatedml scale class and hetero-lr class double type convert
2. add key hit rate and input data utilization rateadd pr #240 "	1	2019-06-18 02:39:37	2019-06-18 09:57:40	2019-06-18 09:57:40
https://github.com/FederatedAI/FATE/issues/230	['bug']	arch/api/utils/donwload.py fails to deserialize custom objects using pickle	"arch/api/utils/donwload.py fails to deserialize custom objects using pickle**Describe the bug**
1. failed to download a dtable which had custom object by using arch/api/utils/donwload.py
2. copy download.py to another directory can work
3. the download script in arch/api/utils will use the pickle.py in the same directory instead of the native picklearch/api/utils/pickle.py is not used, which is said by eden . It can be deleted in next version"	1	2019-06-16 10:23:19	2019-08-22 09:48:09	2019-08-22 09:48:09
https://github.com/FederatedAI/FATE/issues/229	[]	Stoping when the eggroll.table is used	"Stoping when the eggroll.table is usedHi, 

When I am running the ""run_logistics_homo_cluster.sh"" as a host role.

The program stuck at the eggroll.init() when the RuntimeInstance.EGGROLL.table(""__federation__"", job_id, partition=10) which is exectly when the eggroll.table() is runing the self._create_table() which invoke the grpc client funcition self.kv_stub.createIfAbsent(create_table_info)

I check the ""self.kv_stub"" object creation that the self.channel has the correct port and host.

It seems like the request is sent and keep waiting for the response. And I didn't find the file which set up the KVServiceServicer.

Could you please tell me that what can lead to this problem and is the grpc server start up by some other files?

And if you can provide the module Readme file link for the module including the eggroll, federation and so on. It will really helpful.

Thank you very much!!I have check the instalment of grpc by running the helloworld.proto to create a simple server and client.i have the same problem, need help!!!!It seems like the server file cannot be found.Could you share your server_conf.json?
Normally you can find it at arch/conf/server_conf.json.The server_conf.json is something like that

{
""party_id"": ""1"",
""servers"": {
""manager"": {
""host"": ""192.172.0.199"",
""grpc.port"": 9360,
""http.port"": 9380
},
""servings"": [
""192.172.0.182:8001"",
"":8001""
],
""proxy"": {
""host"": ""192.172.0.199"",
""port"": 9370
},
""roll"": {
""host"": ""192.172.0.199"",
""port"": 8011
},
""federation"": {
""host"": ""192.172.0.199"",
""port"": 9394
}
}
}

And I find this conf json in the other server have all the same ip values, while in this server, there is a different value in the ""servings"". Does it affect?

Thank you!This looks like a configuration issue so we have to check on logs to see what goes wrong.

Please check `fate-roll.log` on 192.172.0.199. You can `tail -f` it in one terminal, and run `eggroll.init(job_id, 1)` in another terminal to see if there is any error message in `fate-roll.log`, or what are the last messages before getting stuck. Thanks.

Oh, almost forgot. Serving module does not affect eggroll."	6	2019-06-14 08:06:00	2019-06-18 07:15:17	2019-06-18 07:15:17
https://github.com/FederatedAI/FATE/issues/227	[]	Quantile point query in statistic module	"Quantile point query in statistic module**Is your feature request related to a problem? Please describe.**
Add quantile point query for statistic module.


**Describe the solution you'd like**
Add an api for that
Already finished"	1	2019-06-13 08:24:54	2019-07-23 08:04:13	2019-07-23 08:04:13
https://github.com/FederatedAI/FATE/issues/226	[]	"The post request in the ""workflow/status_tracer_decorator.py"""	"The post request in the ""workflow/status_tracer_decorator.py""Hello,

When running the ""run_toy_example_cluster.sh"" which will invoke the ""workflow/toy_example_workflow/secure_add_host_workflow.py "", the run() function inside the latter file is decorated by the status_tracer_decorator.status_trace which will invoke the call_back() function.

And this call_back() function will send a post request to a url ""http://192.168.0.100:9380/job/jobStatus/test0/host/0"" where ""test0"" is a jobid and the last ""0"" is the Partyid.

I am confused that which file is act to start this server service? As for the task-manager service, it is not associated with the jobid.the code is quite confusing...... I also encounter this problem!The url is used to post-back job status to task-manager and the task-manager use jobid to identify the unique job. What's more,  we use task-manager to start and control the jobs in real scenario, so jobs need to callback job status to task-manager to life cycle management of the job, status_tracer_decorator is also for this.
run_toy_example_cluster.sh or other run_$algorithm_cluster.sh scripts are just help us to be quickly familiar with Fate and for self-debugging too. If you want to know how to start task by task-manager,  have a look at this link: https://github.com/WeBankFinTech/FATE/tree/master/examples/task_manager_examples"	2	2019-06-13 03:33:03	2019-06-17 12:41:41	2019-06-17 12:41:41
https://github.com/FederatedAI/FATE/issues/225	[]	what's the difference between online and offline module	"what's the difference between online and offline moduleHello,

In the cluster-deploy directory README.md. Under the 4.3. Modify Configuration File there is a note says that 

*Note: tmipList and serving0, serving1 need to be configured only when online deployment is required, and configuration is not required only for offline deployment.*

Is the ""online"" means for the  cluster providing the online service? online represent online inference serving"	1	2019-06-13 03:10:38	2019-06-17 12:41:55	2019-06-17 12:41:55
https://github.com/FederatedAI/FATE/issues/211	[]	if not passed at ./federatedml/test/run_test.sh :34	"if not passed at ./federatedml/test/run_test.sh :34**Describe the bug**
In the file  ./federatedml/test/run_test.sh  
the 34 line should be like this: 
` 34         elif [ $file != _test.py$ ] && [ $1 != /test$ ] ; then
`
not as : 
    elif [[ $file =~ _test.py$ ]] && [[ $1 =~ /test$ ]]; then

**To Reproduce**
Steps to reproduce the behavior:
1.   sh ./federatedml/test/run_test.sh
Can the tell me more infomation like OS enviroment and other error message?  Here =~ operator is use to  regexp matching.Just use the ubuntu 16.04changed to use ubuntu 18.04"	3	2019-06-07 11:02:12	2019-06-21 09:49:36	2019-06-21 09:49:36
https://github.com/FederatedAI/FATE/issues/193	[]	Provide data transform in feature binning	"Provide data transform in feature binning**Is your feature request related to a problem? Please describe.**
After find out split points of a column, provide a data transform function to convert the binned column into its bin index。 In other words, provide a discretization function for data.

**Describe the solution you'd like**
Set this function in params and transfer base on the param setting. 
Already finished"	1	2019-05-30 03:28:28	2019-07-23 08:04:50	2019-07-23 08:04:49
https://github.com/FederatedAI/FATE/issues/191	[]	Lack of log infomation for feature selection.	"Lack of log infomation for feature selection.**Describe the bug**
Add some log information for feature selection for testing. Already finished "	1	2019-05-29 11:01:01	2019-06-11 01:47:18	2019-06-11 01:47:18
https://github.com/FederatedAI/FATE/issues/188	[]	"seems 'remote' attribute is missing in the definition of the class RuntimeInstance in the file FATE/arch/api/__init__.py"" "	"seems 'remote' attribute is missing in the definition of the class RuntimeInstance in the file FATE/arch/api/__init__.py""   File "".../PycharmProjects/FATE/arch/api/federation.py"", line 73, in remote
    return RuntimeInstance.FEDERATION.remote(obj=obj, name=name, tag=tag, role=role, idx=idx)
AttributeError: 'NoneType' object has no attribute 'remote'
Could you provide your initialization steps?

I suppose it should be something like this:
```python
from arch.api import eggroll
from arch.api import federation

eggroll.init(job_id, WORK_MODE)
federation.init(job_id, runtime_conf)
```

where job_id is a string and runtime_conf is a json or dict.I ran the sh ./examples/hetero_logistic_regression/run_logistic_regression_standalone.sh 
and got the error @maxwong 

Plus, we cannot see the log 
/Users/xiangni/PycharmProjects/FATE/examples/hetero_logistic_regression/../../logs/hetero_logistic_regression_example_standalone_20190531112937/workflow.log: No such file or directory

could you tell me where can we find the log?Hi @zazd could you provide some information on this issue?@cacoderquan is something wrong in nohup under the path:  ./examples/hetero_logistic_regression/"	4	2019-05-27 12:52:27	2019-08-22 06:51:22	2019-08-22 06:51:22
https://github.com/FederatedAI/FATE/issues/184	[]	The details of HomoLogisticRegression are different from `this paper`	"The details of HomoLogisticRegression are different from `this paper`**Describe the bug**
In this [paragraph](https://github.com/WeBankFinTech/FATE/tree/master/federatedml/logistic_regression#1-homogeneous-lr), it is described ""More details is available in this paper"". However, the implementation of HomoLR doesn't involve SecureAggregation, which is the major contribution of the paper this paragraph refers to. 

Is there something wrong?
Yes, there is something wrong in the attached paper. The paper showed before is a paper for Hetero-LR. This one[https://acmccs.github.io/papers/p1175-bonawitzA.pdf](url) is the correct one. However, we haven't realize all the mechanism metioned. The aggregation methods used can be treated as a simple version of the paper described. More secure aggregation methods will be available in the future. 

Thanks for your indication and sorry for your inconvenience. Thanks. If you've fixed it, we can close this issue."	2	2019-05-27 02:09:36	2019-06-14 13:18:56	2019-06-14 13:18:56
https://github.com/FederatedAI/FATE/issues/182	[]	The Information of Deployment Environment is needed	"The Information of Deployment Environment is needed**Describe the bug**
the version of FATE and Deployment environment should be more clearly，where can I get these information？
![mmexport1558789476977](https://user-images.githubusercontent.com/50725045/58369747-5d7b5680-7f31-11e9-82b8-50c1cb39981b.jpg)
Thanks for asking. What is the version of your pip is using? For higher than version 18.1, this problem is supposed to disapear. 

However, pip version is also needed for deploy doc. Thanks for your suggestion. "	1	2019-05-25 13:14:13	2019-05-27 04:36:40	2019-05-27 04:36:40
https://github.com/FederatedAI/FATE/issues/170	[]	While predict  one_vs_rest, the predict label type not match the input_data label type	"While predict  one_vs_rest, the predict label type not match the input_data label typeIf do predict of one_vs_rest after load_model from protobuf, the labels(classifier) type will be string, 
but input_data type may not be string(int or others sometimes). This will result to the evaluation results to be abnormal.fix this problem with #171 "	1	2019-05-22 08:46:33	2019-05-22 08:52:19	2019-05-22 08:52:19
https://github.com/FederatedAI/FATE/issues/137	[]	detailed supported documents wanted	"detailed supported documents wanted**Is your feature request related to a problem? Please describe.**
A clear and concise description of what the problem is. Ex. I'm always frustrated when [...]

**Describe the solution you'd like**
A clear and concise description of what you want to happen.

**Describe alternatives you've considered**
A clear and concise description of any alternative solutions or features you've considered.

**Additional context**
Add any other context or screenshots about the feature request here.
where are the more detailed supported documents about how it works and what features it supports and how to use it.If you want to know the features which FATE support, you can read the RELEASE.md file.
In the example module,  we give some examples and documents which told how to use.
In the federatedml modules，we also add some READEME.md file in some algorithms sub-modules.
If you have any other confusions, please tell us.
thanksok, thanks."	3	2019-05-06 08:58:06	2019-05-10 07:47:46	2019-05-10 07:47:46
https://github.com/FederatedAI/FATE/issues/135	[]	try to deploy cluster mode 	"try to deploy cluster mode **Describe the bug**
```
==> python/logs/processor-50002.log <==
Exception calling application: [Errno 2] No such file or directory
Traceback (most recent call last):
  File ""/data/projects/fate/python/arch/processor/processor.py"", line 57, in get_function
    return cloudpickle.loads(function_bytes)
  File ""/data/projects/fate/python/federatedml/toy_example/secure_add_host.py"", line 21, in <module>
    from federatedml.util.transfer_variable import SecureAddExampleTransferVariable
  File ""/data/projects/fate/python/federatedml/util/__init__.py"", line 21, in <module>
    from federatedml.util.param_checker import DataIOParamChecker
  File ""/data/projects/fate/python/federatedml/util/param_checker.py"", line 28, in <module>
    LOGGER = log_utils.getLogger()
  File ""/data/projects/fate/python/arch/api/utils/log_utils.py"", line 94, in getLogger
    frame = inspect.stack()[1]
  File ""/data/projects/common/miniconda3/lib/python3.6/inspect.py"", line 1494, in stack
    return getouterframes(sys._getframe(1), context)
  File ""/data/projects/common/miniconda3/lib/python3.6/inspect.py"", line 1471, in getouterframes
    frameinfo = (frame,) + getframeinfo(frame, context)
  File ""/data/projects/common/miniconda3/lib/python3.6/inspect.py"", line 1441, in getframeinfo
    filename = getsourcefile(frame) or getfile(frame)
  File ""/data/projects/common/miniconda3/lib/python3.6/inspect.py"", line 696, in getsourcefile
    if getattr(getmodule(object, filename), '__loader__', None) is not None:
  File ""/data/projects/common/miniconda3/lib/python3.6/inspect.py"", line 725, in getmodule
    file = getabsfile(object, _filename)
  File ""/data/projects/common/miniconda3/lib/python3.6/inspect.py"", line 709, in getabsfile
    return os.path.normcase(os.path.abspath(_filename))
  File ""/data/projects/fate/venv/lib/python3.6/posixpath.py"", line 376, in abspath
    cwd = os.getcwd()
FileNotFoundError: [Errno 2] No such file or directory

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/data/projects/fate/venv/lib/python3.6/site-packages/grpc/_server.py"", line 389, in _call_behavior
    return behavior(argument, context), True
  File ""/data/projects/fate/python/arch/processor/processor.py"", line 111, in mapValues
    _mapper, _serdes = self.get_function_and_serdes(task_info)
  File ""/data/projects/fate/python/arch/processor/processor.py"", line 233, in get_function_and_serdes
    return self.get_function(_function_bytes), self._serdes
  File ""/data/projects/fate/venv/lib/python3.6/site-packages/cachetools/__init__.py"", line 46, in wrapper
    v = func(*args, **kwargs)
  File ""/data/projects/fate/python/arch/processor/processor.py"", line 60, in get_function
    return pickle._loads(function_bytes)
  File ""/data/projects/common/miniconda3/lib/python3.6/pickle.py"", line 1558, in _loads
    encoding=encoding, errors=errors).load()
  File ""/data/projects/common/miniconda3/lib/python3.6/pickle.py"", line 1050, in load
    dispatch[key[0]](self)
  File ""/data/projects/common/miniconda3/lib/python3.6/pickle.py"", line 1347, in load_stack_global
    self.append(self.find_class(module, name))
  File ""/data/projects/common/miniconda3/lib/python3.6/pickle.py"", line 1388, in find_class
    __import__(module, level=0)
  File ""/data/projects/fate/python/federatedml/toy_example/secure_add_host.py"", line 21, in <module>
    from federatedml.util.transfer_variable import SecureAddExampleTransferVariable
  File ""/data/projects/fate/python/federatedml/util/__init__.py"", line 21, in <module>
    from federatedml.util.param_checker import DataIOParamChecker
  File ""/data/projects/fate/python/federatedml/util/param_checker.py"", line 28, in <module>
    LOGGER = log_utils.getLogger()
  File ""/data/projects/fate/python/arch/api/utils/log_utils.py"", line 94, in getLogger
    frame = inspect.stack()[1]
  File ""/data/projects/common/miniconda3/lib/python3.6/inspect.py"", line 1494, in stack
    return getouterframes(sys._getframe(1), context)
  File ""/data/projects/common/miniconda3/lib/python3.6/inspect.py"", line 1471, in getouterframes
    frameinfo = (frame,) + getframeinfo(frame, context)
  File ""/data/projects/common/miniconda3/lib/python3.6/inspect.py"", line 1441, in getframeinfo
    filename = getsourcefile(frame) or getfile(frame)
  File ""/data/projects/common/miniconda3/lib/python3.6/inspect.py"", line 696, in getsourcefile
    if getattr(getmodule(object, filename), '__loader__', None) is not None:
  File ""/data/projects/common/miniconda3/lib/python3.6/inspect.py"", line 725, in getmodule
    file = getabsfile(object, _filename)
  File ""/data/projects/common/miniconda3/lib/python3.6/inspect.py"", line 709, in getabsfile
    return os.path.normcase(os.path.abspath(_filename))
  File ""/data/projects/fate/venv/lib/python3.6/posixpath.py"", line 376, in abspath
    cwd = os.getcwd()
FileNotFoundError: [Errno 2] No such file or directory

```Another excpetion is:

Tutorial: https://github.com/WeBankFinTech/FATE/tree/master/cluster-deploy
when I run 
```
export PYTHONPATH=/data/projects/fate/python 
source /data/projects/fate/venv/bin/activate
cd /data/projects/fate/python/examples/toy_example/
sh run_toy_examples_standalone.sh
``` 
 It shows success.

However I run
```
export PYTHONPATH=/data/projects/fate/python 
source /data/projects/fate/venv/bin/activate
cd /data/projects/fate/python/examples/toy_example/
 sh run_toy_example_cluster.sh host job_1 1000 999
sh run_toy_example_cluster.sh guest job_1 1000 999
``` 

```
(venv) [app@e1ff17e6162d fate]$ cd python/logs/
(venv) [app@e1ff17e6162d logs]$ ls
123  toy_example_20190429125615
(venv) [app@e1ff17e6162d logs]$ cat 
123/                        toy_example_20190429125615/ 
(venv) [app@e1ff17e6162d logs]$ cat 123/
eggroll.log                  status_tracer_decorator.log  
(venv) [app@e1ff17e6162d logs]$ cat 123/eggroll.log 
""2019-04-29 12:56:46,012 - eggroll.py[line:160] - DEBUG: created table: type:LMDB namespace:123 name:__federation__ partitions:10""
""2019-04-29 12:56:48,491 - eggroll.py[line:177] - DEBUG: created table: type:IN_MEMORY namespace:123 name:3e99101c-6a7e-11e9-b2e0-0242ac110002 partitions:1""
""2019-04-29 12:56:51,870 - eggroll.py[line:160] - DEBUG: created table: type:LMDB namespace:123 name:__federation__ partitions:10""
""2019-04-29 12:56:52,520 - eggroll.py[line:177] - DEBUG: created table: type:IN_MEMORY namespace:123 name:4216fbdc-6a7e-11e9-bb5a-0242ac110002 partitions:1""
(venv) [app@e1ff17e6162d logs]$ cat 123/status_tracer_decorator.log 
""2019-04-29 12:56:49,725 - status_tracer_decorator.py[line:73] - INFO: job status is failed""
""2019-04-29 12:56:49,726 - status_tracer_decorator.py[line:74] - INFO: Traceback (most recent call last):
  File ""/data/projects/fate/python/workflow/status_tracer_decorator.py"", line 69, in wrapper
    res = func(self, *args, **kwargs)
  File ""../../workflow/toy_example_workflow/secure_add_host_workflow.py"", line 66, in run
    self.secure_add_host_inst.run()
  File ""/data/projects/fate/python/federatedml/toy_example/secure_add_host.py"", line 68, in run
    self.secure()
  File ""/data/projects/fate/python/federatedml/toy_example/secure_add_host.py"", line 39, in secure
    y_shares = self.y.mapValues(self.share)
  File ""/data/projects/fate/python/arch/api/cluster/eggroll.py"", line 109, in mapValues
    return _EggRoll.get_instance().map_values(self, func)
  File ""/data/projects/fate/python/arch/api/cluster/eggroll.py"", line 302, in map_values
    resp = self.proc_stub.mapValues(unary_p)
  File ""/data/projects/fate/venv/lib/python3.6/site-packages/grpc/_channel.py"", line 533, in __call__
    return _end_unary_response_blocking(state, call, False, None)
  File ""/data/projects/fate/venv/lib/python3.6/site-packages/grpc/_channel.py"", line 467, in _end_unary_response_blocking
    raise _Rendezvous(state, None, None, deadline)
grpc._channel._Rendezvous: <_Rendezvous of RPC that terminated with:
	status = StatusCode.INTERNAL
	details = ""172.17.0.2:8011: com.webank.ai.fate.core.error.exception.MultipleRuntimeThrowables: error occured in sub tasks. processor type: MapValuesServiceProcessor
	at com.webank.ai.fate.eggroll.roll.api.grpc.server.RollProcessServiceImpl$ProcessServiceTemplate.run(RollProcessServiceImpl.java:324)
	at com.webank.ai.fate.core.api.grpc.server.GrpcServerWrapper.wrapGrpcServerRunnable(GrpcServerWrapper.java:51)
	at com.webank.ai.fate.eggroll.roll.api.grpc.server.RollProcessServiceImpl.mapValues(RollProcessServiceImpl.java:115)
	at com.webank.ai.fate.api.eggroll.processor.ProcessServiceGrpc$MethodHandlers.invoke(ProcessServiceGrpc.java:626)
	at io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:171)
	at io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:283)
	at io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:710)
	at io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.Throwable: idx: 0
java.lang.RuntimeException: java.lang.reflect.InvocationTargetException
	at com.webank.ai.fate.eggroll.roll.api.grpc.client.EggProcessServiceClient.unaryProcessToStorageLocatorUnaryCall(EggProcessServiceClient.java:146)
	at com.webank.ai.fate.eggroll.roll.api.grpc.client.EggProcessServiceClient.mapValues(EggProcessServiceClient.java:57)
	at com.webank.ai.fate.eggroll.roll.service.async.processor.MapValuesServiceProcessor.call(MapValuesServiceProcessor.java:35)
	at com.webank.ai.fate.eggroll.roll.service.async.processor.MapValuesServiceProcessor.call(MapValuesServiceProcessor.java:26)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.reflect.InvocationTargetException
	at com.webank.ai.fate.core.api.grpc.client.GrpcStreamingClientTemplate.calleeStreamingRpcWithImmediateDelayedResult(GrpcStreamingClientTemplate.java:153)
	at com.webank.ai.fate.eggroll.roll.api.grpc.client.EggProcessServiceClient.unaryProcessToStorageLocatorUnaryCall(EggProcessServiceClient.java:144)
	... 7 more
Caused by: io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at io.grpc.Status.asRuntimeException(Status.java:526)
	at io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:434)
	at io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39)
	at io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23)
	at io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40)
	at io.grpc.internal.CensusStatsModule$StatsClientInterceptor$1$1.onClose(CensusStatsModule.java:678)
	at io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39)
	at io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23)
	at io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40)
	at io.grpc.internal.CensusTracingModule$TracingClientInterceptor$1$1.onClose(CensusTracingModule.java:397)
	at io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:459)
	at io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:63)
	at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:546)
	at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:467)
	at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:584)
	at io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
	... 3 more
Caused by: io.grpc.netty.shaded.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /172.17.0.2:50001
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.grpc.netty.shaded.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at io.grpc.netty.shaded.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at io.grpc.netty.shaded.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at io.grpc.netty.shaded.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at io.grpc.netty.shaded.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at io.grpc.netty.shaded.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at io.grpc.netty.shaded.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at io.grpc.netty.shaded.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
```




See https://github.com/grpc/grpc/issues/12116
"	2	2019-04-29 09:49:50	2019-08-29 14:20:39	2019-04-29 14:48:20
https://github.com/FederatedAI/FATE/issues/107	[]	Add doc in examples and main features. 	"Add doc in examples and main features. **Is your feature request related to a problem? Please describe.**
Add README doc in each examples and some feature directory so that users can use them easier. 

**Describe the solution you'd like**
Add doc
Has provided in version 0.2"	1	2019-04-18 09:42:14	2019-04-19 06:17:06	2019-04-19 06:17:06
https://github.com/FederatedAI/FATE/issues/101	['bug']	hetero-lr minibatch bug	hetero-lr minibatch bugThe hetero-lr loss converge depend on iter loss， but now in hetero-lr， it depend on batch loss. This means finishing one batch training, it will decide whether converge or not.close by Feature 0.2 fix bugs #100	1	2019-04-13 09:06:25	2019-04-13 11:51:27	2019-04-13 11:51:27
https://github.com/FederatedAI/FATE/issues/93	['bug']	accurate average gradient and loss	"accurate average gradient and loss**Is your feature request related to a problem? Please describe.**
current average algorithm is E = (s1/cnt1 + s2/cnt2 + ...)/partitions， not a really  mean

**Describe the solution you'd like**
E = (s1 + s2 + ...)/(cn1 + cnt2 + ...)


In fact, we evaluator two methods in some datasets. The results show that the two methods are very close. 
But your solution seems to be better mathematically, so we merged your pr."	1	2019-04-12 02:51:15	2019-08-29 14:20:38	2019-04-13 05:07:32
https://github.com/FederatedAI/FATE/issues/85	['bug']	Use clean up In status_tracer_decorator cause bug	"Use clean up In status_tracer_decorator cause bug**Describe the bug**
use clean up api in status tracer_decorator will cause bugs. Because in many situations, mostly standalone version, host or guest finish first will clean all job's data.


bug fix, delete cleanup api use in status_tracer_decorator"	1	2019-04-08 08:58:30	2019-04-08 09:12:46	2019-04-08 09:11:42
https://github.com/FederatedAI/FATE/issues/79	[]	SecureBoost online inference	"SecureBoost online inference**Is your feature request related to a problem? Please describe.**
A clear and concise description of what the problem is. Ex. I'm always frustrated when [...]

**Describe the solution you'd like**
A clear and concise description of what you want to happen.

**Describe alternatives you've considered**
A clear and concise description of any alternative solutions or features you've considered.

**Additional context**
Add any other context or screenshots about the feature request here.
support secureboost online inference in fate-serving"	1	2019-04-04 12:10:43	2019-11-05 06:11:39	2019-11-05 06:11:39
https://github.com/FederatedAI/FATE/issues/77	['bug']	Input data abnormal	"Input data abnormal**Describe the bug**
If input DTABLE of any component （lr， secureboost，feature eng ，etc） is empty（not any keys，or have keys but values are None） ， what happen？


Added two abnormal checking methods. It's avaible to check if a table has no value or count is 0. These situation will be treat as abnormal so that raise a ValueError. "	1	2019-04-04 11:45:50	2019-08-29 14:20:38	2019-04-13 11:54:35
https://github.com/FederatedAI/FATE/issues/56	[]	How to improve the efficiency of paillier or other homomorphic encryption algorithm?	"How to improve the efficiency of paillier or other homomorphic encryption algorithm?I evaluated the computational efficiency of paillier in Fate(denoted as paillier_fate) and paillier implemented in python(https://github.com/n1analytics/python-paillier , denoted as paillier_python), the  calculation efficiency of paillier_fate is more than six times higher than paillier_python. 

The implementations of the two algorithms are similar. So, i want to know how to improve the efficiency of paillier.  Are there any other homomorphic encryption libraries or implementation tips that can improve efficiency.we test our fate-paillier is same as paillier_python.   
paillier_python： generate_paillier_keypair(n_length=1024) 
 fate-paillier：   PaillierKeypair.generate_keypair(n_length=1024)  

Maybe n_length is not same in your testcaseThanks for your reply! @dylan-fan

1. It is indeed due to the n_length. Moreover, if n_length is set too samll, the decoding will fail. So, what is the smallest value of n_length in safe condition.

2. How much is the efficiency difference between an encrypted LR and an unencrypted LR?

3. Have you tried other homomorphic encryption librarys? such as HELib、SEAL、Pyfhel、FV-NFLib...?


> 
> 
> we test our fate-paillier is same as paillier_python.
> paillier_python： generate_paillier_keypair(n_length=1024)
> fate-paillier： PaillierKeypair.generate_keypair(n_length=1024)
> 
> Maybe n_length is not same in your testcase

Thanks for your reply! @dylan-fan

1. It is indeed due to the n_length. Moreover, if n_length is set too samll, the decoding will fail. So, what is the smallest value of n_length in safe condition.

2. How much is the efficiency difference between an encrypted LR and an unencrypted LR?

3. Have you tried other homomorphic encryption librarys? such as HELib、SEAL、Pyfhel、FV-NFLib...?
1.  n_length>=1024  maybe better
2. encrypted LR  is slower than unencrypted LR，but accuracy is similar. Efficiency  problem in encrypted LR can be resolved in distributed computing. You can run our lr example and see the result.
3. phe , google homomorphic encryption lib.Deep learning is very computationally intensive, and the use of homomorphic encryption will make the efficiency of training very low.  Could you tell me what homomorphic encryption libraries you used to implement the deep learning model, or what optimization techniques did you use on the paillier library ?"	4	2019-03-28 11:10:19	2019-04-03 08:36:10	2019-04-03 08:36:10
https://github.com/FederatedAI/FATE/issues/55	['bug', 'arch']	One-second latency after each transfer event	"One-second latency after each transfer eventNote that the Proxy.Packet (in arch/networking/proxy/src/main/java/com/webank/ai/fate/networking/proxy/grpc/client/DataTransferPipedClient.java line 96)do one extra read from the pipe which is already drained, and the read function set a timeout of 1 second to ensure the pipe has no packets. This may cause an one-second latency at the end of each transfer event. 

This can be solved by adding a ""isDrain"" check before polling packets from the pipe. 

I have tried to add a line of code ""if (isDrained()) return result;"" between line 66 and line 67 of PacketQueuePipe.java(in arch/networking/proxy/src/main/java/com/webank/ai/fate/networking/proxy/infra/impl/) , the training examples works properly and the latency is removed. 

Thanks for your feedback. We are looking into it.thanks，welcome to FATE contributormerge"	3	2019-03-28 08:16:18	2019-03-29 03:18:41	2019-03-29 03:18:41
https://github.com/FederatedAI/FATE/issues/43	['bug', 'arch']	ERROR in SendProcessor with limited number of CPUs	"ERROR in SendProcessor with limited number of CPUsWe rent multiple machines on google cloud for running the FATE project. In the beginning, we used machines with 2 vCPUs. While running the cluster code for hetero_logistic_regression, we get an Error from arbiter when sending public-keys to guest and host(console.log in federation):

[ERROR] 2019-03-18T07:11:15,361 [transferJobSchedulerExecutor-2] [SendProcessor:94] - java.lang.IndexOutOfBoundsException: Index: 0, Size: 0
        at java.util.ArrayList.rangeCheck(ArrayList.java:657)
        at java.util.ArrayList.get(ArrayList.java:433)
        at com.webank.ai.fate.driver.federation.transfer.service.impl.DefaultProxySelectionService.select(DefaultProxySelectionService.java:81)
        at com.webank.ai.fate.driver.federation.transfer.communication.processor.SendProcessor.run(SendProcessor.java:70)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)

[ERROR] 2019-03-18T07:11:24,396 [transferJobSchedulerExecutor-2] [GrpcChannelFactory:119] - [COMMON][CHANNEL][ERROR] Error getting ManagedChannel after retries
[ERROR] 2019-03-18T07:11:24,397 [transferJobSchedulerExecutor-2] [TransferJobScheduler:127] - [FEDERATION][SCHEDULER] processor failed: transferMetaId: cxz-HeteroLRTransferVariable.paillier_pubkey-HeteroLRTransferVariable.paillier_pubkey.0-2-arbiter-1-guest, exception: java.lang.RuntimeException: should never get here
        at com.webank.ai.fate.core.factory.GrpcStubFactory.createGrpcStub(GrpcStubFactory.java:47)
        at com.webank.ai.fate.core.factory.GrpcStubFactory.createGrpcStub(GrpcStubFactory.java:56)
        at com.webank.ai.fate.core.api.grpc.client.GrpcAsyncClientContext.createStub(GrpcAsyncClientContext.java:207)
        at com.webank.ai.fate.core.api.grpc.client.GrpcStreamingClientTemplate.calleeStreamingRpc(GrpcStreamingClientTemplate.java:106)
        at com.webank.ai.fate.core.api.grpc.client.GrpcStreamingClientTemplate.calleeStreamingRpcWithImmediateDelayedResult(GrpcStreamingClientTemplate.java:149)
        at com.webank.ai.fate.driver.federation.transfer.api.grpc.client.ProxyClient.unaryCall(ProxyClient.java:98)
        at com.webank.ai.fate.driver.federation.transfer.api.grpc.client.ProxyClient.requestSendEnd(ProxyClient.java:121)
        at com.webank.ai.fate.driver.federation.transfer.communication.processor.SendProcessor.run(SendProcessor.java:98)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)

and we tried the same code using machines with 8 vCPUs, the ERROR cannot be reproduced. 

Here are the configurations of the two groups of machines: 
The former ones: Google Cloud n1-standard-2 machines with 2 vCPUs and 7.5GB RAM

The latter ones: Google Cloud n1-standard-8 machines with 8 vCPUs and 30GB RAM



Thanks for your feedback. We are looking into it."	1	2019-03-22 03:54:10	2019-11-05 06:12:29	2019-11-05 06:12:29
https://github.com/FederatedAI/FATE/issues/27	['bug']	Training validation in workflow need to reset flowid	"Training validation in workflow need to reset flowid**Describe the bug**
In workflow, if not reset the flowid in validation stage, guest will receive old federation object, may raise a bug.

**To Reproduce**
Steps to reproduce the behavior:
set train and predict data totally different id sets, and run examples.

**Additional context**
If reset flowid in validation stage, it works perfectly.
fix！！"	1	2019-03-12 09:18:38	2019-08-29 14:20:37	2019-04-03 04:07:19
https://github.com/FederatedAI/FATE/issues/18	[]	Lacking of Basic Dashboard Support	"Lacking of Basic Dashboard Support**Is your feature request related to a problem? Please describe.**
It's very hard to observe a training progress, when there is no dashboard or visualization of the whole process

**Describe the solution you'd like**
Tensorboard like or at  least something that is on the  same level with the spark dashboard

**Describe alternatives you've considered**
Nope
Thanks for your advice. This is a very important feature. We plan to implement the feature (view task list, tracking task progress, visualization, etc) in the next version."	1	2019-03-04 07:31:33	2019-08-29 14:20:36	2019-04-04 12:13:46
https://github.com/FederatedAI/FATE/issues/6	[]	Docker support	"Docker support**Is your feature request related to a problem? Please describe.**
A clear and concise description of what the problem is. Ex. I'm always frustrated when [...]

**Describe the solution you'd like**
A clear and concise description of what you want to happen.

**Describe alternatives you've considered**
A clear and concise description of any alternative solutions or features you've considered.

**Additional context**
Add any other context or screenshots about the feature request here.
Hi ljch2018, please provide more details of your request. Your request seems like a request template only.

BTW, Docker is supported in standalone deployment.  You may want to have a look at `FATE/docker/standalone/`. Thanks.HI !  please provide a cluster-deploy for docker by docker-compose，so we can use it straight!,Parameters preferably support one-click configuration. your packaging.sh exits error ""targets=`find ""$base_dir"" -type d -name ""target"" -mindepth 2`""Hi lijiacaigit, thanks for your advice. Docker images for cluster deploy has been planned and will be available in one of future releases, and we are working on it. For now I'm afraid you have to deploy them manually.

As for the error you reported, packaging.sh has been tested in our env before releasing. So could you provide us the followings:
a. The error message, either copying it or uploading a screenshot;
b. Your environment info, e.g. operating system and its version, bash version etc.

Thanks.Hi.
1.when will the docker version of cluster deployment be available? 
2.packaging.sh has `find ""$base_dir"" -type dir -name ""target"" -mindepth 2`"",you can execute the command in your terminal , and you will get error like ""find: Arguments to -type should contain only one letter""


> Hi.
> 1.when will the docker version of cluster deployment be available?
> 2.packaging.sh has `find ""$base_dir"" -type dir -name ""target"" -mindepth 2`"",you can execute the command in your terminal , and you will get error like ""find: Arguments to -type should contain only one letter""

1. We are planning to contain cluster deployment on docker in version 0.3. Hopefully in late April or early May this year.
2. Checked manual and `-type d` works better indeed. Will change this soon. 

Thank you for the feedback.Ok！
Mysql service required for cluster deployment?
When I deployed, I found that some environment dependencies were ambiguous，your documentation is more detailed, and it will be easier to deploy, preferably with one-click configuration> Ok！
> Mysql service required for cluster deployment?
> When I deployed, I found that some environment dependencies were ambiguous，your documentation is more detailed, and it will be easier to deploy, preferably with one-click configuration

Yes, mysql service is required for cluster deployment.
Thank you for your advice and we will add dependency description in documents. 
And we will try to automate deployment, though it could be quite a process.Closing this issue as has been resolved. User may reopen it if there is further question on this issue."	8	2019-02-21 03:57:35	2019-03-04 08:16:47	2019-02-28 09:06:50

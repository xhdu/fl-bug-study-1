url	label	title	search_text	comments	created_time	updated_time	closed_time
https://github.com/adap/flower/issues/817	[]	Error: 'Sequential' object has no attribute 'set_weight'	"Error: 'Sequential' object has no attribute 'set_weight'So I am trying out Federated Learning on structured data and following this [dataset of German credit data](https://www.kaggle.com/kabure/german-credit-data-with-risk). I have a simple tensorflow based model and code. 

Here is my client class- 

```
class GCR_Client(fl.client.NumPyClient):
    def __init__(self, model, x_train, y_train, client_name):
        self.model = model
        self.x_train = x_train
        self.y_train = y_train
        self.client_name = client_name
    
    def get_parameters(self):
        return self.model.get_weights()
    
    def fit(self, parameters, config):
        self.model.set_weights(parameters)
        self.model.fit(self.x_train.values, self.y_train.values, epochs=15, batch_size=64)
        return self.model.get_weights(), len(self.x_train), {""Fit Data from"":self.client_name}
    
    def evaluate(self, parameters, config):
        self.model.set_weight(parameters)
        return 0,0,{""Clinet Evaluation"" : ""Undefined"", ""Client Name"":self.client_name}
```


In order to remove all the external factors I removed the code where I calculate the evaluation. 

Whenever I run the code with 1 server and multiple clients, I get error in the `def evaluate(self, parameters, config)` function. 
Error is `'Sequential' object has no attribute 'set_weight'`

`def fit(self, parameters, config):` method contains the same line but the error is only being generated from `evaluate` function only. I am not sure what's wrong with the code. @Samvid95 thanks for reaching out. Could it be the missing `s`?

- `self.model.set_weights(parameters)` in `fit`
- `self.model.set_weight(parameters)` in `evaluate`Hahaha I completely missed it. Thank you 

Now let me remove this question from the face of the internet. /s"	2	2021-08-17 04:58:41	2021-08-18 08:26:47	2021-08-18 08:26:47
https://github.com/adap/flower/issues/807	[]	set_parameters wrong	"set_parameters wrongHello, when using the efficientnetb0 pre-training model, the joint training will stop at the position shown in the figure below, and the following error will be reported.
![image](https://user-images.githubusercontent.com/59415080/127867393-9591b26e-e0df-49f3-8f7d-869cd3fbe248.png)
![image](https://user-images.githubusercontent.com/59415080/127867469-9b6f244a-35a0-43af-a842-e3fd7af22767.png)
Hello,I have the same problem. Have you solved itï¼ŸI've faced the same problem too.Iâ€™m watching the fedBN example of flower official website.because your model has the 'bn' layer, the model parameters to numpy parameters will wrong
![image](https://user-images.githubusercontent.com/59415080/130625040-9c9e315a-3a63-4386-93b1-5033128812b9.png)
This official code gives the correct idea.server and client add like the next picture describe.
![image](https://user-images.githubusercontent.com/59415080/130626479-f20a1900-b7b9-4aaf-b0fc-078b72c70da4.png)

"	3	2021-08-02 13:12:55	2021-08-24 13:39:54	2021-08-24 13:39:31
https://github.com/adap/flower/issues/756	[]	Client not starting	"Client not startingAm getting the following error when I try to start client after server while trying to run the below example.

[pytorch_from_centralized_to_federated](https://github.com/adap/flower/tree/main/examples/pytorch_from_centralized_to_federated)

`Files already downloaded and verified
Files already downloaded and verified
DEBUG flower 2021-06-10 15:54:23,140 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-06-10 15:54:23,140 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-06-10 15:54:23,141 | connection.py:36 | ChannelConnectivity.TRANSIENT_FAILURE
INFO flower 2021-06-10 15:54:23,141 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-06-10 15:54:23,343 | connection.py:68 | Insecure gRPC channel closed
Traceback (most recent call last):
  File ""client.py"", line 98, in <module>
    main()
  File ""client.py"", line 94, in main
    fl.client.start_numpy_client(""[::]:8080"", client)
  File ""C:\Users\HP\anaconda3\lib\site-packages\flwr\client\app.py"", line 112, in start_numpy_client
    start_client(
  File ""C:\Users\HP\anaconda3\lib\site-packages\flwr\client\app.py"", line 64, in start_client
    server_message = receive()
  File ""C:\Users\HP\anaconda3\lib\site-packages\flwr\client\grpc_client\connection.py"", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File ""C:\Users\HP\anaconda3\lib\site-packages\grpc\_channel.py"", line 416, in __next__
    return self._next()
  File ""C:\Users\HP\anaconda3\lib\site-packages\grpc\_channel.py"", line 689, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
        status = StatusCode.UNAVAILABLE
        details = ""failed to connect to all addresses""
        debug_error_string = ""{""created"":""@1623320663.140000000"",""description"":""Failed to pick subchannel"",""file"":""src/core/ext/filters/client_channel/client_channel.cc"",""file_line"":4134,""referenced_errors"":[{""created"":""@1623320663.140000000"",""description"":""failed to connect to all addresses"",""file"":""src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc"",""file_line"":398,""grpc_status"":14}]}""
>`
![image](https://user-images.githubusercontent.com/16716026/121510537-5edb2700-ca05-11eb-9d22-90c7fed7c863.png)

Python Version: 3.8.5
OS: Windows 10
RAM: 8 GB
Using conda base environment to run this.I had the same problem on Windows. Just try to insert ""localhost"" instead of ""[::]"" in the address provided in the client and server code. That is:
[client.py] fl.client.start_numpy_client(""localhost:8080"", client=client)
[server.py] fl.server.start_server(""localhost:8080"", config={""num_rounds"": HERE_YOUR_NUM_OF_ROUNDS}, strategy=strategy)"	1	2021-06-10 10:33:55	2021-06-11 07:31:17	2021-06-11 07:31:16
https://github.com/adap/flower/issues/751	[]	grpc client server communication is not working when client and server is started from different terminals	"grpc client server communication is not working when client and server is started from different terminalsHi flower developers,

I tried the examples provided with flower and they work if I start the server and clients with the run.sh script, but communication stalls if client and server are started from different terminals.  The log from the client:

DEBUG flower 2021-06-07 17:37:16,844 | connection.py:36 | ChannelConnectivity.READY

This is where it waits indefinitely. At a keyboard interrupt, the log is the following:

File ""client.py"", line 34, in <module>
    fl.client.start_numpy_client(""[::]:8080"", client=CifarClient())
  File ""/home/sallogy/anaconda3/envs/flower/lib/python3.7/site-packages/flwr/client/app.py"", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File ""/home/sallogy/anaconda3/envs/flower/lib/python3.7/site-packages/flwr/client/app.py"", line 64, in start_client
    server_message = receive()
  File ""/home/sallogy/anaconda3/envs/flower/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py"", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File ""/home/sallogy/anaconda3/envs/flower/lib/python3.7/site-packages/grpc/_channel.py"", line 426, in __next__
    return self._next()
  File ""/home/sallogy/anaconda3/envs/flower/lib/python3.7/site-packages/grpc/_channel.py"", line 817, in _next
    _common.wait(self._state.condition.wait, _response_ready)
  File ""/home/sallogy/anaconda3/envs/flower/lib/python3.7/site-packages/grpc/_common.py"", line 141, in wait
    _wait_once(wait_fn, MAXIMUM_WAIT_TIMEOUT, spin_cb)
  File ""/home/sallogy/anaconda3/envs/flower/lib/python3.7/site-packages/grpc/_common.py"", line 106, in _wait_once
    wait_fn(timeout=timeout)
  File ""/home/sallogy/anaconda3/envs/flower/lib/python3.7/threading.py"", line 300, in wait
    gotit = waiter.acquire(True, timeout)
KeyboardInterrupt

The log from the server:

INFO flower 2021-06-07 17:36:33,616 | app.py:76 | Flower server running (insecure, 3 rounds)
INFO flower 2021-06-07 17:36:33,617 | server.py:118 | Getting initial parameters
INFO flower 2021-06-07 17:37:16,913 | server.py:306 | Received initial parameters from one random client
INFO flower 2021-06-07 17:37:16,913 | server.py:120 | Evaluating initial parameters
INFO flower 2021-06-07 17:37:16,913 | server.py:133 | FL starting

It seems that it blocks in python threading. I tried also with different versions of python, the same result. What can be the problem?@sallogy can you share a bit more information about your runtime environment?

* Which OS (incl. version) e.g. Ubuntu 18.04
* Which CPU/GPU
* How much RAM

Also what code did you run? A specific Flower example? Did you bootstrap your own project without any example? Some context is very much appreciated.
Sorry, my mistake. When I dug into the source code, I realized that the default FedAvg strategy expects minimum 2 clients in order to start the training, and I tried with 1 client (actually I dockerized the client and server, and I thought that it is some issue related to this, but not). . Anyway, some informative message about the minimum number of clients required to start the training would be helpful.   @sallogy Happy to hear you could resolve the problem. Would you like to propose it as an idea here: https://github.com/adap/flower/discussions/categories/ideas and explain a little what you would consider a good solution? I would close this ticket for now as it's resolved."	3	2021-06-07 16:14:50	2021-06-11 07:35:00	2021-06-11 07:35:00
https://github.com/adap/flower/issues/712	[]	Using results returned from client's fit	"Using results returned from client's fitI want to save the results returned to the server by the client's fit method and save them. 
I am not sure how I am supposed to access the results in the server script.

The example in https://flower.dev/docs/saving-progress.html#aggregate-custom-evaluation-results only covers results from the clients evaluate function but does not show results from the client's fit function.

In the [advanced_tensorflow](https://github.com/adap/flower/blob/main/examples/advanced_tensorflow/client.py) example, the client's `fit` method is returning some results to the server, but the `server.py` is not using the these results anywhere. 

I could also do this if there was a way to access all the returned accuracies and results from the clients after the fl is finished.

is there an api reference of the returned result object ?Hi @cozek , thanks for the questions. What you want to do isn't properly documented yet (and there will be built-in improvements in future releases), but you could do it in the same way as it's done in the docs you linked above. The only difference is that you'd override `aggregate_fit` instead of `aggregate_evaluate`:

```python
class SaveCustomFitMetricStrategy(fl.server.strategy.FedAvg):
    def aggregate_fit(
        self,
        rnd: int,
        results: List[Tuple[ClientProxy, FitRes]],
        failures: List[BaseException],
    ) -> Optional[Weights]:
        """"""Aggregate evaluation losses using weighted average.""""""
        if not results:
            return None

        # Save results
        for _, fit_res in results:
            fit_metrics = fit_res.metrics
            print(""TODO: save individual results here"", fit_metrics)

        # Call aggregate_fit from base class (FedAvg)
        return super().aggregate_fit(rnd, results, failures)
```

The `results` object is a list of tuples (pairs of `(ClientProxy, FitRes)`), the code example above shows how to get the dictionary returned by `Client.fit` from `FitRes`. The `flwr.common.typing` module contains many type definitions (for future reference):

https://github.com/adap/flower/blob/main/src/py/flwr/common/typing.py@danieljanes Thanks for the code example and quick reply. This solves my use case for now. "	2	2021-05-06 12:37:05	2021-05-07 19:40:25	2021-05-07 19:40:25
https://github.com/adap/flower/issues/710	[]	Connection issue tf-quickstart	"Connection issue tf-quickstartHi there, 

I am trying to implement flower and going through the tensorflow quickstart tutorial. And I am encountering the following error: 

```
 status = StatusCode.UNAVAILABLE
 details = ""failed to connect to all addresses""
```

My issue is the same one as #648 & #537  

I tried changing the port value to IPv6 as well as tried multiple ports but nothing worked for me.  Is there anything else I can do?

My setup: 
Windows 10 with Anaconda virtual environment.

Best,
SamvidHi @Samvid95 , thanks for reaching out.

We had Windows users who had issues with their firewall, could you try turning that off?

Other than that you could try to use WSL2 on Windows 10, that should work like a charm (some of the Flower core devs use it on a daily basis w/ Ubuntu 18.04 or 20.04). Awesome. It works.@Samvid95 great, happy to hear!"	3	2021-05-05 14:45:36	2021-05-11 15:59:17	2021-05-11 13:24:18
https://github.com/adap/flower/issues/659	[]	QFedAvg Loss Unitialized Error	"QFedAvg Loss Unitialized ErrorHello,
I am trying to use the qffedavg strategy and getting ""NameError: free variable 'loss' referenced before assignment in enclosing scope."" I think the problem is that I did not specify an evaluation function as a parameter so the loss variable is not initialized before it is called later in the program. If I understand right, then if the loss really is necessary for q-FedAvg the evaluation function parameter should not be optional. Otherwise, the for loop after the line where loss is supposed to be initialized (line 185) should first check that loss is not None.

Also, from the paper, I think the correct name of the algorithm is qFedAvg not qFFedAvg as the strategy is named here. 

Is there an example for the evaluation function?


Server code:
```
import flwr as fl
from flwr.server import Server, SimpleClientManager

def main():
    strategy = fl.server.strategy.QffedAvg(min_available_clients=2)

    myServer = Server(client_manager = SimpleClientManager(), strategy=strategy)

    fl.server.start_server(server_address= ""localhost:8080"", server = myServer, config={""num_rounds"": 5})

if __name__ == ""__main__"":
    main()
```

Error message produced:
```
Traceback (most recent call last):
  File ""C:\Users\wishi\OneDrive - University of Kentucky\FLCode\Organized_Pytorch\DataDistributions\centralizedDist\trimmedServer.py"", line 12, in <module>
    main()
  File ""C:\Users\wishi\OneDrive - University of Kentucky\FLCode\Organized_Pytorch\DataDistributions\centralizedDist\trimmedServer.py"", line 9, in main
    fl.server.start_server(server_address= ""localhost:8080"", server = myServer, config={""num_rounds"": 5})
  File ""C:\Users\wishi\AppData\Local\Programs\Python\Python37\lib\site-packages\flwr\server\app.py"", line 79, in start_server
    _fl(server=initialized_server, config=initialized_config)
  File ""C:\Users\wishi\AppData\Local\Programs\Python\Python37\lib\site-packages\flwr\server\app.py"", line 108, in _fl
    hist = server.fit(num_rounds=config[""num_rounds""])
  File ""C:\Users\wishi\AppData\Local\Programs\Python\Python37\lib\site-packages\flwr\server\server.py"", line 92, in fit
    weights_prime = self.fit_round(rnd=current_round)
  File ""C:\Users\wishi\AppData\Local\Programs\Python\Python37\lib\site-packages\flwr\server\server.py"", line 181, in fit_round
    return self.strategy.aggregate_fit(rnd, results, failures)
  File ""C:\Users\wishi\AppData\Local\Programs\Python\Python37\lib\site-packages\flwr\server\strategy\qffedavg.py"", line 193, in aggregate_fit
    [np.float_power(loss + 1e-10, self.q_param) * grad for grad in grads]
  File ""C:\Users\wishi\AppData\Local\Programs\Python\Python37\lib\site-packages\flwr\server\strategy\qffedavg.py"", line 193, in <listcomp>
    [np.float_power(loss + 1e-10, self.q_param) * grad for grad in grads]
NameError: free variable 'loss' referenced before assignment in enclosing scope


```
Hi @smoser82 , thanks a lot for the detailed report!

We do have an example for the evaluation function in the Advanced TensorFlow Example (https://github.com/adap/flower/tree/main/examples/advanced_tensorflow, and a few more in deprecated parts of the codebase under `src/py/flwr_example` and `src/py/flwr_experimental`, but those will be removed eventually).

The gist is to hand a function to the strategy that takes model parameters and return the evaluation result:

```python
def main() -> None:
    # Create strategy
    strategy = fl.server.strategy.FedAvg(
        fraction_fit=0.3,
        fraction_eval=0.2,
        min_fit_clients=3,
        min_eval_clients=2,
        min_available_clients=10,
        eval_fn=get_eval_fn(),
        on_fit_config_fn=fit_config,
        on_evaluate_config_fn=evaluate_config,
    )
    # Start Flower server for four rounds of federated learning
    fl.server.start_server(""[::]:8080"", config={""num_rounds"": 4}, strategy=strategy)


def get_eval_fn():
    """"""Return an evaluation function for server-side evaluation.""""""

    # Load data and model here to avoid the overhead of doing it in `evaluate` itself
    (x_train, y_train), _ = tf.keras.datasets.cifar10.load_data()

    # Use the last 5k training examples as a validation set
    x_val, y_val = x_train[45000:50000], y_train[45000:50000]

    # Load and compile model
    model = tf.keras.applications.EfficientNetB0(
        input_shape=(32, 32, 3), weights=None, classes=10
    )
    model.compile(""adam"", ""sparse_categorical_crossentropy"", metrics=[""accuracy""])

    # The `evaluate` function will be called after every round
    def evaluate(weights: fl.common.Weights) -> Optional[Tuple[float, float]]:
        model.set_weights(weights)  # Update model with the latest parameters
        loss, accuracy = model.evaluate(x_val, y_val)
        return loss, accuracy

    return evaluate
```

Does this solve your issue?

I'll take a look at the paper and talk to the original author of this strategy to learn more about the naming and the issue with the optional nature of the evaluation function.That's a very helpful example, thank you. I think it's working now!The renaming just got merged into `main` and will become available in tomorrow's Flower nightly release (and the full 0.17 a little later) - thanks again for pointing this out @smoser82 ! "	3	2021-03-03 16:20:12	2021-08-15 12:03:42	2021-08-15 12:01:34
https://github.com/adap/flower/issues/648	[]	Trying to run quickstart_tensorflow	"Trying to run quickstart_tensorflowHello,
I am trying to run your quickstart project but I got an error. When I tried to run server.py with port 8080 it failed, so I just changed the port to 5040 in both files (+ I checked if it is a free port ). The server runs ok, but then when I tried to run client.py I could not connect to the server. Both files client and server are running from the same PC with anaconda environment. Any clue what I did wrong? 

![flower quickstart2](https://user-images.githubusercontent.com/72346204/108837436-8af7a700-75d2-11eb-8ff5-c4604ee30efa.png)
![flower quickstart3](https://user-images.githubusercontent.com/72346204/108838494-fdb55200-75d3-11eb-8e3a-7b80d7fd2e95.png)

Hi @Martin-Stevlik , can you try to use IPv6 (so `[::]:8080`) for both server and client? We've recently changed the example code to use this because IPv4 produced an error in some cases.Thank you for your quick response. I have tried it and it works just fine. Is there a way for it to work with IPv4 in future? Because I want to run the server.py in AZURE VM and most of VM does not support IPv6 ...Great to hear it works @Martin-Stevlik - IPv4 is generally supported, but we're seeing the error you reported every now and then, however, it's not quite clear where it's coming from. Which platform are you on? We've tested the examples with both IPv4 and IPv6 and some people experienced issues while others didn't.

In the case of Docker, it's actually recommended to use IPv4 over IPv6 (IPv6 requires additional configuration in Docker).I am using Windows 10 and as a virtual environment Anaconda. My next step is to try your embedded devices quickstart on my Raspberry PI's. I will see how it goes there...@Martin-Stevlik were you able to resolve your issue? Let us know if we can help you further. With regards to Flower on Raspberry this might be useful for you: https://github.com/adap/flower/tree/main/examples/embedded_devices


Hi, I followed your instructions in the embedded devices tutorial and came across the same connecting issue. I have a PC witch runs server.py and 2 raspberries that runs client.py. Both raspberries and PC are on the same network and I am using your latest release 0.14.0. I don't know if you should put the port number in the client's code, but I have tried it but it would not resolve an issue.

![flower_raspberry3 1](https://user-images.githubusercontent.com/72346204/110376751-da6ab800-8053-11eb-9e40-daa9e0df2869.png)
![flower_raspberry](https://user-images.githubusercontent.com/72346204/110376764-dfc80280-8053-11eb-9071-c961a3a2211e.png)
![flower_raspberry2](https://user-images.githubusercontent.com/72346204/110376776-e22a5c80-8053-11eb-861a-e58bb8456085.png)
@Martin-Stevlik I think the issue is that the clients also need the port of the server. Can you try with `192.168.1.32:5000` when calling the `run_pi.sh`?

If that's the issue I will adjust the https://github.com/adap/flower/blob/main/examples/embedded_devices/README.md file to clarify it further.@tanertopal as you can see on the right side of the image. I have already tried it and it did not work ... I will try using IPv6 and give you an update on how it goes. @Martin-Stevlik my bad. Missed that. Am I guessing right that the server is running on a Windows machine? I think we did not test the setup with a Windows OS. I'll try it out in the next couple days on Windows 10 if you can confirm my guess.

In general can you tell me a little bit about your overall setup?

- Which exact OS and version
- Version of the tools involved e.g. DockerI am using 64 bit OS, Windows 10 PRO version 2004. For the environment on PC, I am using an anaconda with python=3.8.3, flwr=0.14.0, tensorflow-cpu=2.4.1 

As for raspberries I have raspberry 3 model B, OS is 64bit Ubuntu Server 20.04.2 LTS with docker version 20.10.4@tanertopal so I have tried it with IPv6 and the same issue comes up. I have put ""[::]:5040"" in server.py and my IPv6 address in client.py, if I do this in quickstart_tensorflow project it works ...@Martin-Stevlik so I assume you have run the `quickstart_tensorflow` example without docker as otherwise, you would have to activate [IPv6 support in Docker](https://docs.docker.com/config/daemon/ipv6/)? I am going to set up a new Raspberry Pi and try to replicate your issue. Need to check if I have a Raspberry 3 B somewhere lying around (I think so ðŸ˜„  ).

As another idea. Are you already part of our [Slack community](https://flower.dev/join-slack)? Maybe we can solve your issue faster there.

A few more ideas/questions:
1. Is the IP of the server you are using visible when you run `Get-NetIPConfiguration` in Powershell on the Windows server?
2. Can you modify the `run_pi.sh` and `run_jetson.sh` to include `--net=host`
    * `docker run --rm flower_client ${@}` => `docker run --net=host --rm flower_client ${@}` 
3. What happens when you run `telnet SERVER_ADDRESS SERVER_PORT` on the Raspberry Pi? Does it connect? You can cancel the connection if so using CTRL+D. This will give us a hint if its a Docker issue.Okay, so the key advice for running this ""embedded_devices"" project on windows 10 is to fully disable the firewall ;) "	13	2021-02-23 11:39:53	2021-03-18 19:49:45	2021-03-18 19:49:45
https://github.com/adap/flower/issues/552	[]	Improve docs (misc)	"Improve docs (misc)# Description
Improve the docs by removing obsolete parts and making it overall more readable (also on mobile).

# Tasks
- [x] Remove obsolete parts of the docs aka. How To AWS
- [x] Fix formatting
- [x] Use new Theme
Related PR's
* #547 
* #548 
* #551 Also relates to #482 and #472"	2	2021-01-05 17:16:41	2021-01-19 11:16:41	2021-01-19 11:16:29
https://github.com/adap/flower/issues/542	[]	transport_pb2.pyi file	"transport_pb2.pyi fileHow to generate the `transport_pb2.pyi` file? I cannot find any information about this on gRPC's official documentation. https://github.com/dropbox/mypy-protobuf
Problem solved. Thanks!"	1	2020-12-27 09:17:36	2020-12-27 09:56:52	2020-12-27 09:56:52
https://github.com/adap/flower/issues/540	['bug']	Evaluation of the final model on empty client set	"Evaluation of the final model on empty client setHello,
I'm trying to run the basic [Tensorflow Example](https://github.com/adap/flower/tree/main/examples/quickstart_tensorflow) but when the [final model evaluation is executed](https://github.com/adap/flower/blob/42ef63b6a8097c3b571b65e11b5471477253a48d/src/py/flwr/server/app.py#L97) the client returns an empty set, thus the evaluation is not executed.
This should be due to the fact that the server [closes the connections](https://github.com/adap/flower/blob/42ef63b6a8097c3b571b65e11b5471477253a48d/src/py/flwr/server/server.py#L117) with the clients after the fit.

Thank youThanks for the report @NicholasRasi ! What you're describing is right, good catch. We'll fix this asap.This is fixed by #553 and will be available in Flower 0.13.0."	2	2020-12-23 08:45:41	2021-01-06 09:37:37	2021-01-06 09:37:37
https://github.com/adap/flower/issues/537	[]	grpc error: details: failed to connect to all addresses	"grpc error: details: failed to connect to all addressesHi, I was just trying the examples on [https://flower.dev/docs/example_walkthrough_pytorch_mnist.html](url). After runing  `bash ./run-clients.sh`, I got the following errors. Can someone provides any help? 
`$ DEBUG flower 2020-12-17 14:45:45,394 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2020-12-17 14:45:45,394 | connection.py:36 | ChannelConnectivity.TRANSIENT_FAILURE
INFO flower 2020-12-17 14:45:45,394 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2020-12-17 14:45:45,410 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2020-12-17 14:45:45,410 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2020-12-17 14:45:45,410 | connection.py:36 | ChannelConnectivity.TRANSIENT_FAILURE
INFO flower 2020-12-17 14:45:45,410 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2020-12-17 14:45:45,597 | connection.py:68 | Insecure gRPC channel closed 
`
`Traceback (most recent call last):  
  File ""E:\Anaconda3\envs\ptq\lib\runpy.py"", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File ""E:\Anaconda3\envs\ptq\lib\runpy.py"", line 87, in _run_code
    exec(code, run_globals)
  File ""E:\Anaconda3\envs\ptq\lib\site-packages\flwr_example\quickstart_pytorch\client.py"", line 96, in <module>
    fl.client.start_client(args.server_address, client)
  File ""E:\Anaconda3\envs\ptq\lib\site-packages\flwr\client\app.py"", line 64, in start_client
    server_message = receive()
  File ""E:\Anaconda3\envs\ptq\lib\site-packages\flwr\client\grpc_client\connection.py"", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File ""E:\Anaconda3\envs\ptq\lib\site-packages\grpc\_channel.py"", line 416, in __next__
    return self._next()
  File ""E:\Anaconda3\envs\ptq\lib\site-packages\grpc\_channel.py"", line 786, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
        status = StatusCode.UNAVAILABLE
        details = ""failed to connect to all addresses""
        debug_error_string = ""{""created"":""@1608187545.406000000"",""description"":""Failed to pick subchannel"",""file"":""src/core/ext/filters/client_channel/client_channel.cc"",""file_line"":4143,""referenced_errors"":[{""created"":""@1608187545.406000000"",""description"":""failed to connect to all addresses"",""file"":""src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc"",""file_line"":398,""grpc_status"":14}]}""`issue solved by changing the ipv4 port.Hey I am having the same problem. I tried changing the port. But it still having the same issue. Can you tell me what did you exactly change?I have the same issue but after I changed port 5040 for both server and client, the FL worked fine."	3	2020-12-17 07:07:00	2021-08-19 15:45:26	2020-12-17 09:12:56
https://github.com/adap/flower/issues/530	['bug']	`Server.fit` method crash with `TypeError: 'int' object is not iterable` error	"`Server.fit` method crash with `TypeError: 'int' object is not iterable` errorHello,
since release `0.11.0` I'm not able to launch code that worked fine with release `0.10.0`

I have the same problem with release `0.12.0` 

Here is the Error Stack : 
```
File ""/srv/code/utils/ml_server_flower.py"", line 70, in run
    hist = server.fit(num_rounds=federated_config['ROUND_BEFORE_AGGREGATION'])
  File ""/usr/local/lib/python3.7/dist-packages/flwr/server/server.py"", line 110, in fit
    res_fed = self.evaluate(rnd=current_round)
  File ""/usr/local/lib/python3.7/dist-packages/flwr/server/server.py"", line 133, in evaluate
    rnd=rnd, weights=self.weights, client_manager=self._client_manager
  File ""/usr/local/lib/python3.7/dist-packages/flwr/server/strategy/fedavg.py"", line 121, in configure_evaluate
    parameters = weights_to_parameters(weights)
  File ""/usr/local/lib/python3.7/dist-packages/flwr/common/parameter.py"", line 28, in weights_to_parameters
    tensors = [ndarray_to_bytes(ndarray) for ndarray in weights]
TypeError: 'int' object is not iterable
```
The context where the issue appears

```python
client_manager = SimpleClientManager()
strategy = FedAvg()
server = Server(client_manager=client_manager, strategy=strategy)

model = KerasModel(data[0].shape[1], data[0].shape[2], data[1].shape[1])

grpc_server = start_insecure_grpc_server(
	client_manager=server.client_manager(), server_address=params['grpc_host']
)
hist = server.fit(num_rounds=federated_config['ROUND_BEFORE_AGGREGATION'])
...
```

the model i use :
```python
class KerasModel:
    def __init__(self, n_timesteps, n_features, n_outputs):
        """"""
        with : n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]
        """"""
        #Personalization of the optimizer
        sgd = optimizers.SGD(lr=float(keras_config['LEARNING_RATE']), momentum=0.0, decay=0.0,
                             nesterov=False)
        adam = optimizers.Adam(lr=float(keras_config['LEARNING_RATE']))
        rmsProp = optimizers.RMSprop(lr=float(keras_config['LEARNING_RATE']), rho=0.9, epsilon=None, decay=0.0)
        adagrad = optimizers.Adagrad(lr=0.01, epsilon=None, decay=0.0)
        adadelta = optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)
        adamax = optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)

	    #The network
        self.model = Sequential()
        self.model.add(Conv1D(filters=int(keras_config['FILTERS_CONV1D']),
                         kernel_size=int(keras_config['KERNEL_CONV1D']), activation=keras_config['ACTIVATION_CONV1D'],
                         input_shape=(n_timesteps,n_features)))
        #self.model.add(Conv1D(filters=8, kernel_size=5, activation='relu'))
        self.model.add(Dropout(float(keras_config['DROPOUT_RATIO'])))
        self.model.add(MaxPooling1D(pool_size=int(keras_config['POOL_SIZE_MAXPOOL'])))

        self.model.add(Conv1D(filters = int(keras_config['FILTERS_CONV1D']),
                              kernel_size=int(keras_config['KERNEL_CONV1D']), activation = keras_config['ACTIVATION_CONV1D']))
        self.model.add(Dropout(float(keras_config['DROPOUT_RATIO'])))
        self.model.add(MaxPooling1D(pool_size=int(keras_config['POOL_SIZE_MAXPOOL'])))
 
        self.model.add(Flatten())
		self.model.add(Dense(int(keras_config['DENSE1_NEURONS']), activation=keras_config['ACTIVATION_DENSE1']))
        self.model.add(Dense(n_outputs, activation=keras_config['ACTIVATION_DENSE2']))
        self.model.compile(loss=keras_config['LOSS'], optimizer=keras_config['OPTIMIZER'], metrics=['accuracy'])
 
    def set_weights(self, weights):
        self.model.set_weights(weights)
 
    def fit(self, x_train, y_train, epochs=None):
        self.model.fit(x_train, y_train, epochs=epochs, batch_size=common_config['BATCH_SIZE'])
 
    def get_weights(self):
        return self.model.get_weights()
 
    def evaluate(self, x_test, y_test):
        return self.model.evaluate(x_test, y_test)
```

configuration dictionary : 

```python
federated_config = {
    'ROUND_BEFORE_AGGREGATION': 3,
    'EPOCHS_PER_ROUND': 2,
}

common_config = {
    'TEST_BATCH_SIZE': 1000,
    'BATCH_SIZE': 64,
    'EPOCHS': 5,
}

keras_config = {
    'LEARNING_RATE': 0.0004,
    'FILTERS_CONV1D': 8,
    'KERNEL_CONV1D': 3,
    'ACTIVATION_CONV1D': 'relu',
    'DROPOUT_RATIO': 0.5,
    'POOL_SIZE_MAXPOOL': 3,
    'L2_REGU': False,
    'DENSE1_NEURONS': 20,
    'ACTIVATION_DENSE1': 'relu',
    'VALUE_L2_REGU': 0.001,
    'ACTIVATION_DENSE2': 'softmax',
    'LOSS': 'mean_squared_error',
    'OPTIMIZER': 'adam',
}
Thanks for the report @altor ! We went through your code and everything looks fine. The issues seems to be related to parameter serialization for distributed evaluation (i.e., on the clients). Does the initial round of training work before Flower tries to do the evaluation?
IIRC there were no changes related to that part of the codebase during the 0.11.0 and 0.12.0 release. Would it be possible to open source your code (or alternatively invite @tanertopal  and @danieljanes  to a private repo) so that we can try to run it?Closing this now because we couldn't reproduce. Feel free to reopen if this is still an issue for you @altor ."	2	2020-12-09 18:39:19	2021-02-05 10:10:08	2021-02-05 10:10:07
https://github.com/adap/flower/issues/408	['bug']	execution of client example crash after training is terminated	"execution of client example crash after training is terminatedHello !

I'm trying to use the example you provide ([quickstart](https://github.com/adap/flower/tree/main/src/py/flwr_example/quickstart) and [tensorflow](https://github.com/adap/flower/tree/main/src/py/flwr_example/tensorflow)). I achieve to train models but clients can't achieve to stop themselves without crashing.

I just run `run_server.sh` and `run_clients.sh` in separate terminals, see the clients downloading data and train their models. After training, the server evaluate the model ant stop itself properly.
At this moments, clients crash by rising an exception with this message : 

```
Traceback (most recent call last):
  File ""client.py"", line 114, in <module>
    main()
  File ""client.py"", line 110, in main
    fl.client.start_keras_client(args.server_address, client)
  File ""/usr/local/lib/python3.7/dist-packages/flwr/client/app.py"", line 47, in start_keras_client
    start_client(server_address, flower_client)
  File ""/usr/local/lib/python3.7/dist-packages/flwr/client/app.py"", line 35, in start_client
    server_message = receive()
  File ""/usr/local/lib/python3.7/dist-packages/flwr/client/grpc_client/connection.py"", line 59, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File ""/usr/local/lib/python3.7/dist-packages/grpc/_channel.py"", line 416, in __next__
    return self._next()
  File ""/usr/local/lib/python3.7/dist-packages/grpc/_channel.py"", line 706, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
        status = StatusCode.UNAVAILABLE
        details = ""Socket closed""
        debug_error_string = ""{""created"":""@1601383903.613729459"",""description"":""Error received from peer ipv6:[::]:8080"",""file"":""src/core/lib/surface/call.cc"",""file_line"":1055,""grpc_message"":""Socket closed"",""grpc_status"":14}""
```
 Hi @altor - thanks for creating the issue! We are aware of this, the reason for this exception is that the current `Client`/`KerasClient` implementations do not implement a *graceful shutdown* when the server is done training. We'll soon release an update that fixes the issue :) until we do, if the server shows the final accuracy/loss logs, your workload ran successfully.Ok, For the moment, i'll just catch the exception and close the client properly
Thanks for your answer !We'll update this issue once the change has landed.Thanks !
PR is ready: #449 PR is merged, graceful shutdown is available on branch main. New release will follow shortly.thanks !@altor the new release 0.10.0 is now available on PyPI"	8	2020-09-29 13:11:20	2020-11-09 11:28:22	2020-11-09 11:28:22
